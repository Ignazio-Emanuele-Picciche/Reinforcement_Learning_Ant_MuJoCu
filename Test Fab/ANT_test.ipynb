{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    \"\"\"\n",
    "    Crea e restituisce l'ambiente Ant-v5 dalla libreria Gymnasium.\n",
    "\n",
    "    Questa funzione istanzia l'ambiente \"Ant-v5\", uno degli ambienti recenti e ben supportati\n",
    "    in Gymnasium. I parametri usati sono:\n",
    "    - reset_noise_scale (0.1): determina la scala del rumore quando l'ambiente viene resettato.\n",
    "    - render_mode ('None'): indica che non verrà effettuato il rendering durante l'esecuzione.\n",
    "\n",
    "    Ritorna:\n",
    "        gym.Env: l'ambiente Ant-v5 inizializzato.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ant-v5 è l’ambiente più recente in Gymnasium.\n",
    "    return gym.make(\"Ant-v5\", \n",
    "                    reset_noise_scale=0.2282706739101626, # scala del rumore quando l'ambiente viene resettato \n",
    "                    forward_reward_weight=0.09314040045482441, # peso del reward per il movimento in avanti\n",
    "                    ctrl_cost_weight=0.028140178122103423, # peso del reward per il controllo\n",
    "                    healthy_reward =0.9926479631637423, # reward per la salute\n",
    "                    render_mode='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='None' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Creiamo un ambiente vettorializzato (Vectorized Environment)\n",
    "# Utilizziamo DummyVecEnv per gestire più istanze dell'ambiente come se fossero una singola entità.\n",
    "# Qui passiamo la funzione make_env (definita in un'altra cella) che crea l'ambiente \"Ant-v5\".\n",
    "env = DummyVecEnv([make_env])  \n",
    "\n",
    "# 2. Normalizziamo osservazioni (obs) e ricompense (reward)\n",
    "# VecNormalize scala le osservazioni e le ricompense per stabilizzare l'allenamento.\n",
    "# Parametri:\n",
    "#   norm_obs=True   -> Abilita la normalizzazione delle osservazioni.\n",
    "#   norm_reward=True -> Abilita la normalizzazione delle ricompense.\n",
    "#   clip_obs=10.     -> Limita i valori normalizzati dell'osservazione a un range [-10, 10] per evitare estremi.\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. Definiamo il modello RL (PPO) con spiegazioni dettagliate per ciascun parametro\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    learning_rate=0.0003,  # Ridotto per evitare aggiornamenti instabili\n",
    "    n_steps=2048,  # Mantenuto per bilanciare stabilità ed efficienza\n",
    "    batch_size=64,  # Manteniamo lo stesso batch size\n",
    "    n_epochs=10,  # Ridotto per evitare overfitting\n",
    "    gamma=0.99,  # Aumentato per migliorare l'importanza delle ricompense future\n",
    "    gae_lambda=0.95,  # Manteniamo questo valore\n",
    "    clip_range=0.2,  # Aumentato per dare più libertà alla policy\n",
    "    ent_coef=0.01,  # Aggiunto per incentivare una leggera esplorazione\n",
    "    vf_coef=0.5,  # Aggiunto per dare più peso alla funzione di valore\n",
    "    max_grad_norm=0.5,  # Aggiunto per evitare gradient explosion\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./ppo_Ant_tensorboard/\",\n",
    "    device='mps'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_Ant_tensorboard/PPO_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 360  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 5    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018420346 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | -1.17       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.114      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019352475 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | -1.37       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.165      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.0473      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 253         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019465992 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.148      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0703      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016995244 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.155      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0881      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01946146 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.4      |\n",
      "|    explained_variance   | 0.289      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.189     |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0533    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 0.0381     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020460451 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.154      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0536     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0484      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021043818 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.125      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0521     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0549      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020460907 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.149      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0549     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0609      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019589256 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | -0.0974     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.142      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0494     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020220213 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.168      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0649      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023436513 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.16       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0546     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0695      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023356173 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.154      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0561     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0339      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02167888 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.5      |\n",
      "|    explained_variance   | 0.811      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.173     |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0553    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0477     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022058332 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.172      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.053      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0372      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020457644 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.171      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0554     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0738      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023207247 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.2        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0561     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0387      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022206437 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.164      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0551     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0625      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023285637 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.18       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.057      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0269      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021412786 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.168      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0545     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0681      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023209095 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.169      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0563     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0636      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022305887 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.175      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0559     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0614      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 199        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02317201 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.5      |\n",
      "|    explained_variance   | 0.815      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.06      |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.0801     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020024084 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.16       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0556     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026648205 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.183      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0373      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024614593 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.179      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0576     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.097       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 235       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 234       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0233917 |\n",
      "|    clip_fraction        | 0.251     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -11.5     |\n",
      "|    explained_variance   | 0.852     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.158    |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -0.0589   |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 0.0797    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02524884 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.5      |\n",
      "|    explained_variance   | 0.87       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.199     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0611    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0603     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024785876 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.177      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0558     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0519      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026787568 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.179      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0561     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0256      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027922818 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.181      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0409      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 278        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02671523 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.6      |\n",
      "|    explained_variance   | 0.808      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.177     |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0567    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.027      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 287        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02422901 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.6      |\n",
      "|    explained_variance   | 0.769      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.166     |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0525    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 0.0588     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 295        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02670566 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.6      |\n",
      "|    explained_variance   | 0.837      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.177     |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0583    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0183     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 235        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02488002 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.7      |\n",
      "|    explained_variance   | 0.775      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.168     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0541    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.0536     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025033776 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.7       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.164      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0541     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0723      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024687262 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.7       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.173      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0568     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.048       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026388818 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.7       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.176      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0538     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0273      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025134694 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.7       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.175      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.055      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0408      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025661424 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.8       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.185      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0544     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0262      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026248429 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.8       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.174      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0243      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028297678 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.8       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.157      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0554     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0564      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024874093 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.8       |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.158      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0546     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0651      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 384        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02456365 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.9      |\n",
      "|    explained_variance   | 0.779      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.169     |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0591    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024038058 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.9       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.151      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0573     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0783      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024860943 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.8       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.162      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0561     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033072844 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.9       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.189      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0563     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024722766 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.9       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.152      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0596     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028507408 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.9       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.175      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0592     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0522      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x3823d5360>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Alleniamo il modello\n",
    "# Il parametro total_timesteps indica il numero totale di iterazioni (o passi)\n",
    "# che il modello eseguirà durante l'allenamento. Ogni timestep rappresenta un'interazione\n",
    "# con l'ambiente in cui il modello esegue un'azione e riceve un feedback, che viene poi\n",
    "# usato per aggiornare la sua politica interna.\n",
    "total_timesteps = 5000000  # Puoi aumentare questo valore per permettere al modello di acquisire più esperienza.\n",
    "model.learn(total_timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Salviamo il modello\n",
    "model.save(\"ppo_Ant_model\")\n",
    "env.save(\"vecnormalize_Ant.pkl\")  # salviamo anche i parametri di normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(env, policy, episodes=50):\n",
    "    \"\"\"\n",
    "    Valuta una policy addestrata su un ambiente dato.\n",
    "\n",
    "    Parametri:\n",
    "    - env: L'ambiente di simulazione.\n",
    "    - policy: La policy addestrata da valutare.\n",
    "    - episodes: Numero di episodi da eseguire per la valutazione.\n",
    "\n",
    "    Ritorna:\n",
    "    - La ricompensa media e la deviazione standard delle ricompense ottenute.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs = env.reset()  # Reset dell'ambiente per iniziare un nuovo episodio\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action, _ = policy.predict(obs)  # Predice l'azione da eseguire\n",
    "            obs, reward, done, _ = env.step(action)  # Esegue l'azione e ottiene il feedback dall'ambiente\n",
    "            total_reward += reward  # Accumula la ricompensa ottenuta\n",
    "        total_rewards.append(total_reward)  # Aggiunge la ricompensa totale dell'episodio alla lista\n",
    "    return np.mean(total_rewards), np.std(total_rewards)  # Calcola e ritorna la media e la deviazione standard delle ricompense\n",
    "\n",
    "\n",
    "def evaluate_random_policy(env, episodes=5000):\n",
    "    \"\"\"\n",
    "    Valuta una policy casuale su un ambiente dato.\n",
    "\n",
    "    Parametri:\n",
    "    - env: L'ambiente di simulazione.\n",
    "    - episodes: Numero di episodi da eseguire per la valutazione.\n",
    "\n",
    "    Ritorna:\n",
    "    - La ricompensa media e la deviazione standard delle ricompense ottenute.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs = env.reset()  # Reset dell'ambiente per iniziare un nuovo episodio\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action = env.action_space.sample()  # Genera un'azione casuale\n",
    "            obs, reward, done, _ = env.step(np.array([action]))  # Esegue l'azione e ottiene il feedback dall'ambiente\n",
    "            total_reward += reward  # Accumula la ricompensa ottenuta\n",
    "        total_rewards.append(total_reward)  # Aggiunge la ricompensa totale dell'episodio alla lista\n",
    "    return np.mean(total_rewards), np.std(total_rewards)  # Calcola e ritorna la media e la deviazione standard delle ricompense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Policy: Mean Reward: 5.4697794914245605, Std: 9.441436767578125\n",
      "Random Policy: Mean Reward: 7.851289749145508, Std: 10.90255069732666\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Valutazione dopo l'addestramento\n",
    "mean_reward_trained, std_reward_trained = evaluate_policy(env, model)  # Valuta la policy addestrata\n",
    "mean_reward_random, std_reward_random = evaluate_random_policy(env)  # Valuta la policy casuale\n",
    "\n",
    "# Stampa dei risultati\n",
    "print(f\"Trained Policy: Mean Reward: {mean_reward_trained}, Std: {std_reward_trained}\")\n",
    "print(f\"Random Policy: Mean Reward: {mean_reward_random}, Std: {std_reward_random}\")\n",
    "\n",
    "# Creazione del grafico di confronto\n",
    "labels = ['Random Policy', 'Trained Policy']\n",
    "means = [mean_reward_random, mean_reward_trained]\n",
    "stds = [std_reward_random, std_reward_trained]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, means, yerr=stds, capsize=10, color=['skyblue', 'lightgreen'])\n",
    "plt.ylabel('Mean Episodic Reward')\n",
    "plt.title('Policy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
