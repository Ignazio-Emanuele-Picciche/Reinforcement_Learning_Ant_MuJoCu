{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import time\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecNormalize, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./sac_HalfCheetah_tensorboard/SAC_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -256     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 82       |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.5      |\n",
      "|    critic_loss     | 0.03     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 7792     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -78.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.09    |\n",
      "|    critic_loss     | 0.283    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 15792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.7    |\n",
      "|    critic_loss     | 0.401    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 23792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 119      |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 184      |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.9    |\n",
      "|    critic_loss     | 0.414    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 31792    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=684.91 +/- 91.27\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 685      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.1    |\n",
      "|    critic_loss     | 0.468    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 39792    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 221      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 318      |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 278      |\n",
      "|    total_timesteps | 24000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -36.2    |\n",
      "|    critic_loss     | 0.429    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 47792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 391      |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 324      |\n",
      "|    total_timesteps | 28000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -40.1    |\n",
      "|    critic_loss     | 0.424    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 55792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 454      |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 371      |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -43.7    |\n",
      "|    critic_loss     | 0.369    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 63792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 510      |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 418      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -47.2    |\n",
      "|    critic_loss     | 0.348    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 71792    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=757.84 +/- 565.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 758      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -51.4    |\n",
      "|    critic_loss     | 0.428    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 79792    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 575      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 466      |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 634      |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 514      |\n",
      "|    total_timesteps | 44000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57.1    |\n",
      "|    critic_loss     | 0.517    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 87792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 687      |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 560      |\n",
      "|    total_timesteps | 48000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.3    |\n",
      "|    critic_loss     | 0.728    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 95792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 721      |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 607      |\n",
      "|    total_timesteps | 52000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.7    |\n",
      "|    critic_loss     | 0.767    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 103792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 777      |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 653      |\n",
      "|    total_timesteps | 56000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67      |\n",
      "|    critic_loss     | 0.856    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 111792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=1451.06 +/- 180.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 1.45e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66.8    |\n",
      "|    critic_loss     | 1.03     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 119792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 802      |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 701      |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 826      |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 749      |\n",
      "|    total_timesteps | 64000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68.5    |\n",
      "|    critic_loss     | 0.997    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 127792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 868      |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 794      |\n",
      "|    total_timesteps | 68000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.3    |\n",
      "|    critic_loss     | 1.08     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 135792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 913      |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 840      |\n",
      "|    total_timesteps | 72000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -76.3    |\n",
      "|    critic_loss     | 0.923    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 143792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 955      |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 887      |\n",
      "|    total_timesteps | 76000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81.4    |\n",
      "|    critic_loss     | 1.1      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 151792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=1677.14 +/- 50.52\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 1.68e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.1    |\n",
      "|    critic_loss     | 1.15     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 159792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 996      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 933      |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.04e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 980      |\n",
      "|    total_timesteps | 84000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88.7    |\n",
      "|    critic_loss     | 1.2      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 167792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.08e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1027     |\n",
      "|    total_timesteps | 88000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93      |\n",
      "|    critic_loss     | 1.32     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 175792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.12e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1073     |\n",
      "|    total_timesteps | 92000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 1.6      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 183792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.15e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1119     |\n",
      "|    total_timesteps | 96000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.1    |\n",
      "|    critic_loss     | 1.55     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 191792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=2121.35 +/- 37.95\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.12e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 1.78     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 199792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.19e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1165     |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.28e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1211     |\n",
      "|    total_timesteps | 104000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 1.71     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 207792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.36e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1258     |\n",
      "|    total_timesteps | 108000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 1.85     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 215792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1304     |\n",
      "|    total_timesteps | 112000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 1.68     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 223792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.51e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1350     |\n",
      "|    total_timesteps | 116000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 1.73     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 231792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-1017.29 +/- 63.19\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/              |           |\n",
      "|    mean_ep_length  | 1e+03     |\n",
      "|    mean_reward     | -1.02e+03 |\n",
      "| time/              |           |\n",
      "|    total_timesteps | 120000    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -164      |\n",
      "|    critic_loss     | 4.91      |\n",
      "|    ent_coef        | 0.001     |\n",
      "|    learning_rate   | 4.35e-05  |\n",
      "|    n_updates       | 239792    |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.54e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1396     |\n",
      "|    total_timesteps | 120000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.49e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1442     |\n",
      "|    total_timesteps | 124000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 3.13     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 247792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.54e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1487     |\n",
      "|    total_timesteps | 128000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 2.5      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 255792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1533     |\n",
      "|    total_timesteps | 132000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 2.36     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 263792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.66e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1579     |\n",
      "|    total_timesteps | 136000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -111     |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 271792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=2336.95 +/- 81.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.34e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 140000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -116     |\n",
      "|    critic_loss     | 2.45     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 279792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.72e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1626     |\n",
      "|    total_timesteps | 140000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1673     |\n",
      "|    total_timesteps | 144000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -117     |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 287792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1720     |\n",
      "|    total_timesteps | 148000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 295792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1767     |\n",
      "|    total_timesteps | 152000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 2.02     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 303792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.92e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1814     |\n",
      "|    total_timesteps | 156000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 1.7      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 311792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=2655.41 +/- 9.79\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.66e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 160000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 1.91     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 319792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1863     |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.01e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1911     |\n",
      "|    total_timesteps | 164000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 8.71     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 327792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1958     |\n",
      "|    total_timesteps | 168000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -348     |\n",
      "|    critic_loss     | 3.41e+03 |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 335792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2004     |\n",
      "|    total_timesteps | 172000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -989     |\n",
      "|    critic_loss     | 2.37e+03 |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 343792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.7e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2051     |\n",
      "|    total_timesteps | 176000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -831     |\n",
      "|    critic_loss     | 3.11e+03 |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 351792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-359.08 +/- 21.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -359     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 180000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -591     |\n",
      "|    critic_loss     | 1.11e+03 |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 359792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2098     |\n",
      "|    total_timesteps | 180000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.52e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2144     |\n",
      "|    total_timesteps | 184000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -332     |\n",
      "|    critic_loss     | 479      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 367792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2190     |\n",
      "|    total_timesteps | 188000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -231     |\n",
      "|    critic_loss     | 523      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 375792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.32e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2235     |\n",
      "|    total_timesteps | 192000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 701      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 383792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.22e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2281     |\n",
      "|    total_timesteps | 196000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 170      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 391792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-147.90 +/- 371.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -148     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 200000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -148     |\n",
      "|    critic_loss     | 238      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 399792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.11e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2328     |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.04e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2374     |\n",
      "|    total_timesteps | 204000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -139     |\n",
      "|    critic_loss     | 153      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 407792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 952      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2420     |\n",
      "|    total_timesteps | 208000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -123     |\n",
      "|    critic_loss     | 394      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 415792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 858      |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2467     |\n",
      "|    total_timesteps | 212000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -120     |\n",
      "|    critic_loss     | 149      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 423792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 750      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2515     |\n",
      "|    total_timesteps | 216000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -118     |\n",
      "|    critic_loss     | 232      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 431792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-563.50 +/- 26.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -563     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 220000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -123     |\n",
      "|    critic_loss     | 134      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 439792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 672      |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2563     |\n",
      "|    total_timesteps | 220000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 676      |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2610     |\n",
      "|    total_timesteps | 224000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 387      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 447792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 581      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2656     |\n",
      "|    total_timesteps | 228000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 175      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 455792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 488      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2703     |\n",
      "|    total_timesteps | 232000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.6    |\n",
      "|    critic_loss     | 342      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 463792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 377      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2749     |\n",
      "|    total_timesteps | 236000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.7    |\n",
      "|    critic_loss     | 482      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 471792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-372.17 +/- 300.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -372     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 240000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.6    |\n",
      "|    critic_loss     | 107      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 479792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2797     |\n",
      "|    total_timesteps | 240000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 155      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2844     |\n",
      "|    total_timesteps | 244000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.2    |\n",
      "|    critic_loss     | 195      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 487792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 46.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2891     |\n",
      "|    total_timesteps | 248000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.2    |\n",
      "|    critic_loss     | 261      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 495792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -53.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2936     |\n",
      "|    total_timesteps | 252000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78      |\n",
      "|    critic_loss     | 104      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 503792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -160     |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2981     |\n",
      "|    total_timesteps | 256000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.8    |\n",
      "|    critic_loss     | 146      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 511792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=214.58 +/- 173.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 215      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 260000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71      |\n",
      "|    critic_loss     | 148      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 519792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -266     |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 3027     |\n",
      "|    total_timesteps | 260000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -336     |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 3073     |\n",
      "|    total_timesteps | 264000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66.3    |\n",
      "|    critic_loss     | 48.3     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 527792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -295     |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 3118     |\n",
      "|    total_timesteps | 268000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68.8    |\n",
      "|    critic_loss     | 208      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 535792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -231     |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 3163     |\n",
      "|    total_timesteps | 272000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.7    |\n",
      "|    critic_loss     | 118      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 543792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -152     |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3208     |\n",
      "|    total_timesteps | 276000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -69.1    |\n",
      "|    critic_loss     | 118      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 551792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=1370.32 +/- 56.34\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 1.37e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 280000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67      |\n",
      "|    critic_loss     | 46.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 559792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -89      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3254     |\n",
      "|    total_timesteps | 280000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -26.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3299     |\n",
      "|    total_timesteps | 284000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.5    |\n",
      "|    critic_loss     | 137      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 567792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 49.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3344     |\n",
      "|    total_timesteps | 288000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.1    |\n",
      "|    critic_loss     | 120      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 575792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 121      |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3389     |\n",
      "|    total_timesteps | 292000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.8    |\n",
      "|    critic_loss     | 79.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 583792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 199      |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3434     |\n",
      "|    total_timesteps | 296000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73      |\n",
      "|    critic_loss     | 155      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 591792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=2419.69 +/- 120.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.42e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 300000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.6    |\n",
      "|    critic_loss     | 35.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 599792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 289      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3480     |\n",
      "|    total_timesteps | 300000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 359      |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3526     |\n",
      "|    total_timesteps | 304000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -72.9    |\n",
      "|    critic_loss     | 64       |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 607792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 407      |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3571     |\n",
      "|    total_timesteps | 308000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.8    |\n",
      "|    critic_loss     | 214      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 615792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 476      |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3616     |\n",
      "|    total_timesteps | 312000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68      |\n",
      "|    critic_loss     | 388      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 623792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 571      |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3661     |\n",
      "|    total_timesteps | 316000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -64.9    |\n",
      "|    critic_loss     | 56.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 631792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=1932.85 +/- 77.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 1.93e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 320000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68.3    |\n",
      "|    critic_loss     | 28.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 639792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 646      |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3707     |\n",
      "|    total_timesteps | 320000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 738      |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3753     |\n",
      "|    total_timesteps | 324000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -75      |\n",
      "|    critic_loss     | 36.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 647792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 829      |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3798     |\n",
      "|    total_timesteps | 328000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -75.6    |\n",
      "|    critic_loss     | 73.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 655792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 908      |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3843     |\n",
      "|    total_timesteps | 332000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.1    |\n",
      "|    critic_loss     | 8.97     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 663792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1e+03    |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3887     |\n",
      "|    total_timesteps | 336000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -76.7    |\n",
      "|    critic_loss     | 118      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 671792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=2359.70 +/- 129.68\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.36e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 340000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.8    |\n",
      "|    critic_loss     | 367      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 679792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.1e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3933     |\n",
      "|    total_timesteps | 340000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.18e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3979     |\n",
      "|    total_timesteps | 344000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.7    |\n",
      "|    critic_loss     | 6.45     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 687792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.27e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4024     |\n",
      "|    total_timesteps | 348000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81.6    |\n",
      "|    critic_loss     | 68.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 695792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.35e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4069     |\n",
      "|    total_timesteps | 352000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78.6    |\n",
      "|    critic_loss     | 58.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 703792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4114     |\n",
      "|    total_timesteps | 356000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.5    |\n",
      "|    critic_loss     | 140      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 711792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=2015.70 +/- 50.56\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.02e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 360000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -83.3    |\n",
      "|    critic_loss     | 229      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 719792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.51e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4160     |\n",
      "|    total_timesteps | 360000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.58e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4205     |\n",
      "|    total_timesteps | 364000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.5    |\n",
      "|    critic_loss     | 187      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 727792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.66e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4250     |\n",
      "|    total_timesteps | 368000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.5    |\n",
      "|    critic_loss     | 8.43     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 735792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.72e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4295     |\n",
      "|    total_timesteps | 372000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.5    |\n",
      "|    critic_loss     | 15.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 743792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4340     |\n",
      "|    total_timesteps | 376000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.2    |\n",
      "|    critic_loss     | 7.04     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 751792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=2511.67 +/- 39.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.51e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 380000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.9    |\n",
      "|    critic_loss     | 32.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 759792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4386     |\n",
      "|    total_timesteps | 380000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4432     |\n",
      "|    total_timesteps | 384000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.1    |\n",
      "|    critic_loss     | 98       |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 767792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4477     |\n",
      "|    total_timesteps | 388000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -83.4    |\n",
      "|    critic_loss     | 126      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 775792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4522     |\n",
      "|    total_timesteps | 392000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89      |\n",
      "|    critic_loss     | 6.03     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 783792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4567     |\n",
      "|    total_timesteps | 396000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.1    |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 791792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=2424.00 +/- 33.23\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.42e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 400000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.8    |\n",
      "|    critic_loss     | 214      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 799792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2e+03    |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4613     |\n",
      "|    total_timesteps | 400000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.02e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4658     |\n",
      "|    total_timesteps | 404000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87      |\n",
      "|    critic_loss     | 188      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 807792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.07e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4703     |\n",
      "|    total_timesteps | 408000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.9    |\n",
      "|    critic_loss     | 26.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 815792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.09e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4748     |\n",
      "|    total_timesteps | 412000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.4    |\n",
      "|    critic_loss     | 55       |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 823792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.11e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4793     |\n",
      "|    total_timesteps | 416000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.1    |\n",
      "|    critic_loss     | 98.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 831792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=2485.44 +/- 114.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.49e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 420000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93      |\n",
      "|    critic_loss     | 109      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 839792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.15e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4839     |\n",
      "|    total_timesteps | 420000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.16e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4885     |\n",
      "|    total_timesteps | 424000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.6    |\n",
      "|    critic_loss     | 5.61     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 847792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.18e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 428      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4930     |\n",
      "|    total_timesteps | 428000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.8    |\n",
      "|    critic_loss     | 171      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 855792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.17e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 432      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4975     |\n",
      "|    total_timesteps | 432000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.2    |\n",
      "|    critic_loss     | 41.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 863792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.19e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 436      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5020     |\n",
      "|    total_timesteps | 436000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98      |\n",
      "|    critic_loss     | 67.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 871792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=2341.76 +/- 94.75\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.34e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 440000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 4.84     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 879792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.2e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5066     |\n",
      "|    total_timesteps | 440000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.22e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 444      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5112     |\n",
      "|    total_timesteps | 444000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.6    |\n",
      "|    critic_loss     | 64.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 887792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.24e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 448      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5157     |\n",
      "|    total_timesteps | 448000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.6    |\n",
      "|    critic_loss     | 31.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 895792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.27e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 452      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5202     |\n",
      "|    total_timesteps | 452000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 146      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 903792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.29e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 456      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5247     |\n",
      "|    total_timesteps | 456000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99      |\n",
      "|    critic_loss     | 159      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 911792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=2508.74 +/- 109.03\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.51e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 460000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 66.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 919792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.31e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5292     |\n",
      "|    total_timesteps | 460000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.33e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 464      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5338     |\n",
      "|    total_timesteps | 464000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 4.9      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 927792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.35e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 468      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5383     |\n",
      "|    total_timesteps | 468000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 137      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 935792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.37e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 472      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5428     |\n",
      "|    total_timesteps | 472000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 92.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 943792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.38e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 476      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5473     |\n",
      "|    total_timesteps | 476000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 25.3     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 951792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=2560.85 +/- 39.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 480000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 4.13     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 959792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.39e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5519     |\n",
      "|    total_timesteps | 480000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.41e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 484      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5565     |\n",
      "|    total_timesteps | 484000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 70.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 967792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 488      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5610     |\n",
      "|    total_timesteps | 488000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 92.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 975792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 492      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5655     |\n",
      "|    total_timesteps | 492000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 49.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 983792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 496      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5700     |\n",
      "|    total_timesteps | 496000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 47.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 991792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=2570.53 +/- 47.58\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 500000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 4.44     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 999792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.44e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5746     |\n",
      "|    total_timesteps | 500000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.45e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 504      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5791     |\n",
      "|    total_timesteps | 504000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 5.13     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1007792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.46e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 508      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5836     |\n",
      "|    total_timesteps | 508000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 28.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1015792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.48e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 512      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5881     |\n",
      "|    total_timesteps | 512000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 30.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1023792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.49e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 516      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5926     |\n",
      "|    total_timesteps | 516000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 134      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1031792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=2498.72 +/- 98.98\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.5e+03  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 520000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1039792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.5e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5972     |\n",
      "|    total_timesteps | 520000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.51e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 524      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6019     |\n",
      "|    total_timesteps | 524000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -120     |\n",
      "|    critic_loss     | 231      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1047792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.51e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 528      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6064     |\n",
      "|    total_timesteps | 528000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -118     |\n",
      "|    critic_loss     | 52.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1055792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.54e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 532      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6109     |\n",
      "|    total_timesteps | 532000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 50.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1063792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.55e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 536      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6154     |\n",
      "|    total_timesteps | 536000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -118     |\n",
      "|    critic_loss     | 120      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1071792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=2568.55 +/- 30.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 540000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 46.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1079792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6200     |\n",
      "|    total_timesteps | 540000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 544      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6245     |\n",
      "|    total_timesteps | 544000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 4.87     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1087792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 548      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6290     |\n",
      "|    total_timesteps | 548000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 5.19     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1095792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 552      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6335     |\n",
      "|    total_timesteps | 552000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 81.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1103792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 556      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6380     |\n",
      "|    total_timesteps | 556000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 75.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1111792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=2586.95 +/- 38.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 560000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 65.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1119792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6426     |\n",
      "|    total_timesteps | 560000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 564      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6472     |\n",
      "|    total_timesteps | 564000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 4.4      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1127792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 568      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6517     |\n",
      "|    total_timesteps | 568000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 67.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1135792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 572      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6562     |\n",
      "|    total_timesteps | 572000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -128     |\n",
      "|    critic_loss     | 70.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1143792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 576      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6607     |\n",
      "|    total_timesteps | 576000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 3.74     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1151792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=2558.62 +/- 36.70\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 580000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 23.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1159792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6653     |\n",
      "|    total_timesteps | 580000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 584      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6698     |\n",
      "|    total_timesteps | 584000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 75.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1167792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.58e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 588      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6743     |\n",
      "|    total_timesteps | 588000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 392      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1175792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.58e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 592      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6788     |\n",
      "|    total_timesteps | 592000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 71.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1183792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 596      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6833     |\n",
      "|    total_timesteps | 596000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -128     |\n",
      "|    critic_loss     | 159      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1191792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=2605.93 +/- 43.71\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 600000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 10.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1199792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6879     |\n",
      "|    total_timesteps | 600000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 604      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6925     |\n",
      "|    total_timesteps | 604000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 22.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1207792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 608      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6969     |\n",
      "|    total_timesteps | 608000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 51.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1215792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 612      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7015     |\n",
      "|    total_timesteps | 612000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 4.89     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1223792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 616      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7059     |\n",
      "|    total_timesteps | 616000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 28.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1231792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=2627.23 +/- 55.72\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 620000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 46.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1239792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7106     |\n",
      "|    total_timesteps | 620000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 624      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7151     |\n",
      "|    total_timesteps | 624000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 20.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1247792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 628      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7196     |\n",
      "|    total_timesteps | 628000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 127      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1255792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 632      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7241     |\n",
      "|    total_timesteps | 632000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -133     |\n",
      "|    critic_loss     | 91.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1263792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 636      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7286     |\n",
      "|    total_timesteps | 636000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 3.37     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1271792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=2538.10 +/- 205.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.54e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 640000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -134     |\n",
      "|    critic_loss     | 29.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1279792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7334     |\n",
      "|    total_timesteps | 640000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 644      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7379     |\n",
      "|    total_timesteps | 644000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -137     |\n",
      "|    critic_loss     | 5.29     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1287792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 648      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7425     |\n",
      "|    total_timesteps | 648000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -133     |\n",
      "|    critic_loss     | 77.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1295792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 652      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7470     |\n",
      "|    total_timesteps | 652000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 178      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1303792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 656      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7515     |\n",
      "|    total_timesteps | 656000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -134     |\n",
      "|    critic_loss     | 52.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1311792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=2637.67 +/- 54.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 660000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 112      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1319792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7561     |\n",
      "|    total_timesteps | 660000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 664      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7606     |\n",
      "|    total_timesteps | 664000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 3.62     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1327792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 668      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7651     |\n",
      "|    total_timesteps | 668000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -138     |\n",
      "|    critic_loss     | 3.2      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1335792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 672      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7696     |\n",
      "|    total_timesteps | 672000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -139     |\n",
      "|    critic_loss     | 113      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1343792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 676      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7741     |\n",
      "|    total_timesteps | 676000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -140     |\n",
      "|    critic_loss     | 2.5      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1351792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-84.03 +/- 58.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -84      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 680000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -142     |\n",
      "|    critic_loss     | 2.07     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1359792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7787     |\n",
      "|    total_timesteps | 680000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 684      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7833     |\n",
      "|    total_timesteps | 684000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -146     |\n",
      "|    critic_loss     | 2.23     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1367792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 688      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7878     |\n",
      "|    total_timesteps | 688000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -147     |\n",
      "|    critic_loss     | 2.88     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1375792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 692      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7923     |\n",
      "|    total_timesteps | 692000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -147     |\n",
      "|    critic_loss     | 2.07     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1383792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 696      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7967     |\n",
      "|    total_timesteps | 696000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -148     |\n",
      "|    critic_loss     | 2.08     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1391792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=2708.97 +/- 32.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.71e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 700000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -149     |\n",
      "|    critic_loss     | 1.96     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1399792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8013     |\n",
      "|    total_timesteps | 700000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 704      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8059     |\n",
      "|    total_timesteps | 704000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -152     |\n",
      "|    critic_loss     | 1.73     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1407792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.66e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 708      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8104     |\n",
      "|    total_timesteps | 708000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -152     |\n",
      "|    critic_loss     | 1.75     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1415792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 712      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8149     |\n",
      "|    total_timesteps | 712000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -150     |\n",
      "|    critic_loss     | 1.53     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1423792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 716      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8194     |\n",
      "|    total_timesteps | 716000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -151     |\n",
      "|    critic_loss     | 2.01     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1431792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=2745.63 +/- 15.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.75e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 720000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -154     |\n",
      "|    critic_loss     | 1.73     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1439792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 720      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8239     |\n",
      "|    total_timesteps | 720000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 724      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8285     |\n",
      "|    total_timesteps | 724000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -154     |\n",
      "|    critic_loss     | 1.74     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1447792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 728      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8330     |\n",
      "|    total_timesteps | 728000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -156     |\n",
      "|    critic_loss     | 2.23     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1455792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 732      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8375     |\n",
      "|    total_timesteps | 732000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -156     |\n",
      "|    critic_loss     | 1.91     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1463792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 736      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8420     |\n",
      "|    total_timesteps | 736000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -158     |\n",
      "|    critic_loss     | 1.72     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1471792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=156.15 +/- 4.79\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 156      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 740000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -159     |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1479792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 740      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8466     |\n",
      "|    total_timesteps | 740000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 744      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8512     |\n",
      "|    total_timesteps | 744000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -162     |\n",
      "|    critic_loss     | 1.43     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1487792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 748      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8557     |\n",
      "|    total_timesteps | 748000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -161     |\n",
      "|    critic_loss     | 1.83     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1495792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 752      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8601     |\n",
      "|    total_timesteps | 752000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -163     |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1503792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 756      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8646     |\n",
      "|    total_timesteps | 756000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -164     |\n",
      "|    critic_loss     | 1.15     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1511792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=2740.49 +/- 18.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 760000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -166     |\n",
      "|    critic_loss     | 1.23     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1519792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 760      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8692     |\n",
      "|    total_timesteps | 760000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 764      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8738     |\n",
      "|    total_timesteps | 764000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 2.4      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1527792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 768      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8783     |\n",
      "|    total_timesteps | 768000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 1.36     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1535792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 772      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8828     |\n",
      "|    total_timesteps | 772000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -166     |\n",
      "|    critic_loss     | 1.51     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1543792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 776      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8872     |\n",
      "|    total_timesteps | 776000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 0.889    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1551792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=2792.40 +/- 12.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 780000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 1.07     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1559792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 780      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8918     |\n",
      "|    total_timesteps | 780000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 784      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8964     |\n",
      "|    total_timesteps | 784000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -169     |\n",
      "|    critic_loss     | 0.83     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1567792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 788      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9009     |\n",
      "|    total_timesteps | 788000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 1.44     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1575792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 792      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9054     |\n",
      "|    total_timesteps | 792000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 1.21     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1583792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 796      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9099     |\n",
      "|    total_timesteps | 796000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 0.862    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1591792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=2743.32 +/- 6.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 800000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -169     |\n",
      "|    critic_loss     | 0.811    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1599792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9145     |\n",
      "|    total_timesteps | 800000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 804      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9190     |\n",
      "|    total_timesteps | 804000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -169     |\n",
      "|    critic_loss     | 0.84     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1607792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 808      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9235     |\n",
      "|    total_timesteps | 808000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 1.24     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1615792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 812      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9280     |\n",
      "|    total_timesteps | 812000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 0.805    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1623792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 816      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9325     |\n",
      "|    total_timesteps | 816000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 1.14     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1631792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=2733.12 +/- 8.37\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.73e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 820000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 1.16     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1639792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 820      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9370     |\n",
      "|    total_timesteps | 820000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 824      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9416     |\n",
      "|    total_timesteps | 824000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 0.755    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1647792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 828      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9461     |\n",
      "|    total_timesteps | 828000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 0.738    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1655792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 832      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9506     |\n",
      "|    total_timesteps | 832000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 0.801    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1663792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 836      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9551     |\n",
      "|    total_timesteps | 836000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -172     |\n",
      "|    critic_loss     | 0.778    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1671792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=2772.89 +/- 6.19\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 840000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.851    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1679792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 840      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9596     |\n",
      "|    total_timesteps | 840000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.69e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 844      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9642     |\n",
      "|    total_timesteps | 844000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 1.17     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1687792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 848      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9687     |\n",
      "|    total_timesteps | 848000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.633    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1695792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 852      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9732     |\n",
      "|    total_timesteps | 852000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 0.851    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1703792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.69e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 856      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9777     |\n",
      "|    total_timesteps | 856000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.446    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1711792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=2738.21 +/- 9.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 860000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 0.552    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1719792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.69e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 860      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9823     |\n",
      "|    total_timesteps | 860000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.69e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 864      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9868     |\n",
      "|    total_timesteps | 864000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.461    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1727792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.71e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 868      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9913     |\n",
      "|    total_timesteps | 868000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.908    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1735792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 872      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9958     |\n",
      "|    total_timesteps | 872000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 0.911    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1743792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 876      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10003    |\n",
      "|    total_timesteps | 876000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 0.85     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1751792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=2776.31 +/- 13.73\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 880000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.516    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1759792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 880      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10049    |\n",
      "|    total_timesteps | 880000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.75e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 884      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10094    |\n",
      "|    total_timesteps | 884000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.426    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1767792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.75e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 888      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10139    |\n",
      "|    total_timesteps | 888000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.66     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1775792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.76e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 892      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10184    |\n",
      "|    total_timesteps | 892000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.602    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1783792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.76e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 896      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10229    |\n",
      "|    total_timesteps | 896000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.506    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1791792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=2790.96 +/- 18.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 900000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -176     |\n",
      "|    critic_loss     | 0.523    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1799792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.76e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 900      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10275    |\n",
      "|    total_timesteps | 900000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 904      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10320    |\n",
      "|    total_timesteps | 904000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.348    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1807792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 908      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10365    |\n",
      "|    total_timesteps | 908000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -176     |\n",
      "|    critic_loss     | 0.408    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1815792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 912      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10410    |\n",
      "|    total_timesteps | 912000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.461    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1823792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 916      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10455    |\n",
      "|    total_timesteps | 916000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -176     |\n",
      "|    critic_loss     | 0.681    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1831792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=2793.97 +/- 17.38\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 920000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.462    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1839792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 920      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10501    |\n",
      "|    total_timesteps | 920000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 924      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10546    |\n",
      "|    total_timesteps | 924000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.339    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1847792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 928      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10591    |\n",
      "|    total_timesteps | 928000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.239    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1855792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 932      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10636    |\n",
      "|    total_timesteps | 932000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.344    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1863792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 936      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10681    |\n",
      "|    total_timesteps | 936000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.383    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1871792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=2776.28 +/- 22.48\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 940000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.506    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1879792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 940      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10727    |\n",
      "|    total_timesteps | 940000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 944      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10773    |\n",
      "|    total_timesteps | 944000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.277    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1887792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 948      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10818    |\n",
      "|    total_timesteps | 948000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.248    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1895792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 952      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10863    |\n",
      "|    total_timesteps | 952000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.458    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1903792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 956      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10908    |\n",
      "|    total_timesteps | 956000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.36     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1911792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=2800.17 +/- 41.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 960000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.375    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1919792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 960      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10954    |\n",
      "|    total_timesteps | 960000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 964      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10999    |\n",
      "|    total_timesteps | 964000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.237    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1927792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 968      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11044    |\n",
      "|    total_timesteps | 968000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.414    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1935792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 972      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11089    |\n",
      "|    total_timesteps | 972000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.469    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1943792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 976      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11134    |\n",
      "|    total_timesteps | 976000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.276    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1951792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=2811.22 +/- 15.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 980000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.553    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1959792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 980      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11183    |\n",
      "|    total_timesteps | 980000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 984      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11228    |\n",
      "|    total_timesteps | 984000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.295    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1967792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 988      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11275    |\n",
      "|    total_timesteps | 988000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.344    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1975792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 992      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11322    |\n",
      "|    total_timesteps | 992000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.3      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1983792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 996      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11369    |\n",
      "|    total_timesteps | 996000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.551    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1991792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=2820.67 +/- 20.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1000000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.374    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1999792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1000     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11416    |\n",
      "|    total_timesteps | 1000000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1004     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11464    |\n",
      "|    total_timesteps | 1004000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 0.228    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2007792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1008     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11510    |\n",
      "|    total_timesteps | 1008000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 0.253    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2015792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1012     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11556    |\n",
      "|    total_timesteps | 1012000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.324    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2023792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1016     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11603    |\n",
      "|    total_timesteps | 1016000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 0.344    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2031792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=2822.69 +/- 13.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1020000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 0.27     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2039792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1020     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11650    |\n",
      "|    total_timesteps | 1020000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1024     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11697    |\n",
      "|    total_timesteps | 1024000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.295    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2047792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1028     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11743    |\n",
      "|    total_timesteps | 1028000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.154    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2055792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1032     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11790    |\n",
      "|    total_timesteps | 1032000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.339    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2063792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1036     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11836    |\n",
      "|    total_timesteps | 1036000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.262    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2071792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=2840.88 +/- 14.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1040000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.285    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2079792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1040     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11883    |\n",
      "|    total_timesteps | 1040000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1044     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11930    |\n",
      "|    total_timesteps | 1044000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.284    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2087792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1048     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11976    |\n",
      "|    total_timesteps | 1048000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.231    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2095792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1052     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12022    |\n",
      "|    total_timesteps | 1052000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.598    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2103792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1056     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12069    |\n",
      "|    total_timesteps | 1056000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.231    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2111792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=2843.55 +/- 32.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1060000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2119792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1060     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12116    |\n",
      "|    total_timesteps | 1060000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1064     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12163    |\n",
      "|    total_timesteps | 1064000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.177    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2127792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1068     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12209    |\n",
      "|    total_timesteps | 1068000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.339    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2135792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1072     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12255    |\n",
      "|    total_timesteps | 1072000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.411    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2143792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1076     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12301    |\n",
      "|    total_timesteps | 1076000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.278    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2151792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=2868.93 +/- 15.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1080000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.277    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2159792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1080     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12349    |\n",
      "|    total_timesteps | 1080000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1084     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12396    |\n",
      "|    total_timesteps | 1084000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.255    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2167792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1088     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12441    |\n",
      "|    total_timesteps | 1088000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.283    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2175792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1092     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12486    |\n",
      "|    total_timesteps | 1092000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2183792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1096     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12531    |\n",
      "|    total_timesteps | 1096000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.492    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2191792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=2843.34 +/- 27.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1100000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.256    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2199792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1100     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12577    |\n",
      "|    total_timesteps | 1100000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1104     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12622    |\n",
      "|    total_timesteps | 1104000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.224    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2207792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1108     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12667    |\n",
      "|    total_timesteps | 1108000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.276    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2215792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1112     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12712    |\n",
      "|    total_timesteps | 1112000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.236    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2223792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1116     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12757    |\n",
      "|    total_timesteps | 1116000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.299    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2231792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=2854.31 +/- 26.54\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1120000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.198    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2239792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1120     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12803    |\n",
      "|    total_timesteps | 1120000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1124     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12848    |\n",
      "|    total_timesteps | 1124000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.263    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2247792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1128     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12893    |\n",
      "|    total_timesteps | 1128000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.25     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2255792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1132     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12938    |\n",
      "|    total_timesteps | 1132000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.246    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2263792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1136     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12983    |\n",
      "|    total_timesteps | 1136000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.259    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2271792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1140000, episode_reward=2854.96 +/- 24.89\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1140000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.24     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2279792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1140     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13029    |\n",
      "|    total_timesteps | 1140000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1144     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13075    |\n",
      "|    total_timesteps | 1144000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.25     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2287792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1148     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13120    |\n",
      "|    total_timesteps | 1148000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.249    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2295792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1152     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13165    |\n",
      "|    total_timesteps | 1152000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.329    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2303792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1156     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13210    |\n",
      "|    total_timesteps | 1156000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.15     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2311792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=2874.34 +/- 66.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1160000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.205    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2319792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1160     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13256    |\n",
      "|    total_timesteps | 1160000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1164     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13301    |\n",
      "|    total_timesteps | 1164000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.287    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2327792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1168     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13346    |\n",
      "|    total_timesteps | 1168000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.25     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2335792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1172     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13391    |\n",
      "|    total_timesteps | 1172000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.281    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2343792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1176     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13436    |\n",
      "|    total_timesteps | 1176000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.319    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2351792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=2920.32 +/- 35.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.92e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1180000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.275    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2359792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1180     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13482    |\n",
      "|    total_timesteps | 1180000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1184     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13528    |\n",
      "|    total_timesteps | 1184000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.254    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2367792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1188     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13573    |\n",
      "|    total_timesteps | 1188000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.326    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2375792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1192     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13618    |\n",
      "|    total_timesteps | 1192000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.379    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2383792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1196     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13663    |\n",
      "|    total_timesteps | 1196000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.357    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2391792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=2869.14 +/- 18.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1200000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.26     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2399792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1200     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13709    |\n",
      "|    total_timesteps | 1200000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1204     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13754    |\n",
      "|    total_timesteps | 1204000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.374    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2407792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1208     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13799    |\n",
      "|    total_timesteps | 1208000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.424    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2415792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1212     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13844    |\n",
      "|    total_timesteps | 1212000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2423792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1216     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13889    |\n",
      "|    total_timesteps | 1216000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.248    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2431792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=2942.43 +/- 51.68\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1220000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.175    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2439792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1220     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13935    |\n",
      "|    total_timesteps | 1220000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1224     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13981    |\n",
      "|    total_timesteps | 1224000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.505    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2447792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.89e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1228     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14026    |\n",
      "|    total_timesteps | 1228000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.21     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2455792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.89e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1232     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14071    |\n",
      "|    total_timesteps | 1232000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.301    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2463792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.89e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1236     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14116    |\n",
      "|    total_timesteps | 1236000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.225    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2471792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=3004.80 +/- 11.17\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3e+03    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1240000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.378    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2479792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1240     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14161    |\n",
      "|    total_timesteps | 1240000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1244     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14207    |\n",
      "|    total_timesteps | 1244000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.36     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2487792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1248     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14252    |\n",
      "|    total_timesteps | 1248000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.487    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2495792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1252     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14297    |\n",
      "|    total_timesteps | 1252000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.218    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2503792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1256     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14342    |\n",
      "|    total_timesteps | 1256000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.414    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2511792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=2953.80 +/- 13.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1260000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.319    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2519792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1260     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14387    |\n",
      "|    total_timesteps | 1260000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1264     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14433    |\n",
      "|    total_timesteps | 1264000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -187     |\n",
      "|    critic_loss     | 0.412    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2527792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1268     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14478    |\n",
      "|    total_timesteps | 1268000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -187     |\n",
      "|    critic_loss     | 0.202    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2535792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.92e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1272     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14523    |\n",
      "|    total_timesteps | 1272000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -187     |\n",
      "|    critic_loss     | 0.288    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2543792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.92e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1276     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14570    |\n",
      "|    total_timesteps | 1276000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -187     |\n",
      "|    critic_loss     | 0.277    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2551792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=2996.53 +/- 15.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3e+03    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1280000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 0.347    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2559792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.92e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1280     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14618    |\n",
      "|    total_timesteps | 1280000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.93e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1284     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14663    |\n",
      "|    total_timesteps | 1284000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 0.316    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2567792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.93e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1288     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14708    |\n",
      "|    total_timesteps | 1288000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.47     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2575792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.93e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1292     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14753    |\n",
      "|    total_timesteps | 1292000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.264    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2583792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1296     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14798    |\n",
      "|    total_timesteps | 1296000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.252    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2591792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=3008.52 +/- 14.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3.01e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1300000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.329    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2599792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1300     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14844    |\n",
      "|    total_timesteps | 1300000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1304     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14890    |\n",
      "|    total_timesteps | 1304000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 0.306    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2607792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1308     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14935    |\n",
      "|    total_timesteps | 1308000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.199    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2615792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1312     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14980    |\n",
      "|    total_timesteps | 1312000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.289    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2623792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1316     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15025    |\n",
      "|    total_timesteps | 1316000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 0.426    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2631792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=2949.33 +/- 10.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1320000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.273    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2639792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1320     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15071    |\n",
      "|    total_timesteps | 1320000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1324     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15117    |\n",
      "|    total_timesteps | 1324000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.263    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2647792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1328     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15162    |\n",
      "|    total_timesteps | 1328000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.216    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2655792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1332     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15207    |\n",
      "|    total_timesteps | 1332000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.408    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2663792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1336     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15252    |\n",
      "|    total_timesteps | 1336000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.439    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2671792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=3020.18 +/- 16.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3.02e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1340000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.358    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2679792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1340     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15298    |\n",
      "|    total_timesteps | 1340000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1344     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15343    |\n",
      "|    total_timesteps | 1344000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.207    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2687792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1348     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15389    |\n",
      "|    total_timesteps | 1348000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.279    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2695792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1352     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15434    |\n",
      "|    total_timesteps | 1352000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.601    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2703792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1356     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15479    |\n",
      "|    total_timesteps | 1356000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.309    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2711792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=2888.05 +/- 59.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.89e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1360000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.3      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2719792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1360     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15525    |\n",
      "|    total_timesteps | 1360000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1364     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15570    |\n",
      "|    total_timesteps | 1364000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.374    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2727792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1368     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15615    |\n",
      "|    total_timesteps | 1368000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.238    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2735792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1372     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15660    |\n",
      "|    total_timesteps | 1372000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.267    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2743792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1376     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15705    |\n",
      "|    total_timesteps | 1376000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.19     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2751792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=2985.45 +/- 36.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.99e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1380000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.285    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2759792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1380     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15751    |\n",
      "|    total_timesteps | 1380000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1384     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15797    |\n",
      "|    total_timesteps | 1384000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2767792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1388     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15842    |\n",
      "|    total_timesteps | 1388000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.321    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2775792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1392     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15887    |\n",
      "|    total_timesteps | 1392000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.236    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2783792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1396     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15932    |\n",
      "|    total_timesteps | 1396000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.251    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2791792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=2938.88 +/- 32.36\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1400000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.436    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2799792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1400     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15978    |\n",
      "|    total_timesteps | 1400000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1404     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16024    |\n",
      "|    total_timesteps | 1404000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.294    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2807792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1408     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16069    |\n",
      "|    total_timesteps | 1408000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.193    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2815792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1412     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16114    |\n",
      "|    total_timesteps | 1412000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.336    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2823792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1416     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16159    |\n",
      "|    total_timesteps | 1416000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.296    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2831792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=2991.34 +/- 9.73\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.99e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1420000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.194    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2839792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1420     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16205    |\n",
      "|    total_timesteps | 1420000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1424     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16250    |\n",
      "|    total_timesteps | 1424000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.321    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2847792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1428     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16295    |\n",
      "|    total_timesteps | 1428000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.339    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2855792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1432     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16340    |\n",
      "|    total_timesteps | 1432000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.229    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2863792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1436     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16385    |\n",
      "|    total_timesteps | 1436000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.264    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2871792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=3001.28 +/- 11.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3e+03    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1440000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.397    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2879792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1440     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16431    |\n",
      "|    total_timesteps | 1440000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1444     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16477    |\n",
      "|    total_timesteps | 1444000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.45     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2887792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1448     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16522    |\n",
      "|    total_timesteps | 1448000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.32     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2895792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1452     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16567    |\n",
      "|    total_timesteps | 1452000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.305    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2903792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1456     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16612    |\n",
      "|    total_timesteps | 1456000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.239    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2911792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=2805.35 +/- 64.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1460000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.403    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2919792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1460     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16658    |\n",
      "|    total_timesteps | 1460000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1464     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16703    |\n",
      "|    total_timesteps | 1464000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.272    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2927792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1468     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16748    |\n",
      "|    total_timesteps | 1468000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.263    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2935792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1472     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16793    |\n",
      "|    total_timesteps | 1472000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.23     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2943792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1476     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16838    |\n",
      "|    total_timesteps | 1476000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.239    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2951792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=3010.92 +/- 17.01\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3.01e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1480000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.315    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2959792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1480     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16884    |\n",
      "|    total_timesteps | 1480000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1484     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16931    |\n",
      "|    total_timesteps | 1484000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.357    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2967792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1488     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16976    |\n",
      "|    total_timesteps | 1488000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.299    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2975792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1492     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 17022    |\n",
      "|    total_timesteps | 1492000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.266    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2983792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1496     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 17068    |\n",
      "|    total_timesteps | 1496000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.254    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2991792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=2962.79 +/- 11.86\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1500000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.275    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2999792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1500     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 17115    |\n",
      "|    total_timesteps | 1500000  |\n",
      "---------------------------------\n",
      "Mean Reward: -1071.18 ± 14.97\n"
     ]
    }
   ],
   "source": [
    "# Numero di ambienti paralleli per il training\n",
    "NUM_ENVS = 4\n",
    "\n",
    "# Wrapper personalizzato per la ricompensa modificata\n",
    "class CustomRewardWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.cappottato_start_time = None\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        \n",
    "        torso_angle = self.env.unwrapped.data.qpos[2]\n",
    "        \n",
    "        if torso_angle < -0.7:\n",
    "            if self.cappottato_start_time is None:\n",
    "                self.cappottato_start_time = time.time()\n",
    "            tempo_cappottato = time.time() - self.cappottato_start_time\n",
    "            penalty = 50 * tempo_cappottato\n",
    "            reward -= penalty\n",
    "        else:\n",
    "            self.cappottato_start_time = None\n",
    "        \n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "# Funzione per creare l'ambiente\n",
    "\n",
    "def make_env():\n",
    "    def _init():\n",
    "        env = gym.make(\"HalfCheetah-v5\",\n",
    "                        reset_noise_scale=0.13635555699602933,\n",
    "                        forward_reward_weight=0.7151140526343989,\n",
    "                        ctrl_cost_weight=0.19342622590821706)\n",
    "        env = Monitor(env)\n",
    "        env = CustomRewardWrapper(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Creazione degli ambienti per il training\n",
    "env = SubprocVecEnv([make_env() for _ in range(NUM_ENVS)])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
    "\n",
    "# Selezione automatica del device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Parametri del modello SAC\n",
    "model_params = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": env,\n",
    "    \"learning_rate\": 4.3539588088977104e-05,\n",
    "    \"buffer_size\": 500000,\n",
    "    \"batch_size\": 256,\n",
    "    \"tau\": 0.013929154106819306,\n",
    "    \"gamma\": 0.9843911115842067,\n",
    "    \"train_freq\": 1,\n",
    "    \"gradient_steps\": 8,\n",
    "    \"ent_coef\": 0.001,\n",
    "    \"verbose\": 1,\n",
    "    \"tensorboard_log\": \"./sac_HalfCheetah_tensorboard/\",\n",
    "    \"device\": device,\n",
    "    \"policy_kwargs\": dict(net_arch=[256, 256, 128])\n",
    "}\n",
    "\n",
    "# Creazione dell'ambiente di valutazione\n",
    "eval_env = DummyVecEnv([make_env()])\n",
    "eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=False, clip_obs=10., training=False)\n",
    "\n",
    "# Callback per valutazione e salvataggi\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs/best_model\",\n",
    "                             log_path=\"./logs/\", eval_freq=5000, deterministic=True, render=False)\n",
    "checkpoint_callback = CheckpointCallback(save_freq=5000, save_path=\"./logs/checkpoints/\",\n",
    "                                         name_prefix=\"sac_halfcheetah_checkpoint\")\n",
    "\n",
    "# Creazione e training del modello\n",
    "model = SAC(**model_params)\n",
    "model.learn(total_timesteps=1_500_000, callback=CallbackList([eval_callback, checkpoint_callback]))\n",
    "\n",
    "# Salvataggio del modello e normalizzazione\n",
    "model.save(\"sac_HalfCheetah_model\")\n",
    "env.save(\"vecnormalize_HalfCheetah.pkl\")\n",
    "\n",
    "# Caricamento del modello e della normalizzazione per la valutazione\n",
    "model = SAC.load(\"sac_HalfCheetah_model\", device=device)\n",
    "eval_env = VecNormalize.load(\"vecnormalize_HalfCheetah.pkl\", eval_env)\n",
    "eval_env.training = False\n",
    "eval_env.reset()\n",
    "\n",
    "# Funzione per la valutazione\n",
    "def evaluate_agent(model, env, episodes=100):\n",
    "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=episodes, deterministic=True)\n",
    "    print(f\"Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "# Valutazione del modello allenato\n",
    "mean_reward_trained, std_reward_trained = evaluate_agent(model, eval_env, episodes=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Salviamo il modello\n",
    "model.save(\"sac_HalfCheetah_model\")\n",
    "env.save(\"vecnormalize_HalfCheetah.pkl\")    # salviamo anche i parametri di normalizzazione\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
