{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Training completo tra 5mln a 10mln di TimeStamp e tra 5000 e 10000 episodi\n",
    "\n",
    "-Per un tuning rapido da 500k a 1mln di TimeStamp e tra 500 a 1k episodi per trial (consigliati 500 trial)\n",
    "\n",
    "-Per i test preliminari 1mln di timestamp e 1k/2k episodi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CHAT con search dice che per il train vanno bene anche 1mln di timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import HParam\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParamCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Saves the hyperparameters and metrics at the start of the training, and logs them to TensorBoard.\n",
    "    \"\"\"\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        hparam_dict = {\n",
    "            \"algorithm\": self.model.__class__.__name__,\n",
    "            \"learning rate\": self.model.learning_rate,\n",
    "            \"gamma\": self.model.gamma,\n",
    "        }\n",
    "        # define the metrics that will appear in the `HPARAMS` Tensorboard tab by referencing their tag\n",
    "        # Tensorbaord will find & display metrics from the `SCALARS` tab\n",
    "        metric_dict = {\n",
    "            #\"rollout/ep_len_mean\": 0,\n",
    "            #\"train/value_loss\": 0.0,\n",
    "        }\n",
    "        self.logger.record(\n",
    "            \"hparams\",\n",
    "            HParam(hparam_dict, metric_dict),\n",
    "            exclude=(\"stdout\", \"log\", \"json\", \"csv\"),\n",
    "        )\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEST_1 (PPO_4) -> {'reset_noise_scale': 0.16872520546404454, 'forward_reward_weight': 0.569165596187308, 'ctrl_cost_weight': 0.15369909636721105, 'healthy_reward': 1.1651483169773327, 'learning_rate': 0.00025118614395972893, 'n_steps': 4096, 'batch_size': 256, 'gamma': 0.9900195327210904, 'gae_lambda': 0.8063306496367846, 'clip_range': 0.1411162146550987, 'ent_coef': 0.006226601057899701, 'variance_penalty_weight': 0.0007310600475679448}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ipreparametri dell'envrionment\n",
    "hp_reset_noise_scale=0.10405074414945424 # scala del rumore quando l'ambiente viene resettato \n",
    "hp_forward_reward_weight=0.5940601384640877 # peso del reward per il movimento in avanti\n",
    "hp_ctrl_cost_weight=0.14771040407991193 # peso del reward per il controllo\n",
    "hp_healthy_reward =1.4039427670916238 # reward per la salute\n",
    "\n",
    "\n",
    "# Iperparametri del modello/policy\n",
    "hp_policy=\"MlpPolicy\"           # Tipo di policy: una rete neurale MLP (Multilayer Perceptron) che mappa osservazioni ad azioni\n",
    "hp_learning_rate=0.00014010166026390974           # Tasso di apprendimento: controlla la velocità con cui il modello apprende aggiornando i pesi\n",
    "hp_n_steps=4096                 # Numero di passi da eseguire nell'ambiente per ogni ciclo di aggiornamento della policy\n",
    "hp_batch_size=64                # Dimensione del batch per gli aggiornamenti stocastici: suddivide i dati raccolti nei mini-batch\n",
    "hp_n_epochs=10                  # Numero di volte (epoch) che il dataset raccolto viene utilizzato per aggiornare la policy\n",
    "hp_gamma=0.9974446213345484      # Fattore di sconto: determina l'importanza delle ricompense future rispetto a quelle immediate\n",
    "hp_gae_lambda=0.8025419607496327              # Parametro per il Generalized Advantage Estimation (GAE): bilancia bias e varianza nella stima dell'advantage\n",
    "hp_clip_range=0.16218657788555388               # Intervallo di clipping: limita le variazioni della policy per mantenere aggiornamenti stabili\n",
    "hp_ent_coef=0.00017603718662988996                 # Coefficiente di entropia: controlla l'incentivo all'esplorazione; 0 significa nessun bonus per l'entropia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    \"\"\"\n",
    "    Crea e restituisce l'ambiente Ant-v5 dalla libreria Gymnasium.\n",
    "\n",
    "    Questa funzione istanzia l'ambiente \"Ant-v5\", uno degli ambienti recenti e ben supportati\n",
    "    in Gymnasium. I parametri usati sono:\n",
    "    - reset_noise_scale (0.1): determina la scala del rumore quando l'ambiente viene resettato.\n",
    "    - render_mode ('None'): indica che non verrà effettuato il rendering durante l'esecuzione.\n",
    "\n",
    "    Ritorna:\n",
    "        gym.Env: l'ambiente Ant-v5 inizializzato.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ant-v5 è l’ambiente più recente in Gymnasium.\n",
    "    return gym.make(\"Ant-v5\", \n",
    "                    reset_noise_scale=hp_reset_noise_scale, # scala del rumore quando l'ambiente viene resettato \n",
    "                    forward_reward_weight=hp_forward_reward_weight, # peso del reward per il movimento in avanti\n",
    "                    ctrl_cost_weight=hp_ctrl_cost_weight, # peso del reward per il controllo\n",
    "                    healthy_reward =hp_healthy_reward, # reward per la salute\n",
    "                    render_mode='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ignazioemanuelepicciche/Documents/Ignazio PC/ucbm/deep_learning/Reinforcement_Learning_MuJoCu/.venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Creiamo un ambiente vettorializzato (Vectorized Environment)\n",
    "# Utilizziamo DummyVecEnv per gestire più istanze dell'ambiente come se fossero una singola entità.\n",
    "# Qui passiamo la funzione make_env (definita in un'altra cella) che crea l'ambiente \"Ant-v5\".\n",
    "env = DummyVecEnv([make_env])  \n",
    "\n",
    "# 2. Normalizziamo osservazioni (obs) e ricompense (reward)\n",
    "# VecNormalize scala le osservazioni e le ricompense per stabilizzare l'allenamento.\n",
    "# Parametri:\n",
    "#   norm_obs=True   -> Abilita la normalizzazione delle osservazioni.\n",
    "#   norm_reward=True -> Abilita la normalizzazione delle ricompense.\n",
    "#   clip_obs=10.     -> Limita i valori normalizzati dell'osservazione a un range [-10, 10] per evitare estremi.\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ignazioemanuelepicciche/Documents/Ignazio PC/ucbm/deep_learning/Reinforcement_Learning_MuJoCu/.venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. Definiamo il modello RL (PPO) con spiegazioni dettagliate per ciascun parametro\n",
    "\n",
    "model = PPO(\n",
    "    policy=hp_policy,           # Tipo di policy: una rete neurale MLP (Multilayer Perceptron) che mappa osservazioni ad azioni\n",
    "    env=env,                      # Ambiente di addestramento: usa l'ambiente vettorializzato e normalizzato creato in precedenza\n",
    "    learning_rate=hp_learning_rate,           # Tasso di apprendimento: controlla la velocità con cui il modello apprende aggiornando i pesi\n",
    "    n_steps=hp_n_steps,                 # Numero di passi da eseguire nell'ambiente per ogni ciclo di aggiornamento della policy\n",
    "    batch_size=hp_batch_size,                # Dimensione del batch per gli aggiornamenti stocastici: suddivide i dati raccolti nei mini-batch\n",
    "    n_epochs=hp_n_epochs,                  # Numero di volte (epoch) che il dataset raccolto viene utilizzato per aggiornare la policy\n",
    "    gamma=hp_gamma,      # Fattore di sconto: determina l'importanza delle ricompense future rispetto a quelle immediate\n",
    "    gae_lambda=hp_gae_lambda,              # Parametro per il Generalized Advantage Estimation (GAE): bilancia bias e varianza nella stima dell'advantage\n",
    "    clip_range=hp_clip_range,               # Intervallo di clipping: limita le variazioni della policy per mantenere aggiornamenti stabili\n",
    "    ent_coef=hp_ent_coef,                 # Coefficiente di entropia: controlla l'incentivo all'esplorazione; 0 significa nessun bonus per l'entropia\n",
    "    verbose=1,                    # Livello di verbosità: 1 per stampare informazioni di log utili durante l'addestramento\n",
    "    tensorboard_log=\"./ppo_Ant_tensorboard/\",  # Cartella per salvare i log di TensorBoard\n",
    "    device='mps'                    # Specifica l'uso della GPU su Apple Silicon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = DummyVecEnv([make_env])\n",
    "eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=True, clip_obs=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/best_model\",\n",
    "    log_path=\"./logs/\",\n",
    "    eval_freq=10000,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3030120753.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[163], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.learn(total_timesteps=total_timesteps callback=eval_callback)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# 4. Alleniamo il modello\n",
    "# Il parametro total_timesteps indica il numero totale di iterazioni (o passi)\n",
    "# che il modello eseguirà durante l'allenamento. Ogni timestep rappresenta un'interazione\n",
    "# con l'ambiente in cui il modello esegue un'azione e riceve un feedback, che viene poi\n",
    "# usato per aggiornare la sua politica interna.\n",
    "total_timesteps = 1000000  # Puoi aumentare questo valore per permettere al modello di acquisire più esperienza.\n",
    "model.learn(total_timesteps=total_timesteps, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Salviamo il modello\n",
    "model.save(\"ppo_Ant_model\")\n",
    "env.save(\"vecnormalize_Ant.pkl\")  # salviamo anche i parametri di normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200-400 episodi sono adeguati \n",
    "def evaluate_policy(env, policy, episodes=500):\n",
    "    \"\"\"\n",
    "    Valuta una policy addestrata su un ambiente dato.\n",
    "\n",
    "    Parametri:\n",
    "    - env: L'ambiente di simulazione.\n",
    "    - policy: La policy addestrata da valutare.\n",
    "    - episodes: Numero di episodi da eseguire per la valutazione.\n",
    "\n",
    "    Ritorna:\n",
    "    - La ricompensa media e la deviazione standard delle ricompense ottenute.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs = env.reset()  # Reset dell'ambiente per iniziare un nuovo episodio\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action, _ = policy.predict(obs)  # Predice l'azione da eseguire\n",
    "            obs, reward, done, _ = env.step(action)  # Esegue l'azione e ottiene il feedback dall'ambiente\n",
    "            total_reward += reward  # Accumula la ricompensa ottenuta\n",
    "        total_rewards.append(total_reward)  # Aggiunge la ricompensa totale dell'episodio alla lista\n",
    "    return np.mean(total_rewards), np.std(total_rewards)  # Calcola e ritorna la media e la deviazione standard delle ricompense\n",
    "\n",
    "# 200-400 episodi sono adeguati \n",
    "def evaluate_random_policy(env, episodes=500):\n",
    "    \"\"\"\n",
    "    Valuta una policy casuale su un ambiente dato.\n",
    "\n",
    "    Parametri:\n",
    "    - env: L'ambiente di simulazione.\n",
    "    - episodes: Numero di episodi da eseguire per la valutazione.\n",
    "\n",
    "    Ritorna:\n",
    "    - La ricompensa media e la deviazione standard delle ricompense ottenute.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs = env.reset()  # Reset dell'ambiente per iniziare un nuovo episodio\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action = env.action_space.sample()  # Genera un'azione casuale\n",
    "            obs, reward, done, _ = env.step(np.array([action]))  # Esegue l'azione e ottiene il feedback dall'ambiente\n",
    "            total_reward += reward  # Accumula la ricompensa ottenuta\n",
    "        total_rewards.append(total_reward)  # Aggiunge la ricompensa totale dell'episodio alla lista\n",
    "    return np.mean(total_rewards), np.std(total_rewards)  # Calcola e ritorna la media e la deviazione standard delle ricompense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Policy: Mean Reward: 2.74877667427063, Std: 6.1324005126953125\n",
      "Random Policy: Mean Reward: 5.563947677612305, Std: 9.290725708007812\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Valutazione dopo l'addestramento\n",
    "mean_reward_trained, std_reward_trained = evaluate_policy(env, model)  # Valuta la policy addestrata\n",
    "mean_reward_random, std_reward_random = evaluate_random_policy(env)  # Valuta la policy casuale\n",
    "\n",
    "# Stampa dei risultati\n",
    "print(f\"Trained Policy: Mean Reward: {mean_reward_trained}, Std: {std_reward_trained}\")\n",
    "print(f\"Random Policy: Mean Reward: {mean_reward_random}, Std: {std_reward_random}\")\n",
    "\n",
    "# Creazione del grafico di confronto\n",
    "labels = ['Random Policy', 'Trained Policy']\n",
    "means = [mean_reward_random, mean_reward_trained]\n",
    "stds = [std_reward_random, std_reward_trained]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, means, yerr=stds, capsize=10, color=['skyblue', 'lightgreen'])\n",
    "plt.ylabel('Mean Episodic Reward')\n",
    "plt.title('Policy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
