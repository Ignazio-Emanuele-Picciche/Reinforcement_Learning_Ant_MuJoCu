{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Training completo tra 5mln a 10mln di TimeStamp e tra 5000 e 10000 episodi\n",
    "\n",
    "-Per un tuning rapido da 500k a 1mln di TimeStamp e tra 500 a 1k episodi per trial (consigliati 500 trial)\n",
    "\n",
    "-Per i test preliminari 1mln di timestamp e 1k/2k episodi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CHAT con search dice che per il train vanno bene anche 1mln di timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import HParam\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParamCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Saves the hyperparameters and metrics at the start of the training, and logs them to TensorBoard.\n",
    "    \"\"\"\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        hparam_dict = {\n",
    "            \"algorithm\": self.model.__class__.__name__,\n",
    "            \"learning rate\": self.model.learning_rate,\n",
    "            \"gamma\": self.model.gamma,\n",
    "        }\n",
    "        # define the metrics that will appear in the `HPARAMS` Tensorboard tab by referencing their tag\n",
    "        # Tensorbaord will find & display metrics from the `SCALARS` tab\n",
    "        metric_dict = {\n",
    "            #\"rollout/ep_len_mean\": 0,\n",
    "            #\"train/value_loss\": 0.0,\n",
    "        }\n",
    "        self.logger.record(\n",
    "            \"hparams\",\n",
    "            HParam(hparam_dict, metric_dict),\n",
    "            exclude=(\"stdout\", \"log\", \"json\", \"csv\"),\n",
    "        )\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEST_1 (PPO_4) -> {'reset_noise_scale': 0.16872520546404454, 'forward_reward_weight': 0.569165596187308, 'ctrl_cost_weight': 0.15369909636721105, 'healthy_reward': 1.1651483169773327, 'learning_rate': 0.00025118614395972893, 'n_steps': 4096, 'batch_size': 256, 'gamma': 0.9900195327210904, 'gae_lambda': 0.8063306496367846, 'clip_range': 0.1411162146550987, 'ent_coef': 0.006226601057899701, 'variance_penalty_weight': 0.0007310600475679448}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEST_2 (PPO_6) -> \n",
    "\n",
    "hp_reset_noise_scale=0.10405074414945424 # scala del rumore quando l'ambiente viene resettato \n",
    "\n",
    "hp_forward_reward_weight=0.5940601384640877 # peso del reward per il movimento in avanti\n",
    "\n",
    "hp_ctrl_cost_weight=0.14771040407991193 # peso del reward per il controllo\n",
    "\n",
    "hp_healthy_reward =1.4039427670916238 # reward per la salute\n",
    "\n",
    "\n",
    "hp_policy=\"MlpPolicy\"           # Tipo di policy: una rete neurale MLP (Multilayer Perceptron) che mappa osservazioni ad azioni\n",
    "\n",
    "hp_learning_rate=0.00014010166026390974           # Tasso di apprendimento: controlla la velocità con cui il modello apprende aggiornando i pesi\n",
    "\n",
    "hp_n_steps=4096                 # Numero di passi da eseguire nell'ambiente per ogni ciclo di aggiornamento della policy\n",
    "\n",
    "hp_batch_size=64                # Dimensione del batch per gli aggiornamenti stocastici: suddivide i dati raccolti nei mini-batch\n",
    "\n",
    "hp_n_epochs=10                  # Numero di volte (epoch) che il dataset raccolto viene utilizzato per aggiornare la policy\n",
    "\n",
    "hp_gamma=0.9974446213345484      # Fattore di sconto: determina l'importanza delle ricompense future rispetto a quelle immediate\n",
    "\n",
    "hp_gae_lambda=0.8025419607496327              # Parametro per il Generalized Advantage Estimation (GAE): bilancia bias e varianza nella stima dell'advantage\n",
    "\n",
    "hp_clip_range=0.16218657788555388               # Intervallo di clipping: limita le variazioni della policy per mantenere aggiornamenti stabili\n",
    "\n",
    "hp_ent_coef=0.00017603718662988996                 # Coefficiente di entropia: controlla l'incentivo all'esplorazione; 0 significa nessun bonus per l'entropia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO_7 {'reset_noise_scale': 0.16260110616284057, 'forward_reward_weight': 0.6594701821995568, 'ctrl_cost_weight': 0.13678469591501632, 'healthy_reward': 1.4384387807236847, 'contact_cost_weight': 0.0007721118603343064, 'healthy_z_lower': 0.11270460095319094, 'healthy_z_upper': 1.1367622027728483, 'contact_force_min': -0.8099290655891269, 'contact_force_max': 0.7683440461793597, 'learning_rate': 0.0001620494220647337, 'n_steps': 4096, 'batch_size': 64, 'gamma': 0.9960403688730154, 'gae_lambda': 0.8519055821923104, 'clip_range': 0.28172421812629234, 'ent_coef': 0.015960745859518122, 'variance_penalty_weight': 0.011924537413547313}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO_8 -> {'reset_noise_scale': 0.14953307712823055, 'forward_reward_weight': 0.5971580841907844, 'ctrl_cost_weight': 0.21085190913852067, 'healthy_reward': 1.3432502908397173, 'contact_cost_weight': 0.0006565424645557624, 'healthy_z_lower': 0.11576255546554826, 'healthy_z_upper': 1.0657755912005253, 'contact_force_min': -0.7947792512332761, 'contact_force_max': 0.7599774107257553, 'learning_rate': 0.0001417417141818677, 'n_steps': 4096, 'batch_size': 64, 'gamma': 0.9977321276628237, 'gae_lambda': 0.8135998374897728, 'clip_range': 0.2502648636777115, 'ent_coef': 0.006686448422595028, 'variance_penalty_weight': 0.0008985044453683972}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO_9 -> {'reset_noise_scale': 0.1224648700491494, 'forward_reward_weight': 1.0798217517026751, 'ctrl_cost_weight': 0.2788960190947023, 'healthy_reward': 1.4972086156641724, 'contact_cost_weight': 0.00019495257535118138, 'healthy_z_lower': 0.10525289571959973, 'healthy_z_upper': 1.1803240798353063, 'contact_force_min': -0.5187992701613672, 'contact_force_max': 0.5870857431066443, 'learning_rate': 0.000983439712869658, 'n_steps': 2048, 'batch_size': 512, 'gamma': 0.9686135698396399, 'gae_lambda': 0.9145395422692033, 'clip_range': 0.37757085535729756, 'ent_coef': 0.00017055556769922042, 'std_penalty_weight': 0.28813167612676016}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO_10 -> {'reset_noise_scale': 0.0811219889284557, 'forward_reward_weight': 0.794019967338759, 'ctrl_cost_weight': 0.1909084649203593, 'healthy_reward': 1.4695470159426132, 'contact_cost_weight': 0.00048075670076003045, 'healthy_z_lower': 0.19353492629665098, 'healthy_z_upper': 1.1936905952567158, 'contact_force_min': -0.5349939620294489, 'contact_force_max': 0.7307512698224117, 'learning_rate': 0.0003564760563058714, 'n_steps': 2048, 'batch_size': 512, 'gamma': 0.9762294172462653, 'gae_lambda': 0.9261117656360015, 'clip_range': 0.3320669028429513, 'ent_coef': 0.0026780011357637598, 'std_penalty_weight': 0.20050838533111062}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ipreparametri dell'envrionment\n",
    "hp_reset_noise_scale= 0.0811219889284557 # scala del rumore quando l'ambiente viene resettato \n",
    "hp_forward_reward_weight = 0.794019967338759 # peso del reward per il movimento in avanti\n",
    "hp_ctrl_cost_weight = 0.1909084649203593 # peso del reward per il controllo\n",
    "hp_healthy_reward = 1.4695470159426132 # reward per la salute\n",
    "\n",
    "hp_contact_cost_weight = 0.00048075670076003045\n",
    "healthy_z = (0.19353492629665098, 1.1936905952567158)\n",
    "contact_force = (-0.5349939620294489, 0.7307512698224117)\n",
    "\n",
    "\n",
    "# Iperparametri del modello/policy\n",
    "hp_policy=\"MlpPolicy\"           # Tipo di policy: una rete neurale MLP (Multilayer Perceptron) che mappa osservazioni ad azioni\n",
    "hp_learning_rate=0.0003564760563058714           # Tasso di apprendimento: controlla la velocità con cui il modello apprende aggiornando i pesi\n",
    "hp_n_steps=2048                 # Numero di passi da eseguire nell'ambiente per ogni ciclo di aggiornamento della policy\n",
    "hp_batch_size=512                # Dimensione del batch per gli aggiornamenti stocastici: suddivide i dati raccolti nei mini-batch\n",
    "hp_n_epochs=6                  # Numero di volte (epoch) che il dataset raccolto viene utilizzato per aggiornare la policy\n",
    "hp_gamma=0.9762294172462653      # Fattore di sconto: determina l'importanza delle ricompense future rispetto a quelle immediate\n",
    "hp_gae_lambda=0.9261117656360015              # Parametro per il Generalized Advantage Estimation (GAE): bilancia bias e varianza nella stima dell'advantage\n",
    "hp_clip_range=0.3320669028429513               # Intervallo di clipping: limita le variazioni della policy per mantenere aggiornamenti stabili\n",
    "hp_ent_coef=0.0026780011357637598                 # Coefficiente di entropia: controlla l'incentivo all'esplorazione; 0 significa nessun bonus per l'entropia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    \"\"\"\n",
    "    Crea e restituisce l'ambiente Ant-v5 dalla libreria Gymnasium.\n",
    "\n",
    "    Questa funzione istanzia l'ambiente \"Ant-v5\", uno degli ambienti recenti e ben supportati\n",
    "    in Gymnasium. I parametri usati sono:\n",
    "    - reset_noise_scale (0.1): determina la scala del rumore quando l'ambiente viene resettato.\n",
    "    - render_mode ('None'): indica che non verrà effettuato il rendering durante l'esecuzione.\n",
    "\n",
    "    Ritorna:\n",
    "        gym.Env: l'ambiente Ant-v5 inizializzato.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ant-v5 è l’ambiente più recente in Gymnasium.\n",
    "    return gym.make(\"Ant-v5\", \n",
    "                    reset_noise_scale=hp_reset_noise_scale, # scala del rumore quando l'ambiente viene resettato \n",
    "                    forward_reward_weight=hp_forward_reward_weight, # peso del reward per il movimento in avanti\n",
    "                    ctrl_cost_weight=hp_ctrl_cost_weight, # peso del reward per il controllo\n",
    "                    healthy_reward =hp_healthy_reward, # reward per la salute\n",
    "                    contact_cost_weight=hp_contact_cost_weight,\n",
    "                    healthy_z_range=healthy_z,\n",
    "                    contact_force_range=contact_force,\n",
    "                    render_mode='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ignazioemanuelepicciche/Documents/Ignazio PC/ucbm/deep_learning/Reinforcement_Learning_MuJoCu/.venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Creiamo un ambiente vettorializzato (Vectorized Environment)\n",
    "# Utilizziamo DummyVecEnv per gestire più istanze dell'ambiente come se fossero una singola entità.\n",
    "# Qui passiamo la funzione make_env (definita in un'altra cella) che crea l'ambiente \"Ant-v5\".\n",
    "env = DummyVecEnv([make_env])  \n",
    "\n",
    "# 2. Normalizziamo osservazioni (obs) e ricompense (reward)\n",
    "# VecNormalize scala le osservazioni e le ricompense per stabilizzare l'allenamento.\n",
    "# Parametri:\n",
    "#   norm_obs=True   -> Abilita la normalizzazione delle osservazioni.\n",
    "#   norm_reward=True -> Abilita la normalizzazione delle ricompense.\n",
    "#   clip_obs=10.     -> Limita i valori normalizzati dell'osservazione a un range [-10, 10] per evitare estremi.\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ignazioemanuelepicciche/Documents/Ignazio PC/ucbm/deep_learning/Reinforcement_Learning_MuJoCu/.venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. Definiamo il modello RL (PPO) con spiegazioni dettagliate per ciascun parametro\n",
    "\n",
    "model = PPO(\n",
    "    policy=hp_policy,           # Tipo di policy: una rete neurale MLP (Multilayer Perceptron) che mappa osservazioni ad azioni\n",
    "    env=env,                      # Ambiente di addestramento: usa l'ambiente vettorializzato e normalizzato creato in precedenza\n",
    "    learning_rate=hp_learning_rate,           # Tasso di apprendimento: controlla la velocità con cui il modello apprende aggiornando i pesi\n",
    "    n_steps=hp_n_steps,                 # Numero di passi da eseguire nell'ambiente per ogni ciclo di aggiornamento della policy\n",
    "    batch_size=hp_batch_size,                # Dimensione del batch per gli aggiornamenti stocastici: suddivide i dati raccolti nei mini-batch\n",
    "    n_epochs=hp_n_epochs,                  # Numero di volte (epoch) che il dataset raccolto viene utilizzato per aggiornare la policy\n",
    "    gamma=hp_gamma,      # Fattore di sconto: determina l'importanza delle ricompense future rispetto a quelle immediate\n",
    "    gae_lambda=hp_gae_lambda,              # Parametro per il Generalized Advantage Estimation (GAE): bilancia bias e varianza nella stima dell'advantage\n",
    "    clip_range=hp_clip_range,               # Intervallo di clipping: limita le variazioni della policy per mantenere aggiornamenti stabili\n",
    "    ent_coef=hp_ent_coef,                 # Coefficiente di entropia: controlla l'incentivo all'esplorazione; 0 significa nessun bonus per l'entropia\n",
    "    seed=42,                        # Seed per la riproducibilità\n",
    "    verbose=1,                    # Livello di verbosità: 1 per stampare informazioni di log utili durante l'addestramento\n",
    "    tensorboard_log=\"./ppo_Ant_tensorboard/\",  # Cartella per salvare i log di TensorBoard\n",
    "    device='mps'                    # Specifica l'uso della GPU su Apple Silicon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ignazioemanuelepicciche/Documents/Ignazio PC/ucbm/deep_learning/Reinforcement_Learning_MuJoCu/.venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "eval_env = DummyVecEnv([make_env])\n",
    "eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=True, clip_obs=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./logs/best_model\",\n",
    "    log_path=\"./logs/\",\n",
    "    eval_freq=10000,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_Ant_tensorboard/PPO_10\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 364  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 5    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 339          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029149135 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -0.91        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | 0.0567       |\n",
      "|    n_updates            | 6            |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.501        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 337          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023357254 |\n",
      "|    clip_fraction        | 0.000163     |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -1.56        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | 0.0122       |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 0.222        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021232157 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -0.413       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | 0.00826      |\n",
      "|    n_updates            | 18           |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 0.195        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ignazioemanuelepicciche/Documents/Ignazio PC/ucbm/deep_learning/Reinforcement_Learning_MuJoCu/.venv/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=45.97 +/- 10.41\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 46           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023700937 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -1.91        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.00328     |\n",
      "|    n_updates            | 24           |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 0.138        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 280   |\n",
      "|    iterations      | 5     |\n",
      "|    time_elapsed    | 36    |\n",
      "|    total_timesteps | 10240 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024921605 |\n",
      "|    clip_fraction        | 0.000407     |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -0.947       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0239      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 0.114        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 295          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027821036 |\n",
      "|    clip_fraction        | 0.00057      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.3        |\n",
      "|    explained_variance   | -1.73        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0206      |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 0.123        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 300          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036508786 |\n",
      "|    clip_fraction        | 0.000651     |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.2        |\n",
      "|    explained_variance   | -0.317       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0261      |\n",
      "|    n_updates            | 42           |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 0.111        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004225884 |\n",
      "|    clip_fraction        | 0.00106     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.427      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0361     |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=51.84 +/- 9.11\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003946094 |\n",
      "|    clip_fraction        | 0.0013      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.918      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0321     |\n",
      "|    n_updates            | 54          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 0.0868      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 277   |\n",
      "|    iterations      | 10    |\n",
      "|    time_elapsed    | 73    |\n",
      "|    total_timesteps | 20480 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045924815 |\n",
      "|    clip_fraction        | 0.00187      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.2        |\n",
      "|    explained_variance   | -0.46        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0451      |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 0.0674       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038684001 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.2        |\n",
      "|    explained_variance   | -0.0296      |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0517      |\n",
      "|    n_updates            | 66           |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 0.0682       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004118368 |\n",
      "|    clip_fraction        | 0.00236     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.689      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0436     |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 0.0694      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 295          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042263074 |\n",
      "|    clip_fraction        | 0.00236      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.2        |\n",
      "|    explained_variance   | -0.773       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0487      |\n",
      "|    n_updates            | 78           |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 0.0517       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=55.08 +/- 7.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004700834 |\n",
      "|    clip_fraction        | 0.00228     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0334     |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 278   |\n",
      "|    iterations      | 15    |\n",
      "|    time_elapsed    | 110   |\n",
      "|    total_timesteps | 30720 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048618317 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 0.0934       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0426      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 0.0871       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054801973 |\n",
      "|    clip_fraction        | 0.00301      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | -0.177       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0478      |\n",
      "|    n_updates            | 96           |\n",
      "|    policy_gradient_loss | -0.0191      |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 0.0494       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005321088 |\n",
      "|    clip_fraction        | 0.00309     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | -0.247      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0449     |\n",
      "|    n_updates            | 102         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 0.0552      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 294          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061785197 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11.1        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0313      |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 0.0733       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=56.17 +/- 6.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 56.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050386405 |\n",
      "|    clip_fraction        | 0.00163      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0417      |\n",
      "|    n_updates            | 114          |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 0.069        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 282   |\n",
      "|    iterations      | 20    |\n",
      "|    time_elapsed    | 144   |\n",
      "|    total_timesteps | 40960 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 285          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076727094 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0398      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0199      |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 0.0859       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077103693 |\n",
      "|    clip_fraction        | 0.00431      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0533      |\n",
      "|    n_updates            | 126          |\n",
      "|    policy_gradient_loss | -0.02        |\n",
      "|    std                  | 0.96         |\n",
      "|    value_loss           | 0.0615       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008122064 |\n",
      "|    clip_fraction        | 0.00627     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.044      |\n",
      "|    n_updates            | 132         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 0.0663      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007395821 |\n",
      "|    clip_fraction        | 0.00407     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0514     |\n",
      "|    n_updates            | 138         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 0.957       |\n",
      "|    value_loss           | 0.0605      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=55.74 +/- 4.86\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007950201 |\n",
      "|    clip_fraction        | 0.00358     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.07       |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 0.954       |\n",
      "|    value_loss           | 0.0387      |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 284   |\n",
      "|    iterations      | 25    |\n",
      "|    time_elapsed    | 180   |\n",
      "|    total_timesteps | 51200 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067053414 |\n",
      "|    clip_fraction        | 0.00431      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -11          |\n",
      "|    explained_variance   | -0.526       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0554      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0206      |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 0.0416       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005804075 |\n",
      "|    clip_fraction        | 0.0022      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | -0.227      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0592     |\n",
      "|    n_updates            | 156         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 0.0354      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006525289 |\n",
      "|    clip_fraction        | 0.0026      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0614     |\n",
      "|    n_updates            | 162         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 0.941       |\n",
      "|    value_loss           | 0.0462      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006996431 |\n",
      "|    clip_fraction        | 0.00342     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0735     |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 0.0426      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=57.50 +/- 5.22\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 57.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074883397 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -10.8        |\n",
      "|    explained_variance   | -0.734       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0622      |\n",
      "|    n_updates            | 174          |\n",
      "|    policy_gradient_loss | -0.0224      |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 0.0339       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 280   |\n",
      "|    iterations      | 30    |\n",
      "|    time_elapsed    | 218   |\n",
      "|    total_timesteps | 61440 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00605817 |\n",
      "|    clip_fraction        | 0.00228    |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -10.8      |\n",
      "|    explained_variance   | -0.309     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0739    |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    std                  | 0.933      |\n",
      "|    value_loss           | 0.0315     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006371971 |\n",
      "|    clip_fraction        | 0.00269     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.8       |\n",
      "|    explained_variance   | -0.219      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0653     |\n",
      "|    n_updates            | 186         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 0.0311      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072619775 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -10.7        |\n",
      "|    explained_variance   | -0.753       |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0667      |\n",
      "|    n_updates            | 192          |\n",
      "|    policy_gradient_loss | -0.0193      |\n",
      "|    std                  | 0.926        |\n",
      "|    value_loss           | 0.0277       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007684552 |\n",
      "|    clip_fraction        | 0.00439     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0526     |\n",
      "|    n_updates            | 198         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    std                  | 0.924       |\n",
      "|    value_loss           | 0.0373      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=59.92 +/- 4.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 59.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007950065 |\n",
      "|    clip_fraction        | 0.00439     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | -0.482      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0708     |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 0.0239      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 282   |\n",
      "|    iterations      | 35    |\n",
      "|    time_elapsed    | 253   |\n",
      "|    total_timesteps | 71680 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008199954 |\n",
      "|    clip_fraction        | 0.00594     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0562     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 0.0423      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009107597 |\n",
      "|    clip_fraction        | 0.0057      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0485     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 0.916       |\n",
      "|    value_loss           | 0.0684      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007982658 |\n",
      "|    clip_fraction        | 0.00529     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.00549     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0713     |\n",
      "|    n_updates            | 222         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 0.913       |\n",
      "|    value_loss           | 0.0318      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008686792 |\n",
      "|    clip_fraction        | 0.00529     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0521     |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 0.911       |\n",
      "|    value_loss           | 0.0462      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=59.28 +/- 4.07\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 59.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072067175 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -10.6        |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0407      |\n",
      "|    n_updates            | 234          |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    std                  | 0.908        |\n",
      "|    value_loss           | 0.0525       |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 283   |\n",
      "|    iterations      | 40    |\n",
      "|    time_elapsed    | 288   |\n",
      "|    total_timesteps | 81920 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008778362 |\n",
      "|    clip_fraction        | 0.00675     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | -0.195      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0729     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.0323      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009007984 |\n",
      "|    clip_fraction        | 0.0061      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0562     |\n",
      "|    n_updates            | 246         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 0.902       |\n",
      "|    value_loss           | 0.0538      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008942613 |\n",
      "|    clip_fraction        | 0.00586     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.00946     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.067      |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 0.897       |\n",
      "|    value_loss           | 0.0323      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=59.12 +/- 2.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 59.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008831038 |\n",
      "|    clip_fraction        | 0.0061      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0511     |\n",
      "|    n_updates            | 258         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 0.0388      |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 283   |\n",
      "|    iterations      | 44    |\n",
      "|    time_elapsed    | 318   |\n",
      "|    total_timesteps | 90112 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008817534 |\n",
      "|    clip_fraction        | 0.00708     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.4       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0634     |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 0.892       |\n",
      "|    value_loss           | 0.0256      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011382503 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.4       |\n",
      "|    explained_variance   | -0.828      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0733     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 0.0194      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010589408 |\n",
      "|    clip_fraction        | 0.00895     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.4       |\n",
      "|    explained_variance   | -0.57       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0799     |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    std                  | 0.885       |\n",
      "|    value_loss           | 0.0217      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 341        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00762677 |\n",
      "|    clip_fraction        | 0.00553    |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | -0.105     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.069     |\n",
      "|    n_updates            | 282        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    std                  | 0.883      |\n",
      "|    value_loss           | 0.0249     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=58.65 +/- 2.52\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 58.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009104159 |\n",
      "|    clip_fraction        | 0.00716     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0558     |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 0.0547      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 283    |\n",
      "|    iterations      | 49     |\n",
      "|    time_elapsed    | 354    |\n",
      "|    total_timesteps | 100352 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009877078 |\n",
      "|    clip_fraction        | 0.00936     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0698     |\n",
      "|    n_updates            | 294         |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 0.88        |\n",
      "|    value_loss           | 0.0383      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009778615 |\n",
      "|    clip_fraction        | 0.0083      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0735     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 0.0365      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 371         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008572272 |\n",
      "|    clip_fraction        | 0.00643     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0628     |\n",
      "|    n_updates            | 306         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 0.041       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012409378 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0638     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 0.877       |\n",
      "|    value_loss           | 0.0348      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=52.70 +/- 1.32\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 52.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010486495 |\n",
      "|    clip_fraction        | 0.00822     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.083       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0786     |\n",
      "|    n_updates            | 318         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 0.0189      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 283    |\n",
      "|    iterations      | 54     |\n",
      "|    time_elapsed    | 389    |\n",
      "|    total_timesteps | 110592 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009331519 |\n",
      "|    clip_fraction        | 0.00692     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.0169      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0767     |\n",
      "|    n_updates            | 324         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    std                  | 0.87        |\n",
      "|    value_loss           | 0.017       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010765886 |\n",
      "|    clip_fraction        | 0.00944     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | 0.0841      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0769     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011819163 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | -0.322      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0737     |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 0.0279      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008840873 |\n",
      "|    clip_fraction        | 0.00529     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0708     |\n",
      "|    n_updates            | 342         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=54.41 +/- 3.49\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 54.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011824104 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0737     |\n",
      "|    n_updates            | 348         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    std                  | 0.862       |\n",
      "|    value_loss           | 0.0336      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 284    |\n",
      "|    iterations      | 59     |\n",
      "|    time_elapsed    | 424    |\n",
      "|    total_timesteps | 120832 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012052896 |\n",
      "|    clip_fraction        | 0.00985     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0683     |\n",
      "|    n_updates            | 354         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 0.859       |\n",
      "|    value_loss           | 0.0335      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 435         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010826373 |\n",
      "|    clip_fraction        | 0.00863     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0635     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 0.0272      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 441         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011419303 |\n",
      "|    clip_fraction        | 0.00911     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | -0.103      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0793     |\n",
      "|    n_updates            | 366         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.0209      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010612644 |\n",
      "|    clip_fraction        | 0.00985     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | -0.153      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0838     |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 0.0204      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=55.77 +/- 2.14\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011876654 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.064      |\n",
      "|    n_updates            | 378         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 0.0369      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 285    |\n",
      "|    iterations      | 64     |\n",
      "|    time_elapsed    | 459    |\n",
      "|    total_timesteps | 131072 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010219473 |\n",
      "|    clip_fraction        | 0.00806     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -10         |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0628     |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 0.848       |\n",
      "|    value_loss           | 0.0257      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 469          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100142155 |\n",
      "|    clip_fraction        | 0.00814      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -10          |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0808      |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0247      |\n",
      "|    std                  | 0.845        |\n",
      "|    value_loss           | 0.0186       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011549877 |\n",
      "|    clip_fraction        | 0.00968     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.99       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0862     |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    std                  | 0.842       |\n",
      "|    value_loss           | 0.0154      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012029201 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.96       |\n",
      "|    explained_variance   | -0.403      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0773     |\n",
      "|    n_updates            | 402         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    std                  | 0.839       |\n",
      "|    value_loss           | 0.0262      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=55.48 +/- 2.69\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011698078 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.94       |\n",
      "|    explained_variance   | 0.0883      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0642     |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 0.837       |\n",
      "|    value_loss           | 0.0329      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 286    |\n",
      "|    iterations      | 69     |\n",
      "|    time_elapsed    | 493    |\n",
      "|    total_timesteps | 141312 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011098656 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.91       |\n",
      "|    explained_variance   | -0.242      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0782     |\n",
      "|    n_updates            | 414         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 0.0151      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 504        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01425283 |\n",
      "|    clip_fraction        | 0.0143     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -9.89      |\n",
      "|    explained_variance   | -0.161     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0949    |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    std                  | 0.832      |\n",
      "|    value_loss           | 0.0143     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 510         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010013284 |\n",
      "|    clip_fraction        | 0.00692     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.86       |\n",
      "|    explained_variance   | -0.214      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0701     |\n",
      "|    n_updates            | 426         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 0.828       |\n",
      "|    value_loss           | 0.0107      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016315721 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.82       |\n",
      "|    explained_variance   | -0.215      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0803     |\n",
      "|    n_updates            | 432         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    std                  | 0.824       |\n",
      "|    value_loss           | 0.0134      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=59.25 +/- 2.74\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 59.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013364768 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.79       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0705     |\n",
      "|    n_updates            | 438         |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    std                  | 0.822       |\n",
      "|    value_loss           | 0.0219      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 286    |\n",
      "|    iterations      | 74     |\n",
      "|    time_elapsed    | 529    |\n",
      "|    total_timesteps | 151552 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011916031 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.77       |\n",
      "|    explained_variance   | -0.145      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0664     |\n",
      "|    n_updates            | 444         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 0.82        |\n",
      "|    value_loss           | 0.0245      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013256088 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.74       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0773     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 0.0175      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011748165 |\n",
      "|    clip_fraction        | 0.01        |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.72       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0577     |\n",
      "|    n_updates            | 456         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 0.814       |\n",
      "|    value_loss           | 0.0373      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009907632 |\n",
      "|    clip_fraction        | 0.00741     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.69       |\n",
      "|    explained_variance   | -0.169      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0766     |\n",
      "|    n_updates            | 462         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    std                  | 0.812       |\n",
      "|    value_loss           | 0.0198      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=59.58 +/- 2.49\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 59.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012203723 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.67       |\n",
      "|    explained_variance   | 0.00049     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0767     |\n",
      "|    n_updates            | 468         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 0.809       |\n",
      "|    value_loss           | 0.0157      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 287    |\n",
      "|    iterations      | 79     |\n",
      "|    time_elapsed    | 562    |\n",
      "|    total_timesteps | 161792 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013313621 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.64       |\n",
      "|    explained_variance   | -0.15       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0851     |\n",
      "|    n_updates            | 474         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    std                  | 0.806       |\n",
      "|    value_loss           | 0.014       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 574        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01402711 |\n",
      "|    clip_fraction        | 0.016      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -9.6       |\n",
      "|    explained_variance   | 0.0743     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.062     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    std                  | 0.801      |\n",
      "|    value_loss           | 0.0147     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 579        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01063864 |\n",
      "|    clip_fraction        | 0.00911    |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -9.56      |\n",
      "|    explained_variance   | 0.11       |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0641    |\n",
      "|    n_updates            | 486        |\n",
      "|    policy_gradient_loss | -0.0244    |\n",
      "|    std                  | 0.798      |\n",
      "|    value_loss           | 0.0181     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 290          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 584          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116212545 |\n",
      "|    clip_fraction        | 0.00993      |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -9.53        |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0677      |\n",
      "|    n_updates            | 492          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    std                  | 0.796        |\n",
      "|    value_loss           | 0.0385       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=59.98 +/- 4.14\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 60           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 170000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141501585 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -9.51        |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.074       |\n",
      "|    n_updates            | 498          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    std                  | 0.794        |\n",
      "|    value_loss           | 0.0298       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 288    |\n",
      "|    iterations      | 84     |\n",
      "|    time_elapsed    | 597    |\n",
      "|    total_timesteps | 172032 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 602          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128356675 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -9.5         |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.0553      |\n",
      "|    n_updates            | 504          |\n",
      "|    policy_gradient_loss | -0.0249      |\n",
      "|    std                  | 0.793        |\n",
      "|    value_loss           | 0.0393       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 608         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009474485 |\n",
      "|    clip_fraction        | 0.00773     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.48       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0583     |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    std                  | 0.792       |\n",
      "|    value_loss           | 0.0349      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 614         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011094984 |\n",
      "|    clip_fraction        | 0.0092      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.47       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0525     |\n",
      "|    n_updates            | 516         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 0.789       |\n",
      "|    value_loss           | 0.0364      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=57.61 +/- 1.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 57.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013483528 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.44       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0608     |\n",
      "|    n_updates            | 522         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 0.786       |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 287    |\n",
      "|    iterations      | 88     |\n",
      "|    time_elapsed    | 627    |\n",
      "|    total_timesteps | 180224 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011809801 |\n",
      "|    clip_fraction        | 0.01        |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.41       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0763     |\n",
      "|    n_updates            | 528         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 0.782       |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 637        |\n",
      "|    total_timesteps      | 184320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01302033 |\n",
      "|    clip_fraction        | 0.0141     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -9.37      |\n",
      "|    explained_variance   | 0.218      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0739    |\n",
      "|    n_updates            | 534        |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    std                  | 0.78       |\n",
      "|    value_loss           | 0.0233     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014547776 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.35       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0889     |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 0.777       |\n",
      "|    value_loss           | 0.0167      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 650        |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01203186 |\n",
      "|    clip_fraction        | 0.0102     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -9.32      |\n",
      "|    explained_variance   | -0.139     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0669    |\n",
      "|    n_updates            | 546        |\n",
      "|    policy_gradient_loss | -0.0258    |\n",
      "|    std                  | 0.774      |\n",
      "|    value_loss           | 0.027      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=57.82 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 57.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014529712 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.29       |\n",
      "|    explained_variance   | -0.0822     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0774     |\n",
      "|    n_updates            | 552         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    std                  | 0.771       |\n",
      "|    value_loss           | 0.0181      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 287    |\n",
      "|    iterations      | 93     |\n",
      "|    time_elapsed    | 662    |\n",
      "|    total_timesteps | 190464 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 668         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011806966 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.26       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0737     |\n",
      "|    n_updates            | 558         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 0.769       |\n",
      "|    value_loss           | 0.0267      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012021795 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.23       |\n",
      "|    explained_variance   | -0.168      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0625     |\n",
      "|    n_updates            | 564         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 0.767       |\n",
      "|    value_loss           | 0.0196      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 679         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011632903 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.21       |\n",
      "|    explained_variance   | -0.0193     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0577     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 0.765       |\n",
      "|    value_loss           | 0.026       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 684         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014183026 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.19       |\n",
      "|    explained_variance   | -0.467      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.075      |\n",
      "|    n_updates            | 576         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 0.763       |\n",
      "|    value_loss           | 0.00771     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=59.71 +/- 2.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 59.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 200000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01330105 |\n",
      "|    clip_fraction        | 0.0132     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -9.16      |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0611    |\n",
      "|    n_updates            | 582        |\n",
      "|    policy_gradient_loss | -0.0264    |\n",
      "|    std                  | 0.759      |\n",
      "|    value_loss           | 0.0331     |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 288    |\n",
      "|    iterations      | 98     |\n",
      "|    time_elapsed    | 696    |\n",
      "|    total_timesteps | 200704 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 702         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011208293 |\n",
      "|    clip_fraction        | 0.00968     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.13       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.072      |\n",
      "|    n_updates            | 588         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 0.758       |\n",
      "|    value_loss           | 0.0227      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 707         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014457861 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.12       |\n",
      "|    explained_variance   | -0.202      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0892     |\n",
      "|    n_updates            | 594         |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    std                  | 0.756       |\n",
      "|    value_loss           | 0.00961     |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 290      |\n",
      "|    iterations           | 101      |\n",
      "|    time_elapsed         | 712      |\n",
      "|    total_timesteps      | 206848   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.017497 |\n",
      "|    clip_fraction        | 0.0205   |\n",
      "|    clip_range           | 0.332    |\n",
      "|    entropy_loss         | -9.1     |\n",
      "|    explained_variance   | 0.276    |\n",
      "|    learning_rate        | 0.000356 |\n",
      "|    loss                 | -0.0907  |\n",
      "|    n_updates            | 600      |\n",
      "|    policy_gradient_loss | -0.0324  |\n",
      "|    std                  | 0.753    |\n",
      "|    value_loss           | 0.0111   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 718         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011533447 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.07       |\n",
      "|    explained_variance   | -0.0741     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.077      |\n",
      "|    n_updates            | 606         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    std                  | 0.751       |\n",
      "|    value_loss           | 0.0169      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=58.95 +/- 1.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 59          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013966181 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.05       |\n",
      "|    explained_variance   | 0.091       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0773     |\n",
      "|    n_updates            | 612         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    std                  | 0.748       |\n",
      "|    value_loss           | 0.0168      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 288    |\n",
      "|    iterations      | 103    |\n",
      "|    time_elapsed    | 730    |\n",
      "|    total_timesteps | 210944 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 735         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012076939 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -9.01       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0726     |\n",
      "|    n_updates            | 618         |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    std                  | 0.746       |\n",
      "|    value_loss           | 0.0138      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 740         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012316758 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.99       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.078      |\n",
      "|    n_updates            | 624         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 0.743       |\n",
      "|    value_loss           | 0.0208      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 746         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013426938 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.96       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0812     |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 0.741       |\n",
      "|    value_loss           | 0.0191      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 751         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011212961 |\n",
      "|    clip_fraction        | 0.00928     |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.94       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0587     |\n",
      "|    n_updates            | 636         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 0.738       |\n",
      "|    value_loss           | 0.0328      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=60.07 +/- 1.08\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1e+03     |\n",
      "|    mean_reward          | 60.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 220000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0115341 |\n",
      "|    clip_fraction        | 0.0104    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -8.9      |\n",
      "|    explained_variance   | 0.35      |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.076    |\n",
      "|    n_updates            | 642       |\n",
      "|    policy_gradient_loss | -0.0269   |\n",
      "|    std                  | 0.735     |\n",
      "|    value_loss           | 0.0107    |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 108    |\n",
      "|    time_elapsed    | 763    |\n",
      "|    total_timesteps | 221184 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 769         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015537955 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.87       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0597     |\n",
      "|    n_updates            | 648         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 0.733       |\n",
      "|    value_loss           | 0.0308      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 775        |\n",
      "|    total_timesteps      | 225280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01805941 |\n",
      "|    clip_fraction        | 0.0229     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -8.85      |\n",
      "|    explained_variance   | 0.442      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0491    |\n",
      "|    n_updates            | 654        |\n",
      "|    policy_gradient_loss | -0.0265    |\n",
      "|    std                  | 0.731      |\n",
      "|    value_loss           | 0.0512     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 780        |\n",
      "|    total_timesteps      | 227328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01284405 |\n",
      "|    clip_fraction        | 0.0131     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -8.84      |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0775    |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0288    |\n",
      "|    std                  | 0.73       |\n",
      "|    value_loss           | 0.0243     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 786        |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01491878 |\n",
      "|    clip_fraction        | 0.0219     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -8.81      |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0664    |\n",
      "|    n_updates            | 666        |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    std                  | 0.727      |\n",
      "|    value_loss           | 0.0415     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=59.40 +/- 0.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 59.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015013987 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.78       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0686     |\n",
      "|    n_updates            | 672         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    std                  | 0.724       |\n",
      "|    value_loss           | 0.0229      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 113    |\n",
      "|    time_elapsed    | 799    |\n",
      "|    total_timesteps | 231424 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 804         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015158989 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.75       |\n",
      "|    explained_variance   | -0.592      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0905     |\n",
      "|    n_updates            | 678         |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    std                  | 0.721       |\n",
      "|    value_loss           | 0.00904     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013365962 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.71       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0786     |\n",
      "|    n_updates            | 684         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 0.718       |\n",
      "|    value_loss           | 0.0144      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 815         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014623026 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.69       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0678     |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    std                  | 0.716       |\n",
      "|    value_loss           | 0.0308      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 117        |\n",
      "|    time_elapsed         | 821        |\n",
      "|    total_timesteps      | 239616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01269967 |\n",
      "|    clip_fraction        | 0.0121     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -8.67      |\n",
      "|    explained_variance   | 0.443      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0782    |\n",
      "|    n_updates            | 696        |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    std                  | 0.714      |\n",
      "|    value_loss           | 0.0171     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=54.20 +/- 1.22\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 54.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017192025 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.64       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0795     |\n",
      "|    n_updates            | 702         |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    std                  | 0.711       |\n",
      "|    value_loss           | 0.0216      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 118    |\n",
      "|    time_elapsed    | 834    |\n",
      "|    total_timesteps | 241664 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 839         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017681342 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.61       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0691     |\n",
      "|    n_updates            | 708         |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    std                  | 0.709       |\n",
      "|    value_loss           | 0.0198      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 845         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018157138 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.58       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.075      |\n",
      "|    n_updates            | 714         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    std                  | 0.707       |\n",
      "|    value_loss           | 0.0237      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018398983 |\n",
      "|    clip_fraction        | 0.0224      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.55       |\n",
      "|    explained_variance   | -0.0992     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0799     |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 856        |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01584176 |\n",
      "|    clip_fraction        | 0.0181     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -8.52      |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0617    |\n",
      "|    n_updates            | 726        |\n",
      "|    policy_gradient_loss | -0.0284    |\n",
      "|    std                  | 0.701      |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=54.62 +/- 0.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 54.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021360923 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.5        |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0668     |\n",
      "|    n_updates            | 732         |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 0.0193      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 123    |\n",
      "|    time_elapsed    | 868    |\n",
      "|    total_timesteps | 251904 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 874         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016804108 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.48       |\n",
      "|    explained_variance   | -0.423      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0886     |\n",
      "|    n_updates            | 738         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 0.0095      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 879         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013695433 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.45       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.077      |\n",
      "|    n_updates            | 744         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 0.0197      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 885        |\n",
      "|    total_timesteps      | 258048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01646781 |\n",
      "|    clip_fraction        | 0.0199     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -8.44      |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0765    |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    std                  | 0.695      |\n",
      "|    value_loss           | 0.0271     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=57.21 +/- 0.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 57.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016596176 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.42       |\n",
      "|    explained_variance   | 0.0592      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0904     |\n",
      "|    n_updates            | 756         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    std                  | 0.692       |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 127    |\n",
      "|    time_elapsed    | 897    |\n",
      "|    total_timesteps | 260096 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 903         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023984564 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.39       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0589     |\n",
      "|    n_updates            | 762         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 0.0318      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 908         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017371334 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.37       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0763     |\n",
      "|    n_updates            | 768         |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 0.0248      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 914        |\n",
      "|    total_timesteps      | 266240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01556548 |\n",
      "|    clip_fraction        | 0.0195     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -8.35      |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0769    |\n",
      "|    n_updates            | 774        |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    std                  | 0.687      |\n",
      "|    value_loss           | 0.0298     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 919         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014816951 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.33       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0694     |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    std                  | 0.684       |\n",
      "|    value_loss           | 0.0285      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=55.80 +/- 1.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011998369 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.3        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0572     |\n",
      "|    n_updates            | 786         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 0.683       |\n",
      "|    value_loss           | 0.0335      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 132    |\n",
      "|    time_elapsed    | 932    |\n",
      "|    total_timesteps | 270336 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 938         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018378563 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.29       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.086      |\n",
      "|    n_updates            | 792         |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    std                  | 0.681       |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 943         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015165053 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.27       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.084      |\n",
      "|    n_updates            | 798         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 0.68        |\n",
      "|    value_loss           | 0.0174      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015182951 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.25       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0772     |\n",
      "|    n_updates            | 804         |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    std                  | 0.678       |\n",
      "|    value_loss           | 0.0154      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 954        |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02416274 |\n",
      "|    clip_fraction        | 0.037      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -8.23      |\n",
      "|    explained_variance   | 0.511      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0865    |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | -0.036     |\n",
      "|    std                  | 0.677      |\n",
      "|    value_loss           | 0.0147     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=55.11 +/- 1.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018472543 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.22       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0547     |\n",
      "|    n_updates            | 816         |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    std                  | 0.675       |\n",
      "|    value_loss           | 0.0334      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 137    |\n",
      "|    time_elapsed    | 968    |\n",
      "|    total_timesteps | 280576 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 974         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015417986 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.2        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0638     |\n",
      "|    n_updates            | 822         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    std                  | 0.675       |\n",
      "|    value_loss           | 0.0332      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 981         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021969393 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0977     |\n",
      "|    n_updates            | 828         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    std                  | 0.673       |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013205342 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | -0.00656    |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0812     |\n",
      "|    n_updates            | 834         |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    std                  | 0.67        |\n",
      "|    value_loss           | 0.0116      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 993         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017707298 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.13       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0821     |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    std                  | 0.668       |\n",
      "|    value_loss           | 0.0157      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=53.86 +/- 0.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 53.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 290000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014183277 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.11       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0751     |\n",
      "|    n_updates            | 846         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 0.667       |\n",
      "|    value_loss           | 0.017       |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 142    |\n",
      "|    time_elapsed    | 1005   |\n",
      "|    total_timesteps | 290816 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 1012        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017273277 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.1        |\n",
      "|    explained_variance   | 0.0539      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0878     |\n",
      "|    n_updates            | 852         |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    std                  | 0.665       |\n",
      "|    value_loss           | 0.00984     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 1017        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019930925 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.07       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0671     |\n",
      "|    n_updates            | 858         |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    std                  | 0.663       |\n",
      "|    value_loss           | 0.0251      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 1023        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017759383 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.04       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0695     |\n",
      "|    n_updates            | 864         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    std                  | 0.66        |\n",
      "|    value_loss           | 0.0212      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 1028        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018597057 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -8.01       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0862     |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    std                  | 0.657       |\n",
      "|    value_loss           | 0.0135      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=53.87 +/- 1.07\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 53.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016773975 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.98       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0741     |\n",
      "|    n_updates            | 876         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 0.656       |\n",
      "|    value_loss           | 0.0182      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 147    |\n",
      "|    time_elapsed    | 1040   |\n",
      "|    total_timesteps | 301056 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 1045        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014600774 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.96       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0747     |\n",
      "|    n_updates            | 882         |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    std                  | 0.654       |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 1051        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016048836 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.94       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0568     |\n",
      "|    n_updates            | 888         |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    std                  | 0.653       |\n",
      "|    value_loss           | 0.0255      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 1056        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019053016 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.93       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0803     |\n",
      "|    n_updates            | 894         |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    std                  | 0.652       |\n",
      "|    value_loss           | 0.00914     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013598932 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.92       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0775     |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    std                  | 0.65        |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=57.13 +/- 3.06\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 57.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018381082 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.89       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0704     |\n",
      "|    n_updates            | 906         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    std                  | 0.648       |\n",
      "|    value_loss           | 0.0335      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 152    |\n",
      "|    time_elapsed    | 1073   |\n",
      "|    total_timesteps | 311296 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 1079        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018518506 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.85       |\n",
      "|    explained_variance   | 0.0531      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0951     |\n",
      "|    n_updates            | 912         |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    std                  | 0.644       |\n",
      "|    value_loss           | 0.00746     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 1084        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018883899 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.81       |\n",
      "|    explained_variance   | 0.0374      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0865     |\n",
      "|    n_updates            | 918         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 0.641       |\n",
      "|    value_loss           | 0.0162      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 1090        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016329743 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.77       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0766     |\n",
      "|    n_updates            | 924         |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    std                  | 0.639       |\n",
      "|    value_loss           | 0.0273      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 1096        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016655553 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.74       |\n",
      "|    explained_variance   | -0.0244     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0846     |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    std                  | 0.636       |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=56.43 +/- 1.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 56.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149294585 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.332        |\n",
      "|    entropy_loss         | -7.71        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.000356     |\n",
      "|    loss                 | -0.083       |\n",
      "|    n_updates            | 936          |\n",
      "|    policy_gradient_loss | -0.0294      |\n",
      "|    std                  | 0.634        |\n",
      "|    value_loss           | 0.0147       |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 157    |\n",
      "|    time_elapsed    | 1109   |\n",
      "|    total_timesteps | 321536 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 1114       |\n",
      "|    total_timesteps      | 323584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01730912 |\n",
      "|    clip_fraction        | 0.0201     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -7.68      |\n",
      "|    explained_variance   | 0.265      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0723    |\n",
      "|    n_updates            | 942        |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    std                  | 0.631      |\n",
      "|    value_loss           | 0.015      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 1119        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016729858 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.66       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0638     |\n",
      "|    n_updates            | 948         |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 0.63        |\n",
      "|    value_loss           | 0.0219      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 1125       |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01819256 |\n",
      "|    clip_fraction        | 0.0234     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -7.64      |\n",
      "|    explained_variance   | 0.17       |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0826    |\n",
      "|    n_updates            | 954        |\n",
      "|    policy_gradient_loss | -0.0339    |\n",
      "|    std                  | 0.628      |\n",
      "|    value_loss           | 0.0105     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 1130        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016780714 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.61       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0837     |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    std                  | 0.626       |\n",
      "|    value_loss           | 0.00921     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=55.81 +/- 0.98\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019202838 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.58       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0714     |\n",
      "|    n_updates            | 966         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    std                  | 0.624       |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 162    |\n",
      "|    time_elapsed    | 1142   |\n",
      "|    total_timesteps | 331776 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 1147        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015056502 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.55       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0704     |\n",
      "|    n_updates            | 972         |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    std                  | 0.62        |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 1153        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018847883 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.51       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0919     |\n",
      "|    n_updates            | 978         |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    std                  | 0.618       |\n",
      "|    value_loss           | 0.0124      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 1158        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019882869 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.48       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0586     |\n",
      "|    n_updates            | 984         |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    std                  | 0.616       |\n",
      "|    value_loss           | 0.0451      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 1164        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015840901 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.46       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0766     |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    std                  | 0.614       |\n",
      "|    value_loss           | 0.0194      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=55.28 +/- 1.93\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017844003 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.43       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0705     |\n",
      "|    n_updates            | 996         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    std                  | 0.612       |\n",
      "|    value_loss           | 0.0228      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 167    |\n",
      "|    time_elapsed    | 1176   |\n",
      "|    total_timesteps | 342016 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 1181        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021493968 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.41       |\n",
      "|    explained_variance   | -0.108      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.105      |\n",
      "|    n_updates            | 1002        |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    std                  | 0.609       |\n",
      "|    value_loss           | 0.00867     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 1186        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018696584 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.37       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0879     |\n",
      "|    n_updates            | 1008        |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    std                  | 0.607       |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 1192        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019219471 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.34       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0876     |\n",
      "|    n_updates            | 1014        |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    std                  | 0.605       |\n",
      "|    value_loss           | 0.00846     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=58.87 +/- 0.86\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 58.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019187676 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.32       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0843     |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    std                  | 0.603       |\n",
      "|    value_loss           | 0.0176      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 171    |\n",
      "|    time_elapsed    | 1204   |\n",
      "|    total_timesteps | 350208 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 1209        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018007496 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.29       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0804     |\n",
      "|    n_updates            | 1026        |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    std                  | 0.601       |\n",
      "|    value_loss           | 0.0108      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 1214        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021918863 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | 0.0338      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0853     |\n",
      "|    n_updates            | 1032        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    std                  | 0.598       |\n",
      "|    value_loss           | 0.00779     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 1220        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020404281 |\n",
      "|    clip_fraction        | 0.0274      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.22       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0929     |\n",
      "|    n_updates            | 1038        |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    std                  | 0.596       |\n",
      "|    value_loss           | 0.00735     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 1225        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016806979 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.19       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0955     |\n",
      "|    n_updates            | 1044        |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    std                  | 0.593       |\n",
      "|    value_loss           | 0.00639     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=58.18 +/- 1.95\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 58.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 360000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021053012 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.15       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0818     |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    std                  | 0.591       |\n",
      "|    value_loss           | 0.00781     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 176    |\n",
      "|    time_elapsed    | 1237   |\n",
      "|    total_timesteps | 360448 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 1242        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019684587 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0749     |\n",
      "|    n_updates            | 1056        |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    std                  | 0.59        |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 1248        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019221457 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.115      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0768     |\n",
      "|    n_updates            | 1062        |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    std                  | 0.588       |\n",
      "|    value_loss           | 0.0126      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 1253        |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019570563 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | -0.0843     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0813     |\n",
      "|    n_updates            | 1068        |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    std                  | 0.586       |\n",
      "|    value_loss           | 0.009       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 292       |\n",
      "|    iterations           | 180       |\n",
      "|    time_elapsed         | 1259      |\n",
      "|    total_timesteps      | 368640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0240998 |\n",
      "|    clip_fraction        | 0.0348    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -7.05     |\n",
      "|    explained_variance   | 0.124     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.108    |\n",
      "|    n_updates            | 1074      |\n",
      "|    policy_gradient_loss | -0.0377   |\n",
      "|    std                  | 0.584     |\n",
      "|    value_loss           | 0.00576   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=58.00 +/- 1.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 58          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 370000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017079588 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -7.02       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0742     |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 0.581       |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 181    |\n",
      "|    time_elapsed    | 1272   |\n",
      "|    total_timesteps | 370688 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 182        |\n",
      "|    time_elapsed         | 1278       |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01955189 |\n",
      "|    clip_fraction        | 0.0285     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.99      |\n",
      "|    explained_variance   | 0.44       |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0652    |\n",
      "|    n_updates            | 1086       |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    std                  | 0.58       |\n",
      "|    value_loss           | 0.0263     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 1284        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015968937 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.97       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0732     |\n",
      "|    n_updates            | 1092        |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    std                  | 0.578       |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 184        |\n",
      "|    time_elapsed         | 1290       |\n",
      "|    total_timesteps      | 376832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02053041 |\n",
      "|    clip_fraction        | 0.0273     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.95      |\n",
      "|    explained_variance   | 0.119      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0766    |\n",
      "|    n_updates            | 1098       |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    std                  | 0.577      |\n",
      "|    value_loss           | 0.0076     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 1295        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021195298 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.93       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0913     |\n",
      "|    n_updates            | 1104        |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    std                  | 0.575       |\n",
      "|    value_loss           | 0.00574     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=57.80 +/- 0.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 57.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017577872 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.89       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0688     |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    std                  | 0.572       |\n",
      "|    value_loss           | 0.0109      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 186    |\n",
      "|    time_elapsed    | 1308   |\n",
      "|    total_timesteps | 380928 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1313        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019500077 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.86       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0825     |\n",
      "|    n_updates            | 1116        |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    std                  | 0.57        |\n",
      "|    value_loss           | 0.00839     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 1319        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018364433 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | -0.00998    |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0804     |\n",
      "|    n_updates            | 1122        |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    std                  | 0.568       |\n",
      "|    value_loss           | 0.00587     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 189        |\n",
      "|    time_elapsed         | 1325       |\n",
      "|    total_timesteps      | 387072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02037143 |\n",
      "|    clip_fraction        | 0.0283     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.8       |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0898    |\n",
      "|    n_updates            | 1128       |\n",
      "|    policy_gradient_loss | -0.036     |\n",
      "|    std                  | 0.566      |\n",
      "|    value_loss           | 0.0148     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 1330        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019877382 |\n",
      "|    clip_fraction        | 0.0274      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.79       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0929     |\n",
      "|    n_updates            | 1134        |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    std                  | 0.565       |\n",
      "|    value_loss           | 0.00978     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=57.60 +/- 0.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 57.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020509467 |\n",
      "|    clip_fraction        | 0.0278      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.77       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0887     |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    std                  | 0.564       |\n",
      "|    value_loss           | 0.00817     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 191    |\n",
      "|    time_elapsed    | 1343   |\n",
      "|    total_timesteps | 391168 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 1349        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017658323 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.74       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0623     |\n",
      "|    n_updates            | 1146        |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 0.562       |\n",
      "|    value_loss           | 0.0328      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 1355        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015896674 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.71       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0706     |\n",
      "|    n_updates            | 1152        |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    std                  | 0.559       |\n",
      "|    value_loss           | 0.0146      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 1361        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017187914 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.68       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0678     |\n",
      "|    n_updates            | 1158        |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    std                  | 0.558       |\n",
      "|    value_loss           | 0.0227      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 1367        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018178288 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0793     |\n",
      "|    n_updates            | 1164        |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    std                  | 0.556       |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=57.04 +/- 1.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1e+03     |\n",
      "|    mean_reward          | 57        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 400000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0193389 |\n",
      "|    clip_fraction        | 0.024     |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -6.63     |\n",
      "|    explained_variance   | 0.372     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.0848   |\n",
      "|    n_updates            | 1170      |\n",
      "|    policy_gradient_loss | -0.0323   |\n",
      "|    std                  | 0.553     |\n",
      "|    value_loss           | 0.00605   |\n",
      "---------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 196    |\n",
      "|    time_elapsed    | 1380   |\n",
      "|    total_timesteps | 401408 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 1385        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021692045 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.59       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0927     |\n",
      "|    n_updates            | 1176        |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    std                  | 0.551       |\n",
      "|    value_loss           | 0.00553     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 198        |\n",
      "|    time_elapsed         | 1391       |\n",
      "|    total_timesteps      | 405504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02098372 |\n",
      "|    clip_fraction        | 0.0317     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.57      |\n",
      "|    explained_variance   | 0.353      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0933    |\n",
      "|    n_updates            | 1182       |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    std                  | 0.55       |\n",
      "|    value_loss           | 0.00966    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 1397        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017438887 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.55       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0696     |\n",
      "|    n_updates            | 1188        |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    std                  | 0.548       |\n",
      "|    value_loss           | 0.0222      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 1402        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021101398 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.53       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0764     |\n",
      "|    n_updates            | 1194        |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    std                  | 0.547       |\n",
      "|    value_loss           | 0.02        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=49.77 +/- 15.69\n",
      "Episode length: 866.00 +/- 268.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 866        |\n",
      "|    mean_reward          | 49.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 410000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01880525 |\n",
      "|    clip_fraction        | 0.0233     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.51      |\n",
      "|    explained_variance   | 0.186      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0731    |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    std                  | 0.546      |\n",
      "|    value_loss           | 0.0153     |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 201    |\n",
      "|    time_elapsed    | 1415   |\n",
      "|    total_timesteps | 411648 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 1420        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018766794 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.49       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0756     |\n",
      "|    n_updates            | 1206        |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    std                  | 0.545       |\n",
      "|    value_loss           | 0.00754     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 1426        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019019976 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.47       |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0854     |\n",
      "|    n_updates            | 1212        |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    std                  | 0.543       |\n",
      "|    value_loss           | 0.0049      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 1431       |\n",
      "|    total_timesteps      | 417792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02234435 |\n",
      "|    clip_fraction        | 0.0316     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.43      |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0749    |\n",
      "|    n_updates            | 1218       |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    std                  | 0.54       |\n",
      "|    value_loss           | 0.0185     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 205        |\n",
      "|    time_elapsed         | 1437       |\n",
      "|    total_timesteps      | 419840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02448889 |\n",
      "|    clip_fraction        | 0.0356     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.4       |\n",
      "|    explained_variance   | 0.218      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0731    |\n",
      "|    n_updates            | 1224       |\n",
      "|    policy_gradient_loss | -0.0364    |\n",
      "|    std                  | 0.538      |\n",
      "|    value_loss           | 0.00726    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=50.32 +/- 12.05\n",
      "Episode length: 896.00 +/- 208.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 896         |\n",
      "|    mean_reward          | 50.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 420000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018549342 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0691     |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    std                  | 0.537       |\n",
      "|    value_loss           | 0.00779     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 206    |\n",
      "|    time_elapsed    | 1449   |\n",
      "|    total_timesteps | 421888 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 1455        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023368616 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.35       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0842     |\n",
      "|    n_updates            | 1236        |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 0.00837     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 208        |\n",
      "|    time_elapsed         | 1460       |\n",
      "|    total_timesteps      | 425984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01973741 |\n",
      "|    clip_fraction        | 0.0324     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.33      |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.063     |\n",
      "|    n_updates            | 1242       |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    std                  | 0.533      |\n",
      "|    value_loss           | 0.0229     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 1466       |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02142331 |\n",
      "|    clip_fraction        | 0.0286     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.3       |\n",
      "|    explained_variance   | -0.141     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0771    |\n",
      "|    n_updates            | 1248       |\n",
      "|    policy_gradient_loss | -0.0358    |\n",
      "|    std                  | 0.531      |\n",
      "|    value_loss           | 0.0054     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=56.78 +/- 0.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 56.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022374889 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.27       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0844     |\n",
      "|    n_updates            | 1254        |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    std                  | 0.529       |\n",
      "|    value_loss           | 0.00854     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 210    |\n",
      "|    time_elapsed    | 1480   |\n",
      "|    total_timesteps | 430080 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 1486        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021916581 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.24       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0815     |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    std                  | 0.528       |\n",
      "|    value_loss           | 0.00947     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 212        |\n",
      "|    time_elapsed         | 1491       |\n",
      "|    total_timesteps      | 434176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01981496 |\n",
      "|    clip_fraction        | 0.0259     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.22      |\n",
      "|    explained_variance   | -0.0757    |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0993    |\n",
      "|    n_updates            | 1266       |\n",
      "|    policy_gradient_loss | -0.0348    |\n",
      "|    std                  | 0.526      |\n",
      "|    value_loss           | 0.00707    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 1497        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022046193 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.19       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 1272        |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    std                  | 0.524       |\n",
      "|    value_loss           | 0.00588     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 1503       |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02118219 |\n",
      "|    clip_fraction        | 0.0326     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.16      |\n",
      "|    explained_variance   | 0.201      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0796    |\n",
      "|    n_updates            | 1278       |\n",
      "|    policy_gradient_loss | -0.0345    |\n",
      "|    std                  | 0.522      |\n",
      "|    value_loss           | 0.00887    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=56.48 +/- 1.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 56.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 440000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02206791 |\n",
      "|    clip_fraction        | 0.0308     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.13      |\n",
      "|    explained_variance   | 0.0347     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.087     |\n",
      "|    n_updates            | 1284       |\n",
      "|    policy_gradient_loss | -0.0367    |\n",
      "|    std                  | 0.52       |\n",
      "|    value_loss           | 0.00777    |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 215    |\n",
      "|    time_elapsed    | 1516   |\n",
      "|    total_timesteps | 440320 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 1521        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022010535 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.1        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0809     |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    std                  | 0.518       |\n",
      "|    value_loss           | 0.00875     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 217        |\n",
      "|    time_elapsed         | 1527       |\n",
      "|    total_timesteps      | 444416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02068888 |\n",
      "|    clip_fraction        | 0.0284     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -6.07      |\n",
      "|    explained_variance   | 0.239      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0902    |\n",
      "|    n_updates            | 1296       |\n",
      "|    policy_gradient_loss | -0.0374    |\n",
      "|    std                  | 0.516      |\n",
      "|    value_loss           | 0.00548    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 1532        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027336588 |\n",
      "|    clip_fraction        | 0.0412      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -6.02       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0874     |\n",
      "|    n_updates            | 1302        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    std                  | 0.513       |\n",
      "|    value_loss           | 0.00422     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 1538        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026643548 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0927     |\n",
      "|    n_updates            | 1308        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 0.0193      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=49.29 +/- 15.12\n",
      "Episode length: 870.80 +/- 258.40\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 871        |\n",
      "|    mean_reward          | 49.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 450000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02082029 |\n",
      "|    clip_fraction        | 0.0321     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -5.96      |\n",
      "|    explained_variance   | 0.264      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0838    |\n",
      "|    n_updates            | 1314       |\n",
      "|    policy_gradient_loss | -0.037     |\n",
      "|    std                  | 0.509      |\n",
      "|    value_loss           | 0.00847    |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 220    |\n",
      "|    time_elapsed    | 1549   |\n",
      "|    total_timesteps | 450560 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 1555        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023316046 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.93       |\n",
      "|    explained_variance   | 0.0622      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0781     |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    std                  | 0.508       |\n",
      "|    value_loss           | 0.00728     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 222        |\n",
      "|    time_elapsed         | 1560       |\n",
      "|    total_timesteps      | 454656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02206574 |\n",
      "|    clip_fraction        | 0.0316     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -5.91      |\n",
      "|    explained_variance   | 0.246      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0529    |\n",
      "|    n_updates            | 1326       |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    std                  | 0.506      |\n",
      "|    value_loss           | 0.0235     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 223        |\n",
      "|    time_elapsed         | 1566       |\n",
      "|    total_timesteps      | 456704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01678661 |\n",
      "|    clip_fraction        | 0.0203     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -5.89      |\n",
      "|    explained_variance   | 0.0564     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0741    |\n",
      "|    n_updates            | 1332       |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    std                  | 0.505      |\n",
      "|    value_loss           | 0.00839    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 1571        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020362124 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.077      |\n",
      "|    n_updates            | 1338        |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    std                  | 0.503       |\n",
      "|    value_loss           | 0.00687     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=55.78 +/- 1.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 460000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026486179 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.0129      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0824     |\n",
      "|    n_updates            | 1344        |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    std                  | 0.502       |\n",
      "|    value_loss           | 0.00748     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 225    |\n",
      "|    time_elapsed    | 1584   |\n",
      "|    total_timesteps | 460800 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 1589        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020784449 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0942     |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    std                  | 0.5         |\n",
      "|    value_loss           | 0.00698     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 1595        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020263825 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0574     |\n",
      "|    n_updates            | 1356        |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    std                  | 0.498       |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 1600        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023200486 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.091      |\n",
      "|    n_updates            | 1362        |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    std                  | 0.497       |\n",
      "|    value_loss           | 0.00607     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 1606        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019125678 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0674     |\n",
      "|    n_updates            | 1368        |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    std                  | 0.495       |\n",
      "|    value_loss           | 0.0212      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=55.31 +/- 1.72\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 470000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027521212 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0857     |\n",
      "|    n_updates            | 1374        |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    std                  | 0.494       |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 230    |\n",
      "|    time_elapsed    | 1619   |\n",
      "|    total_timesteps | 471040 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 1624        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024460554 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0897     |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 0.493       |\n",
      "|    value_loss           | 0.00854     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 1630        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022457547 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0858     |\n",
      "|    n_updates            | 1386        |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    std                  | 0.491       |\n",
      "|    value_loss           | 0.00811     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 1635        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020200586 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.08       |\n",
      "|    n_updates            | 1392        |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 234        |\n",
      "|    time_elapsed         | 1641       |\n",
      "|    total_timesteps      | 479232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03065468 |\n",
      "|    clip_fraction        | 0.0553     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -5.61      |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0834    |\n",
      "|    n_updates            | 1398       |\n",
      "|    policy_gradient_loss | -0.0372    |\n",
      "|    std                  | 0.488      |\n",
      "|    value_loss           | 0.013      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=56.37 +/- 2.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 56.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022458743 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0817     |\n",
      "|    n_updates            | 1404        |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    std                  | 0.487       |\n",
      "|    value_loss           | 0.00862     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 235    |\n",
      "|    time_elapsed    | 1654   |\n",
      "|    total_timesteps | 481280 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 1660        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025161603 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0832     |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    std                  | 0.485       |\n",
      "|    value_loss           | 0.0117      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 1666        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022348678 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0794     |\n",
      "|    n_updates            | 1416        |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    std                  | 0.484       |\n",
      "|    value_loss           | 0.0167      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 1671        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024293734 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0841     |\n",
      "|    n_updates            | 1422        |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    std                  | 0.482       |\n",
      "|    value_loss           | 0.0109      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 1677        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023575611 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0534     |\n",
      "|    n_updates            | 1428        |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    std                  | 0.482       |\n",
      "|    value_loss           | 0.0279      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=56.20 +/- 1.50\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 56.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 490000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025093218 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.0719      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0922     |\n",
      "|    n_updates            | 1434        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.48        |\n",
      "|    value_loss           | 0.00434     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 240    |\n",
      "|    time_elapsed    | 1690   |\n",
      "|    total_timesteps | 491520 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 1696        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018011043 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.45       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0611     |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 0.478       |\n",
      "|    value_loss           | 0.0266      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 1701        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020894121 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0903     |\n",
      "|    n_updates            | 1446        |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    std                  | 0.476       |\n",
      "|    value_loss           | 0.0133      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 1707        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029315464 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0735     |\n",
      "|    n_updates            | 1452        |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    std                  | 0.475       |\n",
      "|    value_loss           | 0.0303      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 1712        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028701667 |\n",
      "|    clip_fraction        | 0.0492      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0962     |\n",
      "|    n_updates            | 1458        |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    std                  | 0.474       |\n",
      "|    value_loss           | 0.0062      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=49.94 +/- 8.15\n",
      "Episode length: 924.80 +/- 150.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 925         |\n",
      "|    mean_reward          | 49.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023969501 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0922     |\n",
      "|    n_updates            | 1464        |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    std                  | 0.472       |\n",
      "|    value_loss           | 0.00978     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 245    |\n",
      "|    time_elapsed    | 1724   |\n",
      "|    total_timesteps | 501760 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 1730        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025907308 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.31       |\n",
      "|    explained_variance   | 0.0771      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0785     |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 0.47        |\n",
      "|    value_loss           | 0.00592     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 1735        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023045598 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.28       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0795     |\n",
      "|    n_updates            | 1476        |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    std                  | 0.468       |\n",
      "|    value_loss           | 0.00648     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 1740        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025549062 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.26       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0868     |\n",
      "|    n_updates            | 1482        |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    std                  | 0.467       |\n",
      "|    value_loss           | 0.00494     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 249        |\n",
      "|    time_elapsed         | 1746       |\n",
      "|    total_timesteps      | 509952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02461562 |\n",
      "|    clip_fraction        | 0.0401     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -5.22      |\n",
      "|    explained_variance   | 0.428      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0823    |\n",
      "|    n_updates            | 1488       |\n",
      "|    policy_gradient_loss | -0.0382    |\n",
      "|    std                  | 0.464      |\n",
      "|    value_loss           | 0.0135     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=55.22 +/- 1.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021824853 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0716     |\n",
      "|    n_updates            | 1494        |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    std                  | 0.463       |\n",
      "|    value_loss           | 0.0235      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 250    |\n",
      "|    time_elapsed    | 1759   |\n",
      "|    total_timesteps | 512000 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 1765        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021686416 |\n",
      "|    clip_fraction        | 0.034       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.17       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0628     |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    std                  | 0.462       |\n",
      "|    value_loss           | 0.0138      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 252        |\n",
      "|    time_elapsed         | 1770       |\n",
      "|    total_timesteps      | 516096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02142165 |\n",
      "|    clip_fraction        | 0.032      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -5.15      |\n",
      "|    explained_variance   | 0.247      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0789    |\n",
      "|    n_updates            | 1506       |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    std                  | 0.461      |\n",
      "|    value_loss           | 0.0188     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 253        |\n",
      "|    time_elapsed         | 1776       |\n",
      "|    total_timesteps      | 518144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02228831 |\n",
      "|    clip_fraction        | 0.0305     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -5.13      |\n",
      "|    explained_variance   | 0.0911     |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0852    |\n",
      "|    n_updates            | 1512       |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    std                  | 0.459      |\n",
      "|    value_loss           | 0.0064     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=54.76 +/- 1.37\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 54.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 520000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02892952 |\n",
      "|    clip_fraction        | 0.05       |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -5.1       |\n",
      "|    explained_variance   | 0.445      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0727    |\n",
      "|    n_updates            | 1518       |\n",
      "|    policy_gradient_loss | -0.0355    |\n",
      "|    std                  | 0.458      |\n",
      "|    value_loss           | 0.0194     |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 254    |\n",
      "|    time_elapsed    | 1788   |\n",
      "|    total_timesteps | 520192 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 1794        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021650981 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.08       |\n",
      "|    explained_variance   | 0.0754      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0666     |\n",
      "|    n_updates            | 1524        |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    std                  | 0.457       |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 1799        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030704658 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0826     |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    std                  | 0.456       |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 1805        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029972825 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0648     |\n",
      "|    n_updates            | 1536        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    std                  | 0.454       |\n",
      "|    value_loss           | 0.0215      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 1811        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025620911 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0794     |\n",
      "|    n_updates            | 1542        |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    std                  | 0.452       |\n",
      "|    value_loss           | 0.0136      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=51.04 +/- 1.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 51          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029086947 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0961     |\n",
      "|    n_updates            | 1548        |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    std                  | 0.45        |\n",
      "|    value_loss           | 0.00849     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 259    |\n",
      "|    time_elapsed    | 1824   |\n",
      "|    total_timesteps | 530432 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 1830        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028080137 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0717     |\n",
      "|    n_updates            | 1554        |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    std                  | 0.449       |\n",
      "|    value_loss           | 0.0172      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 261        |\n",
      "|    time_elapsed         | 1836       |\n",
      "|    total_timesteps      | 534528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02714131 |\n",
      "|    clip_fraction        | 0.0453     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -4.93      |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0753    |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    std                  | 0.448      |\n",
      "|    value_loss           | 0.0244     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 1842        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026248015 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.91       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0797     |\n",
      "|    n_updates            | 1566        |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    std                  | 0.447       |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 1847        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021481788 |\n",
      "|    clip_fraction        | 0.0327      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0743     |\n",
      "|    n_updates            | 1572        |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    std                  | 0.446       |\n",
      "|    value_loss           | 0.0133      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=52.66 +/- 1.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 52.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 540000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025262449 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0921     |\n",
      "|    n_updates            | 1578        |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    std                  | 0.445       |\n",
      "|    value_loss           | 0.00985     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 264    |\n",
      "|    time_elapsed    | 1860   |\n",
      "|    total_timesteps | 540672 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 1866        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025527637 |\n",
      "|    clip_fraction        | 0.0412      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.85       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0986     |\n",
      "|    n_updates            | 1584        |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    std                  | 0.444       |\n",
      "|    value_loss           | 0.00887     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 1872        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025889166 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.84       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0595     |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    std                  | 0.443       |\n",
      "|    value_loss           | 0.0415      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 1878        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036881942 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0568     |\n",
      "|    n_updates            | 1596        |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    std                  | 0.443       |\n",
      "|    value_loss           | 0.0532      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 1884        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030821273 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0943     |\n",
      "|    n_updates            | 1602        |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    std                  | 0.442       |\n",
      "|    value_loss           | 0.016       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=54.58 +/- 1.75\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 54.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 550000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02227125 |\n",
      "|    clip_fraction        | 0.0339     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -4.79      |\n",
      "|    explained_variance   | 0.344      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.066     |\n",
      "|    n_updates            | 1608       |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    std                  | 0.44       |\n",
      "|    value_loss           | 0.015      |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 269    |\n",
      "|    time_elapsed    | 1897   |\n",
      "|    total_timesteps | 550912 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 1903        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025331631 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0815     |\n",
      "|    n_updates            | 1614        |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    std                  | 0.439       |\n",
      "|    value_loss           | 0.00906     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 1909        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025181044 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0714     |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    std                  | 0.436       |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 1914        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024941161 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.078      |\n",
      "|    n_updates            | 1626        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    std                  | 0.434       |\n",
      "|    value_loss           | 0.00982     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 1920        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028929325 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0909     |\n",
      "|    n_updates            | 1632        |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    std                  | 0.433       |\n",
      "|    value_loss           | 0.00853     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=50.37 +/- 0.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 50.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028720304 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.095      |\n",
      "|    n_updates            | 1638        |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    std                  | 0.432       |\n",
      "|    value_loss           | 0.00799     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 274    |\n",
      "|    time_elapsed    | 1933   |\n",
      "|    total_timesteps | 561152 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 1939        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027893092 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.09       |\n",
      "|    n_updates            | 1644        |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    std                  | 0.43        |\n",
      "|    value_loss           | 0.00506     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 276        |\n",
      "|    time_elapsed         | 1945       |\n",
      "|    total_timesteps      | 565248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03559654 |\n",
      "|    clip_fraction        | 0.0763     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -4.58      |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0773    |\n",
      "|    n_updates            | 1650       |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    std                  | 0.429      |\n",
      "|    value_loss           | 0.0106     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 1952        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024241686 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0711     |\n",
      "|    n_updates            | 1656        |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    std                  | 0.428       |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 1958        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027329914 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.068      |\n",
      "|    n_updates            | 1662        |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    std                  | 0.427       |\n",
      "|    value_loss           | 0.0222      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=52.47 +/- 1.15\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 52.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 570000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030456673 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.51       |\n",
      "|    explained_variance   | -0.191      |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0842     |\n",
      "|    n_updates            | 1668        |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 0.425       |\n",
      "|    value_loss           | 0.00717     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 279    |\n",
      "|    time_elapsed    | 1972   |\n",
      "|    total_timesteps | 571392 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 1978        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028660603 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0784     |\n",
      "|    n_updates            | 1674        |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    std                  | 0.425       |\n",
      "|    value_loss           | 0.0126      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 1984        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029939499 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.48       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0859     |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 0.423       |\n",
      "|    value_loss           | 0.00457     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 1990        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028877925 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.066      |\n",
      "|    n_updates            | 1686        |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    std                  | 0.422       |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 1995        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026406605 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0808     |\n",
      "|    n_updates            | 1692        |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    std                  | 0.421       |\n",
      "|    value_loss           | 0.00766     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=54.74 +/- 1.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 54.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029847682 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.41       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0967     |\n",
      "|    n_updates            | 1698        |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    std                  | 0.42        |\n",
      "|    value_loss           | 0.00853     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 284    |\n",
      "|    time_elapsed    | 2008   |\n",
      "|    total_timesteps | 581632 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 2014        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032044835 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.39       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0912     |\n",
      "|    n_updates            | 1704        |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    std                  | 0.419       |\n",
      "|    value_loss           | 0.00638     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 2019        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030936662 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.37       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0909     |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    std                  | 0.418       |\n",
      "|    value_loss           | 0.00691     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 2025        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025474757 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.35       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0728     |\n",
      "|    n_updates            | 1716        |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    std                  | 0.417       |\n",
      "|    value_loss           | 0.0252      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 2030        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034881294 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.33       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0986     |\n",
      "|    n_updates            | 1722        |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    std                  | 0.416       |\n",
      "|    value_loss           | 0.00571     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=53.34 +/- 0.92\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 53.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 590000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027929427 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.062      |\n",
      "|    n_updates            | 1728        |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    std                  | 0.415       |\n",
      "|    value_loss           | 0.0205      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 289    |\n",
      "|    time_elapsed    | 2042   |\n",
      "|    total_timesteps | 591872 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 2048        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029246276 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.29       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0726     |\n",
      "|    n_updates            | 1734        |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    std                  | 0.413       |\n",
      "|    value_loss           | 0.0211      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 2053        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025798164 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.27       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0739     |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    std                  | 0.413       |\n",
      "|    value_loss           | 0.0205      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 2059        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029460773 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0956     |\n",
      "|    n_updates            | 1746        |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    std                  | 0.411       |\n",
      "|    value_loss           | 0.0045      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=54.34 +/- 0.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 54.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 600000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02799756 |\n",
      "|    clip_fraction        | 0.0444     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -4.21      |\n",
      "|    explained_variance   | 0.104      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0835    |\n",
      "|    n_updates            | 1752       |\n",
      "|    policy_gradient_loss | -0.0418    |\n",
      "|    std                  | 0.409      |\n",
      "|    value_loss           | 0.00767    |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 293    |\n",
      "|    time_elapsed    | 2072   |\n",
      "|    total_timesteps | 600064 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 2078        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028355027 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0756     |\n",
      "|    n_updates            | 1758        |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    std                  | 0.408       |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 295        |\n",
      "|    time_elapsed         | 2084       |\n",
      "|    total_timesteps      | 604160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03149657 |\n",
      "|    clip_fraction        | 0.0569     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -4.16      |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0781    |\n",
      "|    n_updates            | 1764       |\n",
      "|    policy_gradient_loss | -0.0427    |\n",
      "|    std                  | 0.407      |\n",
      "|    value_loss           | 0.00928    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 2090        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030940749 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0758     |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 0.406       |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 2096        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026556384 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0766     |\n",
      "|    n_updates            | 1776        |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 0.404       |\n",
      "|    value_loss           | 0.00822     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=53.33 +/- 1.19\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 53.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029141026 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0988     |\n",
      "|    n_updates            | 1782        |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    std                  | 0.403       |\n",
      "|    value_loss           | 0.00696     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 298    |\n",
      "|    time_elapsed    | 2109   |\n",
      "|    total_timesteps | 610304 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 2115        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031909216 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0969     |\n",
      "|    n_updates            | 1788        |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 0.0042      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 300        |\n",
      "|    time_elapsed         | 2121       |\n",
      "|    total_timesteps      | 614400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03275263 |\n",
      "|    clip_fraction        | 0.0583     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -4.03      |\n",
      "|    explained_variance   | 0.275      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0761    |\n",
      "|    n_updates            | 1794       |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    std                  | 0.401      |\n",
      "|    value_loss           | 0.0147     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 301        |\n",
      "|    time_elapsed         | 2126       |\n",
      "|    total_timesteps      | 616448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03177713 |\n",
      "|    clip_fraction        | 0.056      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -4.02      |\n",
      "|    explained_variance   | 0.379      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0738    |\n",
      "|    n_updates            | 1800       |\n",
      "|    policy_gradient_loss | -0.0421    |\n",
      "|    std                  | 0.4        |\n",
      "|    value_loss           | 0.00852    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 2132        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030705933 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0753     |\n",
      "|    n_updates            | 1806        |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    std                  | 0.399       |\n",
      "|    value_loss           | 0.027       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=53.80 +/- 1.72\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 53.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 620000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028331153 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0756     |\n",
      "|    n_updates            | 1812        |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    std                  | 0.398       |\n",
      "|    value_loss           | 0.0163      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 303    |\n",
      "|    time_elapsed    | 2145   |\n",
      "|    total_timesteps | 620544 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 2150        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028966375 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0655     |\n",
      "|    n_updates            | 1818        |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    std                  | 0.397       |\n",
      "|    value_loss           | 0.0121      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 289      |\n",
      "|    iterations           | 305      |\n",
      "|    time_elapsed         | 2156     |\n",
      "|    total_timesteps      | 624640   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.029131 |\n",
      "|    clip_fraction        | 0.0578   |\n",
      "|    clip_range           | 0.332    |\n",
      "|    entropy_loss         | -3.94    |\n",
      "|    explained_variance   | 0.288    |\n",
      "|    learning_rate        | 0.000356 |\n",
      "|    loss                 | -0.0661  |\n",
      "|    n_updates            | 1824     |\n",
      "|    policy_gradient_loss | -0.0369  |\n",
      "|    std                  | 0.396    |\n",
      "|    value_loss           | 0.0188   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 306        |\n",
      "|    time_elapsed         | 2161       |\n",
      "|    total_timesteps      | 626688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03040228 |\n",
      "|    clip_fraction        | 0.0551     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -3.91      |\n",
      "|    explained_variance   | 0.247      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0943    |\n",
      "|    n_updates            | 1830       |\n",
      "|    policy_gradient_loss | -0.0419    |\n",
      "|    std                  | 0.394      |\n",
      "|    value_loss           | 0.00559    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 307        |\n",
      "|    time_elapsed         | 2167       |\n",
      "|    total_timesteps      | 628736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02752396 |\n",
      "|    clip_fraction        | 0.0471     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -3.87      |\n",
      "|    explained_variance   | 0.503      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0752    |\n",
      "|    n_updates            | 1836       |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    std                  | 0.392      |\n",
      "|    value_loss           | 0.0128     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=54.64 +/- 2.16\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 54.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 630000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025089571 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.075      |\n",
      "|    n_updates            | 1842        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 0.391       |\n",
      "|    value_loss           | 0.008       |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 308    |\n",
      "|    time_elapsed    | 2180   |\n",
      "|    total_timesteps | 630784 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 2186        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034331836 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.097      |\n",
      "|    n_updates            | 1848        |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    std                  | 0.39        |\n",
      "|    value_loss           | 0.00567     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 2191        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029229516 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0967     |\n",
      "|    n_updates            | 1854        |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    std                  | 0.389       |\n",
      "|    value_loss           | 0.00934     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 2197        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030216496 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.071       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0735     |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    std                  | 0.388       |\n",
      "|    value_loss           | 0.0107      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 2203        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031803846 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.107      |\n",
      "|    n_updates            | 1866        |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    std                  | 0.387       |\n",
      "|    value_loss           | 0.0055      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=55.93 +/- 2.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030197212 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0804     |\n",
      "|    n_updates            | 1872        |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    std                  | 0.386       |\n",
      "|    value_loss           | 0.0186      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 313    |\n",
      "|    time_elapsed    | 2215   |\n",
      "|    total_timesteps | 641024 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 2221        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032715034 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.095      |\n",
      "|    n_updates            | 1878        |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    std                  | 0.385       |\n",
      "|    value_loss           | 0.00691     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 2226        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030956201 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0832     |\n",
      "|    n_updates            | 1884        |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    std                  | 0.384       |\n",
      "|    value_loss           | 0.0182      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 2232        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031009557 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0874     |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    std                  | 0.383       |\n",
      "|    value_loss           | 0.0089      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 2237        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037141778 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 1896        |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    std                  | 0.383       |\n",
      "|    value_loss           | 0.00486     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=51.21 +/- 14.27\n",
      "Episode length: 880.40 +/- 239.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 880         |\n",
      "|    mean_reward          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032591708 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0947     |\n",
      "|    n_updates            | 1902        |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    std                  | 0.381       |\n",
      "|    value_loss           | 0.00463     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 318    |\n",
      "|    time_elapsed    | 2249   |\n",
      "|    total_timesteps | 651264 |\n",
      "-------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 319       |\n",
      "|    time_elapsed         | 2255      |\n",
      "|    total_timesteps      | 653312    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0297751 |\n",
      "|    clip_fraction        | 0.0503    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -3.61     |\n",
      "|    explained_variance   | 0.564     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.0889   |\n",
      "|    n_updates            | 1908      |\n",
      "|    policy_gradient_loss | -0.0434   |\n",
      "|    std                  | 0.38      |\n",
      "|    value_loss           | 0.00777   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 2261        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029154705 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.59       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0667     |\n",
      "|    n_updates            | 1914        |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    std                  | 0.379       |\n",
      "|    value_loss           | 0.0396      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 2267        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032481115 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0998     |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    std                  | 0.378       |\n",
      "|    value_loss           | 0.00393     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 2272        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027067397 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0814     |\n",
      "|    n_updates            | 1926        |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    std                  | 0.377       |\n",
      "|    value_loss           | 0.00882     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=46.57 +/- 10.23\n",
      "Episode length: 829.60 +/- 214.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 830         |\n",
      "|    mean_reward          | 46.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 660000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033610605 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0879     |\n",
      "|    n_updates            | 1932        |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    std                  | 0.376       |\n",
      "|    value_loss           | 0.0165      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 323    |\n",
      "|    time_elapsed    | 2283   |\n",
      "|    total_timesteps | 661504 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 2288        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030597521 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0942     |\n",
      "|    n_updates            | 1938        |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    std                  | 0.375       |\n",
      "|    value_loss           | 0.0099      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 2294        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033773012 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0931     |\n",
      "|    n_updates            | 1944        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    std                  | 0.374       |\n",
      "|    value_loss           | 0.0153      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 2300        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033532567 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.075      |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    std                  | 0.374       |\n",
      "|    value_loss           | 0.0284      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 2305        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034998685 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0827     |\n",
      "|    n_updates            | 1956        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.373       |\n",
      "|    value_loss           | 0.0149      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=48.69 +/- 12.52\n",
      "Episode length: 879.00 +/- 242.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 879         |\n",
      "|    mean_reward          | 48.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 670000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029260077 |\n",
      "|    clip_fraction        | 0.0601      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0762     |\n",
      "|    n_updates            | 1962        |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    std                  | 0.372       |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 289    |\n",
      "|    iterations      | 328    |\n",
      "|    time_elapsed    | 2316   |\n",
      "|    total_timesteps | 671744 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 2321        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031119078 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0893     |\n",
      "|    n_updates            | 1968        |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    std                  | 0.371       |\n",
      "|    value_loss           | 0.00593     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 330        |\n",
      "|    time_elapsed         | 2327       |\n",
      "|    total_timesteps      | 675840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03364307 |\n",
      "|    clip_fraction        | 0.0661     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -3.39      |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0619    |\n",
      "|    n_updates            | 1974       |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    std                  | 0.37       |\n",
      "|    value_loss           | 0.021      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 2333        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030514432 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0827     |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    std                  | 0.37        |\n",
      "|    value_loss           | 0.0116      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 2338        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027882995 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0715     |\n",
      "|    n_updates            | 1986        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    std                  | 0.369       |\n",
      "|    value_loss           | 0.017       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=52.05 +/- 1.52\n",
      "Episode length: 991.80 +/- 16.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 992         |\n",
      "|    mean_reward          | 52          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 680000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031202326 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0807     |\n",
      "|    n_updates            | 1992        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 0.368       |\n",
      "|    value_loss           | 0.0193      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 333    |\n",
      "|    time_elapsed    | 2350   |\n",
      "|    total_timesteps | 681984 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 2355        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035438042 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0953     |\n",
      "|    n_updates            | 1998        |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    std                  | 0.367       |\n",
      "|    value_loss           | 0.0075      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 2361        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040154815 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0917     |\n",
      "|    n_updates            | 2004        |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    std                  | 0.366       |\n",
      "|    value_loss           | 0.00562     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 336        |\n",
      "|    time_elapsed         | 2366       |\n",
      "|    total_timesteps      | 688128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03174447 |\n",
      "|    clip_fraction        | 0.0559     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -3.29      |\n",
      "|    explained_variance   | 0.586      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0697    |\n",
      "|    n_updates            | 2010       |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    std                  | 0.365      |\n",
      "|    value_loss           | 0.00609    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=54.75 +/- 2.41\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 54.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027977362 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.058      |\n",
      "|    n_updates            | 2016        |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 0.0146      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 337    |\n",
      "|    time_elapsed    | 2378   |\n",
      "|    total_timesteps | 690176 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 2384        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036496397 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.112      |\n",
      "|    n_updates            | 2022        |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 0.00489     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 2389        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033601582 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0913     |\n",
      "|    n_updates            | 2028        |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 0.00346     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 2395       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03244838 |\n",
      "|    clip_fraction        | 0.0579     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -3.19      |\n",
      "|    explained_variance   | 0.667      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.087     |\n",
      "|    n_updates            | 2034       |\n",
      "|    policy_gradient_loss | -0.0427    |\n",
      "|    std                  | 0.36       |\n",
      "|    value_loss           | 0.00846    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 2400        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035523247 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0931     |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    std                  | 0.359       |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=50.20 +/- 7.23\n",
      "Episode length: 909.40 +/- 137.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 909         |\n",
      "|    mean_reward          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035213202 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0622     |\n",
      "|    n_updates            | 2046        |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    std                  | 0.358       |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 342    |\n",
      "|    time_elapsed    | 2412   |\n",
      "|    total_timesteps | 700416 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 2417        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041790463 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0882     |\n",
      "|    n_updates            | 2052        |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    std                  | 0.356       |\n",
      "|    value_loss           | 0.00785     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 344        |\n",
      "|    time_elapsed         | 2423       |\n",
      "|    total_timesteps      | 704512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03441342 |\n",
      "|    clip_fraction        | 0.0619     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -3.08      |\n",
      "|    explained_variance   | 0.458      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0769    |\n",
      "|    n_updates            | 2058       |\n",
      "|    policy_gradient_loss | -0.037     |\n",
      "|    std                  | 0.355      |\n",
      "|    value_loss           | 0.0162     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 2428        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034984656 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.05       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0889     |\n",
      "|    n_updates            | 2064        |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    std                  | 0.354       |\n",
      "|    value_loss           | 0.00515     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 346        |\n",
      "|    time_elapsed         | 2433       |\n",
      "|    total_timesteps      | 708608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03303223 |\n",
      "|    clip_fraction        | 0.0522     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -3.02      |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0927    |\n",
      "|    n_updates            | 2070       |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    std                  | 0.353      |\n",
      "|    value_loss           | 0.00808    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=55.45 +/- 4.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 710000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032455876 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0729     |\n",
      "|    n_updates            | 2076        |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    std                  | 0.353       |\n",
      "|    value_loss           | 0.00965     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 347    |\n",
      "|    time_elapsed    | 2446   |\n",
      "|    total_timesteps | 710656 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 2451        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028175859 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0711     |\n",
      "|    n_updates            | 2082        |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    std                  | 0.351       |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 2457        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036947522 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0613     |\n",
      "|    n_updates            | 2088        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    std                  | 0.35        |\n",
      "|    value_loss           | 0.0234      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 2462        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030824294 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0775     |\n",
      "|    n_updates            | 2094        |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    std                  | 0.349       |\n",
      "|    value_loss           | 0.0108      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 351        |\n",
      "|    time_elapsed         | 2467       |\n",
      "|    total_timesteps      | 718848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03412891 |\n",
      "|    clip_fraction        | 0.0582     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.92      |\n",
      "|    explained_variance   | 0.177      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.086     |\n",
      "|    n_updates            | 2100       |\n",
      "|    policy_gradient_loss | -0.041     |\n",
      "|    std                  | 0.348      |\n",
      "|    value_loss           | 0.00623    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=52.18 +/- 3.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 52.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 720000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032833226 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0865     |\n",
      "|    n_updates            | 2106        |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    std                  | 0.347       |\n",
      "|    value_loss           | 0.00449     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 352    |\n",
      "|    time_elapsed    | 2480   |\n",
      "|    total_timesteps | 720896 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 2485        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033149123 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0899     |\n",
      "|    n_updates            | 2112        |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    std                  | 0.346       |\n",
      "|    value_loss           | 0.00881     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 2490        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034106843 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0843     |\n",
      "|    n_updates            | 2118        |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    std                  | 0.346       |\n",
      "|    value_loss           | 0.00714     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 2496        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034889314 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0991     |\n",
      "|    n_updates            | 2124        |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    std                  | 0.344       |\n",
      "|    value_loss           | 0.00812     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 356        |\n",
      "|    time_elapsed         | 2501       |\n",
      "|    total_timesteps      | 729088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03793935 |\n",
      "|    clip_fraction        | 0.0708     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.8       |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0684    |\n",
      "|    n_updates            | 2130       |\n",
      "|    policy_gradient_loss | -0.0431    |\n",
      "|    std                  | 0.343      |\n",
      "|    value_loss           | 0.0106     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=44.42 +/- 16.70\n",
      "Episode length: 839.00 +/- 322.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 839         |\n",
      "|    mean_reward          | 44.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 730000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037107468 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0707     |\n",
      "|    n_updates            | 2136        |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    std                  | 0.343       |\n",
      "|    value_loss           | 0.00614     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 290    |\n",
      "|    iterations      | 357    |\n",
      "|    time_elapsed    | 2513   |\n",
      "|    total_timesteps | 731136 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 2518        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036131218 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0701     |\n",
      "|    n_updates            | 2142        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    std                  | 0.342       |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 359        |\n",
      "|    time_elapsed         | 2523       |\n",
      "|    total_timesteps      | 735232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03553368 |\n",
      "|    clip_fraction        | 0.0603     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.74      |\n",
      "|    explained_variance   | 0.546      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0883    |\n",
      "|    n_updates            | 2148       |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    std                  | 0.341      |\n",
      "|    value_loss           | 0.00588    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 2529        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035446193 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0842     |\n",
      "|    n_updates            | 2154        |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    std                  | 0.34        |\n",
      "|    value_loss           | 0.00828     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 2534        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048061166 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0957     |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.0502     |\n",
      "|    std                  | 0.339       |\n",
      "|    value_loss           | 0.00269     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=54.86 +/- 2.82\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 54.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037969533 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0895     |\n",
      "|    n_updates            | 2166        |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    std                  | 0.338       |\n",
      "|    value_loss           | 0.00809     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 362    |\n",
      "|    time_elapsed    | 2546   |\n",
      "|    total_timesteps | 741376 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 2552        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034371294 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.094      |\n",
      "|    n_updates            | 2172        |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    std                  | 0.337       |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 2557        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033295225 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0882     |\n",
      "|    n_updates            | 2178        |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    std                  | 0.336       |\n",
      "|    value_loss           | 0.00375     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 2562        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038420245 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0967     |\n",
      "|    n_updates            | 2184        |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    std                  | 0.335       |\n",
      "|    value_loss           | 0.00521     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 366        |\n",
      "|    time_elapsed         | 2568       |\n",
      "|    total_timesteps      | 749568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03783842 |\n",
      "|    clip_fraction        | 0.07       |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.59      |\n",
      "|    explained_variance   | 0.677      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0747    |\n",
      "|    n_updates            | 2190       |\n",
      "|    policy_gradient_loss | -0.041     |\n",
      "|    std                  | 0.335      |\n",
      "|    value_loss           | 0.0157     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=46.20 +/- 16.81\n",
      "Episode length: 840.40 +/- 319.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 840         |\n",
      "|    mean_reward          | 46.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037038602 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0903     |\n",
      "|    n_updates            | 2196        |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    std                  | 0.334       |\n",
      "|    value_loss           | 0.00742     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 367    |\n",
      "|    time_elapsed    | 2579   |\n",
      "|    total_timesteps | 751616 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 2585        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038987555 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0993     |\n",
      "|    n_updates            | 2202        |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    std                  | 0.333       |\n",
      "|    value_loss           | 0.00572     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 2590        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036511876 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0875     |\n",
      "|    n_updates            | 2208        |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    std                  | 0.332       |\n",
      "|    value_loss           | 0.00378     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 2595        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032349862 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0629     |\n",
      "|    n_updates            | 2214        |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    std                  | 0.331       |\n",
      "|    value_loss           | 0.0174      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 371        |\n",
      "|    time_elapsed         | 2601       |\n",
      "|    total_timesteps      | 759808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03902241 |\n",
      "|    clip_fraction        | 0.0785     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.5       |\n",
      "|    explained_variance   | 0.645      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0806    |\n",
      "|    n_updates            | 2220       |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    std                  | 0.331      |\n",
      "|    value_loss           | 0.0161     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=59.73 +/- 1.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 59.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034455843 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0903     |\n",
      "|    n_updates            | 2226        |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 0.331       |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 372    |\n",
      "|    time_elapsed    | 2613   |\n",
      "|    total_timesteps | 761856 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 2619        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033620782 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 2232        |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    std                  | 0.33        |\n",
      "|    value_loss           | 0.0109      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 2624        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039452367 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.47       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.094      |\n",
      "|    n_updates            | 2238        |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    std                  | 0.33        |\n",
      "|    value_loss           | 0.00339     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 2629        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038449667 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.08       |\n",
      "|    n_updates            | 2244        |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    std                  | 0.329       |\n",
      "|    value_loss           | 0.0055      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=55.22 +/- 2.95\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 770000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039614484 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0809     |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    std                  | 0.328       |\n",
      "|    value_loss           | 0.00783     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 376    |\n",
      "|    time_elapsed    | 2641   |\n",
      "|    total_timesteps | 770048 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 2647        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031230906 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0866     |\n",
      "|    n_updates            | 2256        |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.327       |\n",
      "|    value_loss           | 0.0098      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 2652        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040540144 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.39       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0711     |\n",
      "|    n_updates            | 2262        |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    std                  | 0.326       |\n",
      "|    value_loss           | 0.0203      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 379        |\n",
      "|    time_elapsed         | 2658       |\n",
      "|    total_timesteps      | 776192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04258303 |\n",
      "|    clip_fraction        | 0.0805     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.38      |\n",
      "|    explained_variance   | 0.593      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0892    |\n",
      "|    n_updates            | 2268       |\n",
      "|    policy_gradient_loss | -0.0474    |\n",
      "|    std                  | 0.326      |\n",
      "|    value_loss           | 0.00628    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 2663        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036975764 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.35       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0981     |\n",
      "|    n_updates            | 2274        |\n",
      "|    policy_gradient_loss | -0.0513     |\n",
      "|    std                  | 0.325       |\n",
      "|    value_loss           | 0.00553     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=55.09 +/- 3.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 780000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030465566 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0848     |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    std                  | 0.324       |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 381    |\n",
      "|    time_elapsed    | 2675   |\n",
      "|    total_timesteps | 780288 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 2681        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036542878 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0823     |\n",
      "|    n_updates            | 2286        |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 0.00475     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 2686        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040553745 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.105      |\n",
      "|    n_updates            | 2292        |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 2692        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040145356 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0898     |\n",
      "|    n_updates            | 2298        |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 0.0125      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 2697        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032788724 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0607     |\n",
      "|    n_updates            | 2304        |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 0.0162      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=57.77 +/- 3.34\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 57.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 790000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033279397 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0829     |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 0.0191      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 386    |\n",
      "|    time_elapsed    | 2709   |\n",
      "|    total_timesteps | 790528 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 387        |\n",
      "|    time_elapsed         | 2714       |\n",
      "|    total_timesteps      | 792576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03693872 |\n",
      "|    clip_fraction        | 0.0704     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.29      |\n",
      "|    explained_variance   | 0.603      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0749    |\n",
      "|    n_updates            | 2316       |\n",
      "|    policy_gradient_loss | -0.0374    |\n",
      "|    std                  | 0.322      |\n",
      "|    value_loss           | 0.017      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 388        |\n",
      "|    time_elapsed         | 2720       |\n",
      "|    total_timesteps      | 794624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03899051 |\n",
      "|    clip_fraction        | 0.0767     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.28      |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0725    |\n",
      "|    n_updates            | 2322       |\n",
      "|    policy_gradient_loss | -0.038     |\n",
      "|    std                  | 0.321      |\n",
      "|    value_loss           | 0.0107     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 292       |\n",
      "|    iterations           | 389       |\n",
      "|    time_elapsed         | 2725      |\n",
      "|    total_timesteps      | 796672    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0424712 |\n",
      "|    clip_fraction        | 0.0737    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -2.25     |\n",
      "|    explained_variance   | 0.715     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.0871   |\n",
      "|    n_updates            | 2328      |\n",
      "|    policy_gradient_loss | -0.0417   |\n",
      "|    std                  | 0.321     |\n",
      "|    value_loss           | 0.00634   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 2731        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041854307 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.085      |\n",
      "|    n_updates            | 2334        |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    std                  | 0.319       |\n",
      "|    value_loss           | 0.0051      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=56.53 +/- 5.37\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 56.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 800000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04283382 |\n",
      "|    clip_fraction        | 0.0958     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.2       |\n",
      "|    explained_variance   | 0.702      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 2340       |\n",
      "|    policy_gradient_loss | -0.0449    |\n",
      "|    std                  | 0.318      |\n",
      "|    value_loss           | 0.00954    |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 391    |\n",
      "|    time_elapsed    | 2743   |\n",
      "|    total_timesteps | 800768 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 392        |\n",
      "|    time_elapsed         | 2748       |\n",
      "|    total_timesteps      | 802816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03567657 |\n",
      "|    clip_fraction        | 0.0754     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.18      |\n",
      "|    explained_variance   | 0.528      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.064     |\n",
      "|    n_updates            | 2346       |\n",
      "|    policy_gradient_loss | -0.0367    |\n",
      "|    std                  | 0.318      |\n",
      "|    value_loss           | 0.0224     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 393        |\n",
      "|    time_elapsed         | 2754       |\n",
      "|    total_timesteps      | 804864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04198464 |\n",
      "|    clip_fraction        | 0.0914     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.16      |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0554    |\n",
      "|    n_updates            | 2352       |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    std                  | 0.317      |\n",
      "|    value_loss           | 0.0336     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 2759        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041804053 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.09       |\n",
      "|    n_updates            | 2358        |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    std                  | 0.316       |\n",
      "|    value_loss           | 0.0125      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 2765        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039235644 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0972     |\n",
      "|    n_updates            | 2364        |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 0.00895     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=57.64 +/- 2.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 57.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 810000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04150947 |\n",
      "|    clip_fraction        | 0.0869     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.1       |\n",
      "|    explained_variance   | 0.619      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0661    |\n",
      "|    n_updates            | 2370       |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    std                  | 0.314      |\n",
      "|    value_loss           | 0.0115     |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 291    |\n",
      "|    iterations      | 396    |\n",
      "|    time_elapsed    | 2777   |\n",
      "|    total_timesteps | 811008 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 397        |\n",
      "|    time_elapsed         | 2782       |\n",
      "|    total_timesteps      | 813056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04092069 |\n",
      "|    clip_fraction        | 0.084      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.07      |\n",
      "|    explained_variance   | 0.63       |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.086     |\n",
      "|    n_updates            | 2376       |\n",
      "|    policy_gradient_loss | -0.0474    |\n",
      "|    std                  | 0.313      |\n",
      "|    value_loss           | 0.00434    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 398        |\n",
      "|    time_elapsed         | 2788       |\n",
      "|    total_timesteps      | 815104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04313166 |\n",
      "|    clip_fraction        | 0.0837     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -2.05      |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 2382       |\n",
      "|    policy_gradient_loss | -0.0472    |\n",
      "|    std                  | 0.312      |\n",
      "|    value_loss           | 0.00571    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 2793        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041518025 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0684     |\n",
      "|    n_updates            | 2388        |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 0.0147      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 2798        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038318772 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0849     |\n",
      "|    n_updates            | 2394        |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 0.00431     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=55.84 +/- 1.50\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 55.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033335805 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0864     |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    std                  | 0.309       |\n",
      "|    value_loss           | 0.00858     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 292    |\n",
      "|    iterations      | 401    |\n",
      "|    time_elapsed    | 2811   |\n",
      "|    total_timesteps | 821248 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 2816        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034889266 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0842     |\n",
      "|    n_updates            | 2406        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    std                  | 0.308       |\n",
      "|    value_loss           | 0.0147      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 403        |\n",
      "|    time_elapsed         | 2822       |\n",
      "|    total_timesteps      | 825344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04007015 |\n",
      "|    clip_fraction        | 0.0753     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.92      |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0586    |\n",
      "|    n_updates            | 2412       |\n",
      "|    policy_gradient_loss | -0.0365    |\n",
      "|    std                  | 0.308      |\n",
      "|    value_loss           | 0.0135     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 404        |\n",
      "|    time_elapsed         | 2827       |\n",
      "|    total_timesteps      | 827392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03646634 |\n",
      "|    clip_fraction        | 0.0829     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0624    |\n",
      "|    n_updates            | 2418       |\n",
      "|    policy_gradient_loss | -0.0386    |\n",
      "|    std                  | 0.307      |\n",
      "|    value_loss           | 0.0158     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 292       |\n",
      "|    iterations           | 405       |\n",
      "|    time_elapsed         | 2832      |\n",
      "|    total_timesteps      | 829440    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0449574 |\n",
      "|    clip_fraction        | 0.0799    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -1.9      |\n",
      "|    explained_variance   | 0.64      |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.101    |\n",
      "|    n_updates            | 2424      |\n",
      "|    policy_gradient_loss | -0.0501   |\n",
      "|    std                  | 0.307     |\n",
      "|    value_loss           | 0.00494   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=56.68 +/- 3.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 56.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 830000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042442292 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.103      |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    std                  | 0.306       |\n",
      "|    value_loss           | 0.00555     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 292    |\n",
      "|    iterations      | 406    |\n",
      "|    time_elapsed    | 2845   |\n",
      "|    total_timesteps | 831488 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 407        |\n",
      "|    time_elapsed         | 2850       |\n",
      "|    total_timesteps      | 833536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04058347 |\n",
      "|    clip_fraction        | 0.091      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.717      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0912    |\n",
      "|    n_updates            | 2436       |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    std                  | 0.306      |\n",
      "|    value_loss           | 0.0108     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 292       |\n",
      "|    iterations           | 408       |\n",
      "|    time_elapsed         | 2855      |\n",
      "|    total_timesteps      | 835584    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0377832 |\n",
      "|    clip_fraction        | 0.0951    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -1.86     |\n",
      "|    explained_variance   | 0.773     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.084    |\n",
      "|    n_updates            | 2442      |\n",
      "|    policy_gradient_loss | -0.0475   |\n",
      "|    std                  | 0.305     |\n",
      "|    value_loss           | 0.0117    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 2861        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042811804 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.103      |\n",
      "|    n_updates            | 2448        |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    std                  | 0.305       |\n",
      "|    value_loss           | 0.0044      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 2866        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041655377 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0722     |\n",
      "|    n_updates            | 2454        |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    std                  | 0.305       |\n",
      "|    value_loss           | 0.0217      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=46.89 +/- 15.56\n",
      "Episode length: 860.00 +/- 280.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 860         |\n",
      "|    mean_reward          | 46.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 840000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051837783 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.106      |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0553     |\n",
      "|    std                  | 0.304       |\n",
      "|    value_loss           | 0.00458     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 292    |\n",
      "|    iterations      | 411    |\n",
      "|    time_elapsed    | 2877   |\n",
      "|    total_timesteps | 841728 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 2883        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042548917 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0908     |\n",
      "|    n_updates            | 2466        |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    std                  | 0.303       |\n",
      "|    value_loss           | 0.00633     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 413        |\n",
      "|    time_elapsed         | 2888       |\n",
      "|    total_timesteps      | 845824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03896778 |\n",
      "|    clip_fraction        | 0.0875     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.8       |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0853    |\n",
      "|    n_updates            | 2472       |\n",
      "|    policy_gradient_loss | -0.0463    |\n",
      "|    std                  | 0.303      |\n",
      "|    value_loss           | 0.0122     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 292       |\n",
      "|    iterations           | 414       |\n",
      "|    time_elapsed         | 2893      |\n",
      "|    total_timesteps      | 847872    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0420535 |\n",
      "|    clip_fraction        | 0.0781    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -1.78     |\n",
      "|    explained_variance   | 0.756     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.0909   |\n",
      "|    n_updates            | 2478      |\n",
      "|    policy_gradient_loss | -0.0504   |\n",
      "|    std                  | 0.302     |\n",
      "|    value_loss           | 0.00488   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 2899        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037774198 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.072      |\n",
      "|    n_updates            | 2484        |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    std                  | 0.301       |\n",
      "|    value_loss           | 0.0136      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=52.60 +/- 3.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 52.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 850000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03857165 |\n",
      "|    clip_fraction        | 0.0832     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.74      |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0637    |\n",
      "|    n_updates            | 2490       |\n",
      "|    policy_gradient_loss | -0.0372    |\n",
      "|    std                  | 0.301      |\n",
      "|    value_loss           | 0.0282     |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 292    |\n",
      "|    iterations      | 416    |\n",
      "|    time_elapsed    | 2911   |\n",
      "|    total_timesteps | 851968 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 417        |\n",
      "|    time_elapsed         | 2917       |\n",
      "|    total_timesteps      | 854016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04558923 |\n",
      "|    clip_fraction        | 0.0982     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.73      |\n",
      "|    explained_variance   | 0.629      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0698    |\n",
      "|    n_updates            | 2496       |\n",
      "|    policy_gradient_loss | -0.044     |\n",
      "|    std                  | 0.3        |\n",
      "|    value_loss           | 0.0214     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 418        |\n",
      "|    time_elapsed         | 2922       |\n",
      "|    total_timesteps      | 856064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04150583 |\n",
      "|    clip_fraction        | 0.0786     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | 0.754      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0968    |\n",
      "|    n_updates            | 2502       |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    std                  | 0.3        |\n",
      "|    value_loss           | 0.00454    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 293       |\n",
      "|    iterations           | 419       |\n",
      "|    time_elapsed         | 2928      |\n",
      "|    total_timesteps      | 858112    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0391267 |\n",
      "|    clip_fraction        | 0.0745    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -1.7      |\n",
      "|    explained_variance   | 0.772     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.082    |\n",
      "|    n_updates            | 2508      |\n",
      "|    policy_gradient_loss | -0.0477   |\n",
      "|    std                  | 0.299     |\n",
      "|    value_loss           | 0.00806   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=51.57 +/- 4.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 51.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 860000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040773056 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0928     |\n",
      "|    n_updates            | 2514        |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    std                  | 0.298       |\n",
      "|    value_loss           | 0.00783     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 292    |\n",
      "|    iterations      | 420    |\n",
      "|    time_elapsed    | 2940   |\n",
      "|    total_timesteps | 860160 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 2945        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041228186 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0579     |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    std                  | 0.298       |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 2950        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038733006 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0783     |\n",
      "|    n_updates            | 2526        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.298       |\n",
      "|    value_loss           | 0.0157      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 423        |\n",
      "|    time_elapsed         | 2956       |\n",
      "|    total_timesteps      | 866304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03976778 |\n",
      "|    clip_fraction        | 0.0925     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | 0.776      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.096     |\n",
      "|    n_updates            | 2532       |\n",
      "|    policy_gradient_loss | -0.0443    |\n",
      "|    std                  | 0.297      |\n",
      "|    value_loss           | 0.0121     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 424        |\n",
      "|    time_elapsed         | 2961       |\n",
      "|    total_timesteps      | 868352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04304886 |\n",
      "|    clip_fraction        | 0.0897     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.64      |\n",
      "|    explained_variance   | 0.492      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0556    |\n",
      "|    n_updates            | 2538       |\n",
      "|    policy_gradient_loss | -0.0377    |\n",
      "|    std                  | 0.297      |\n",
      "|    value_loss           | 0.0374     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=44.84 +/- 15.51\n",
      "Episode length: 851.60 +/- 296.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 852         |\n",
      "|    mean_reward          | 44.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045844123 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0988     |\n",
      "|    n_updates            | 2544        |\n",
      "|    policy_gradient_loss | -0.0499     |\n",
      "|    std                  | 0.297       |\n",
      "|    value_loss           | 0.00429     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 292    |\n",
      "|    iterations      | 425    |\n",
      "|    time_elapsed    | 2972   |\n",
      "|    total_timesteps | 870400 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 2978        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041478973 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0768     |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    std                  | 0.296       |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 2983        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034118142 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0902     |\n",
      "|    n_updates            | 2556        |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.295       |\n",
      "|    value_loss           | 0.0156      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 2989        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048767403 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0986     |\n",
      "|    n_updates            | 2562        |\n",
      "|    policy_gradient_loss | -0.051      |\n",
      "|    std                  | 0.294       |\n",
      "|    value_loss           | 0.00533     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 293       |\n",
      "|    iterations           | 429       |\n",
      "|    time_elapsed         | 2994      |\n",
      "|    total_timesteps      | 878592    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0398785 |\n",
      "|    clip_fraction        | 0.0846    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -1.55     |\n",
      "|    explained_variance   | 0.66      |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.0877   |\n",
      "|    n_updates            | 2568      |\n",
      "|    policy_gradient_loss | -0.0473   |\n",
      "|    std                  | 0.293     |\n",
      "|    value_loss           | 0.00934   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=52.87 +/- 4.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 52.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048387755 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0619     |\n",
      "|    n_updates            | 2574        |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    std                  | 0.293       |\n",
      "|    value_loss           | 0.0243      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 292    |\n",
      "|    iterations      | 430    |\n",
      "|    time_elapsed    | 3006   |\n",
      "|    total_timesteps | 880640 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 431        |\n",
      "|    time_elapsed         | 3012       |\n",
      "|    total_timesteps      | 882688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04190018 |\n",
      "|    clip_fraction        | 0.0867     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.52      |\n",
      "|    explained_variance   | 0.623      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0813    |\n",
      "|    n_updates            | 2580       |\n",
      "|    policy_gradient_loss | -0.0442    |\n",
      "|    std                  | 0.292      |\n",
      "|    value_loss           | 0.0198     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 3017        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046433818 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 2586        |\n",
      "|    policy_gradient_loss | -0.0491     |\n",
      "|    std                  | 0.292       |\n",
      "|    value_loss           | 0.0052      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 3023        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043841925 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.092      |\n",
      "|    n_updates            | 2592        |\n",
      "|    policy_gradient_loss | -0.0502     |\n",
      "|    std                  | 0.291       |\n",
      "|    value_loss           | 0.00772     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 434        |\n",
      "|    time_elapsed         | 3028       |\n",
      "|    total_timesteps      | 888832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04845888 |\n",
      "|    clip_fraction        | 0.0914     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0812    |\n",
      "|    n_updates            | 2598       |\n",
      "|    policy_gradient_loss | -0.0483    |\n",
      "|    std                  | 0.29       |\n",
      "|    value_loss           | 0.0119     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=52.44 +/- 3.84\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 52.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043556437 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0983     |\n",
      "|    n_updates            | 2604        |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 292    |\n",
      "|    iterations      | 435    |\n",
      "|    time_elapsed    | 3040   |\n",
      "|    total_timesteps | 890880 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 3046        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045156438 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0863     |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.0494     |\n",
      "|    std                  | 0.288       |\n",
      "|    value_loss           | 0.00633     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 3051        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048071656 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0984     |\n",
      "|    n_updates            | 2616        |\n",
      "|    policy_gradient_loss | -0.0504     |\n",
      "|    std                  | 0.287       |\n",
      "|    value_loss           | 0.00713     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 3057        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041361913 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0847     |\n",
      "|    n_updates            | 2622        |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    std                  | 0.287       |\n",
      "|    value_loss           | 0.0046      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 3062        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041150253 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 2628        |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    std                  | 0.286       |\n",
      "|    value_loss           | 0.00486     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=51.14 +/- 5.70\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 51.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050012924 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.1        |\n",
      "|    n_updates            | 2634        |\n",
      "|    policy_gradient_loss | -0.0513     |\n",
      "|    std                  | 0.286       |\n",
      "|    value_loss           | 0.00657     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 440    |\n",
      "|    time_elapsed    | 3074   |\n",
      "|    total_timesteps | 901120 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 441        |\n",
      "|    time_elapsed         | 3080       |\n",
      "|    total_timesteps      | 903168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04369857 |\n",
      "|    clip_fraction        | 0.0866     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.819      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0876    |\n",
      "|    n_updates            | 2640       |\n",
      "|    policy_gradient_loss | -0.0484    |\n",
      "|    std                  | 0.285      |\n",
      "|    value_loss           | 0.0106     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 3085        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047202073 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.1        |\n",
      "|    n_updates            | 2646        |\n",
      "|    policy_gradient_loss | -0.0526     |\n",
      "|    std                  | 0.284       |\n",
      "|    value_loss           | 0.00444     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 293       |\n",
      "|    iterations           | 443       |\n",
      "|    time_elapsed         | 3090      |\n",
      "|    total_timesteps      | 907264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0439934 |\n",
      "|    clip_fraction        | 0.0887    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -1.28     |\n",
      "|    explained_variance   | 0.877     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.0899   |\n",
      "|    n_updates            | 2652      |\n",
      "|    policy_gradient_loss | -0.0517   |\n",
      "|    std                  | 0.283     |\n",
      "|    value_loss           | 0.0026    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 3096        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042682365 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0985     |\n",
      "|    n_updates            | 2658        |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    std                  | 0.283       |\n",
      "|    value_loss           | 0.00511     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=52.28 +/- 3.52\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 52.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 910000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03946944 |\n",
      "|    clip_fraction        | 0.0806     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | 0.796      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0965    |\n",
      "|    n_updates            | 2664       |\n",
      "|    policy_gradient_loss | -0.046     |\n",
      "|    std                  | 0.282      |\n",
      "|    value_loss           | 0.00986    |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 445    |\n",
      "|    time_elapsed    | 3108   |\n",
      "|    total_timesteps | 911360 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 446        |\n",
      "|    time_elapsed         | 3114       |\n",
      "|    total_timesteps      | 913408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04903976 |\n",
      "|    clip_fraction        | 0.0953     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.898      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0911    |\n",
      "|    n_updates            | 2670       |\n",
      "|    policy_gradient_loss | -0.0509    |\n",
      "|    std                  | 0.281      |\n",
      "|    value_loss           | 0.0031     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 293       |\n",
      "|    iterations           | 447       |\n",
      "|    time_elapsed         | 3119      |\n",
      "|    total_timesteps      | 915456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0388453 |\n",
      "|    clip_fraction        | 0.0765    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -1.2      |\n",
      "|    explained_variance   | 0.905     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.0665   |\n",
      "|    n_updates            | 2676      |\n",
      "|    policy_gradient_loss | -0.0431   |\n",
      "|    std                  | 0.281     |\n",
      "|    value_loss           | 0.00697   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 448        |\n",
      "|    time_elapsed         | 3125       |\n",
      "|    total_timesteps      | 917504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05035108 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.902      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 2682       |\n",
      "|    policy_gradient_loss | -0.0546    |\n",
      "|    std                  | 0.28       |\n",
      "|    value_loss           | 0.00467    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 449        |\n",
      "|    time_elapsed         | 3130       |\n",
      "|    total_timesteps      | 919552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04629312 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 2688       |\n",
      "|    policy_gradient_loss | -0.0505    |\n",
      "|    std                  | 0.28       |\n",
      "|    value_loss           | 0.00675    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=52.02 +/- 6.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 52         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 920000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03956934 |\n",
      "|    clip_fraction        | 0.0841     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.726      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0637    |\n",
      "|    n_updates            | 2694       |\n",
      "|    policy_gradient_loss | -0.0389    |\n",
      "|    std                  | 0.279      |\n",
      "|    value_loss           | 0.0206     |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 450    |\n",
      "|    time_elapsed    | 3143   |\n",
      "|    total_timesteps | 921600 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 3148        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049561486 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0904     |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.0512     |\n",
      "|    std                  | 0.278       |\n",
      "|    value_loss           | 0.00625     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 3154        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041875534 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.06       |\n",
      "|    n_updates            | 2706        |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    std                  | 0.278       |\n",
      "|    value_loss           | 0.0258      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 3159        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048866957 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0964     |\n",
      "|    n_updates            | 2712        |\n",
      "|    policy_gradient_loss | -0.0492     |\n",
      "|    std                  | 0.277       |\n",
      "|    value_loss           | 0.00934     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 3164        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043831386 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0694     |\n",
      "|    n_updates            | 2718        |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    std                  | 0.276       |\n",
      "|    value_loss           | 0.00983     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=52.92 +/- 5.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 52.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 930000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05335731 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.862      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0986    |\n",
      "|    n_updates            | 2724       |\n",
      "|    policy_gradient_loss | -0.0503    |\n",
      "|    std                  | 0.276      |\n",
      "|    value_loss           | 0.00343    |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 455    |\n",
      "|    time_elapsed    | 3177   |\n",
      "|    total_timesteps | 931840 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 3182        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047856018 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0627     |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 0.276       |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 3188        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049408365 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.095      |\n",
      "|    n_updates            | 2736        |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    std                  | 0.275       |\n",
      "|    value_loss           | 0.00499     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 458        |\n",
      "|    time_elapsed         | 3193       |\n",
      "|    total_timesteps      | 937984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04610654 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0.836      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0932    |\n",
      "|    n_updates            | 2742       |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    std                  | 0.275      |\n",
      "|    value_loss           | 0.00676    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=50.61 +/- 4.87\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 50.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 940000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042822715 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0944     |\n",
      "|    n_updates            | 2748        |\n",
      "|    policy_gradient_loss | -0.0511     |\n",
      "|    std                  | 0.274       |\n",
      "|    value_loss           | 0.00789     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 459    |\n",
      "|    time_elapsed    | 3206   |\n",
      "|    total_timesteps | 940032 |\n",
      "-------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 293       |\n",
      "|    iterations           | 460       |\n",
      "|    time_elapsed         | 3211      |\n",
      "|    total_timesteps      | 942080    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0439934 |\n",
      "|    clip_fraction        | 0.0879    |\n",
      "|    clip_range           | 0.332     |\n",
      "|    entropy_loss         | -0.983    |\n",
      "|    explained_variance   | 0.817     |\n",
      "|    learning_rate        | 0.000356  |\n",
      "|    loss                 | -0.0777   |\n",
      "|    n_updates            | 2754      |\n",
      "|    policy_gradient_loss | -0.0481   |\n",
      "|    std                  | 0.273     |\n",
      "|    value_loss           | 0.00292   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 461        |\n",
      "|    time_elapsed         | 3216       |\n",
      "|    total_timesteps      | 944128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04805273 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -0.958     |\n",
      "|    explained_variance   | 0.568      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0602    |\n",
      "|    n_updates            | 2760       |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    std                  | 0.273      |\n",
      "|    value_loss           | 0.0335     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 462        |\n",
      "|    time_elapsed         | 3222       |\n",
      "|    total_timesteps      | 946176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04407799 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -0.939     |\n",
      "|    explained_variance   | 0.751      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0774    |\n",
      "|    n_updates            | 2766       |\n",
      "|    policy_gradient_loss | -0.0446    |\n",
      "|    std                  | 0.272      |\n",
      "|    value_loss           | 0.0199     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 3227        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046386257 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0672     |\n",
      "|    n_updates            | 2772        |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 0.271       |\n",
      "|    value_loss           | 0.0143      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=41.70 +/- 18.51\n",
      "Episode length: 818.80 +/- 362.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 819         |\n",
      "|    mean_reward          | 41.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051688775 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0964     |\n",
      "|    n_updates            | 2778        |\n",
      "|    policy_gradient_loss | -0.0529     |\n",
      "|    std                  | 0.271       |\n",
      "|    value_loss           | 0.00375     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 464    |\n",
      "|    time_elapsed    | 3238   |\n",
      "|    total_timesteps | 950272 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 3244        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052550044 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.895      |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0922     |\n",
      "|    n_updates            | 2784        |\n",
      "|    policy_gradient_loss | -0.0517     |\n",
      "|    std                  | 0.27        |\n",
      "|    value_loss           | 0.00748     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 3249        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046218112 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0778     |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    std                  | 0.27        |\n",
      "|    value_loss           | 0.00701     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 467        |\n",
      "|    time_elapsed         | 3254       |\n",
      "|    total_timesteps      | 956416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05587473 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -0.858     |\n",
      "|    explained_variance   | 0.846      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.105     |\n",
      "|    n_updates            | 2796       |\n",
      "|    policy_gradient_loss | -0.0526    |\n",
      "|    std                  | 0.269      |\n",
      "|    value_loss           | 0.00421    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 3260        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046854787 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.842      |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0729     |\n",
      "|    n_updates            | 2802        |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    std                  | 0.269       |\n",
      "|    value_loss           | 0.0115      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=47.14 +/- 4.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 47.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043672577 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.103      |\n",
      "|    n_updates            | 2808        |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 0.00337     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 469    |\n",
      "|    time_elapsed    | 3272   |\n",
      "|    total_timesteps | 960512 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 3277        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051522017 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.807      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.1        |\n",
      "|    n_updates            | 2814        |\n",
      "|    policy_gradient_loss | -0.0505     |\n",
      "|    std                  | 0.267       |\n",
      "|    value_loss           | 0.00382     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 471        |\n",
      "|    time_elapsed         | 3283       |\n",
      "|    total_timesteps      | 964608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04952099 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -0.787     |\n",
      "|    explained_variance   | 0.722      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0855    |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | -0.0517    |\n",
      "|    std                  | 0.267      |\n",
      "|    value_loss           | 0.00872    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 472        |\n",
      "|    time_elapsed         | 3288       |\n",
      "|    total_timesteps      | 966656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04575503 |\n",
      "|    clip_fraction        | 0.0963     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -0.765     |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0737    |\n",
      "|    n_updates            | 2826       |\n",
      "|    policy_gradient_loss | -0.044     |\n",
      "|    std                  | 0.266      |\n",
      "|    value_loss           | 0.0131     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 3294        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049665518 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0988     |\n",
      "|    n_updates            | 2832        |\n",
      "|    policy_gradient_loss | -0.0531     |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 0.00418     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=52.01 +/- 7.07\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 52          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 970000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050420713 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0689     |\n",
      "|    n_updates            | 2838        |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 474    |\n",
      "|    time_elapsed    | 3306   |\n",
      "|    total_timesteps | 970752 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 3311        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049123745 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0713     |\n",
      "|    n_updates            | 2844        |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    std                  | 0.265       |\n",
      "|    value_loss           | 0.0194      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 476        |\n",
      "|    time_elapsed         | 3317       |\n",
      "|    total_timesteps      | 974848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03946651 |\n",
      "|    clip_fraction        | 0.0841     |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -0.717     |\n",
      "|    explained_variance   | 0.876      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.0832    |\n",
      "|    n_updates            | 2850       |\n",
      "|    policy_gradient_loss | -0.0438    |\n",
      "|    std                  | 0.264      |\n",
      "|    value_loss           | 0.00676    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 3322        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054746926 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.691      |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.106      |\n",
      "|    n_updates            | 2856        |\n",
      "|    policy_gradient_loss | -0.0555     |\n",
      "|    std                  | 0.264       |\n",
      "|    value_loss           | 0.0041      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 3328        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043792583 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0878     |\n",
      "|    n_updates            | 2862        |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    std                  | 0.263       |\n",
      "|    value_loss           | 0.00543     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=48.56 +/- 4.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 48.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 980000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048822388 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0697     |\n",
      "|    n_updates            | 2868        |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    std                  | 0.262       |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 479    |\n",
      "|    time_elapsed    | 3340   |\n",
      "|    total_timesteps | 980992 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 3345        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042937133 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0807     |\n",
      "|    n_updates            | 2874        |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    std                  | 0.262       |\n",
      "|    value_loss           | 0.0169      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 3351        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050110515 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.626      |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0635     |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    std                  | 0.262       |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 3357        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042989574 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.614      |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0748     |\n",
      "|    n_updates            | 2886        |\n",
      "|    policy_gradient_loss | -0.0442     |\n",
      "|    std                  | 0.261       |\n",
      "|    value_loss           | 0.00718     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 3363        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048926726 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.591      |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0734     |\n",
      "|    n_updates            | 2892        |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 0.0167      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=51.39 +/- 5.36\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 51.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 990000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05625561 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.332      |\n",
      "|    entropy_loss         | -0.58      |\n",
      "|    explained_variance   | 0.765      |\n",
      "|    learning_rate        | 0.000356   |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 2898       |\n",
      "|    policy_gradient_loss | -0.0579    |\n",
      "|    std                  | 0.26       |\n",
      "|    value_loss           | 0.0051     |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 293    |\n",
      "|    iterations      | 484    |\n",
      "|    time_elapsed    | 3375   |\n",
      "|    total_timesteps | 991232 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 3381        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048473187 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0737     |\n",
      "|    n_updates            | 2904        |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 0.0107      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 3386        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049782027 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.562      |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0987     |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.0535     |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 0.00293     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 3391        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043805603 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0782     |\n",
      "|    n_updates            | 2916        |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 0.00671     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 3397        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047622412 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.54       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0821     |\n",
      "|    n_updates            | 2922        |\n",
      "|    policy_gradient_loss | -0.0528     |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 0.00449     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=40.83 +/- 16.61\n",
      "Episode length: 833.80 +/- 332.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 834         |\n",
      "|    mean_reward          | 40.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050268926 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.332       |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.000356    |\n",
      "|    loss                 | -0.0623     |\n",
      "|    n_updates            | 2928        |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 0.0203      |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 293     |\n",
      "|    iterations      | 489     |\n",
      "|    time_elapsed    | 3408    |\n",
      "|    total_timesteps | 1001472 |\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x15aaeefe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Alleniamo il modello\n",
    "# Il parametro total_timesteps indica il numero totale di iterazioni (o passi)\n",
    "# che il modello eseguirà durante l'allenamento. Ogni timestep rappresenta un'interazione\n",
    "# con l'ambiente in cui il modello esegue un'azione e riceve un feedback, che viene poi\n",
    "# usato per aggiornare la sua politica interna.\n",
    "total_timesteps = 1000000  # Puoi aumentare questo valore per permettere al modello di acquisire più esperienza.\n",
    "model.learn(total_timesteps=total_timesteps, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Salviamo il modello\n",
    "model.save(\"ppo_Ant_model\")\n",
    "env.save(\"vecnormalize_Ant.pkl\")  # salviamo anche i parametri di normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200-400 episodi sono adeguati \n",
    "def evaluate_policy(env, policy, episodes=500):\n",
    "    \"\"\"\n",
    "    Valuta una policy addestrata su un ambiente dato.\n",
    "\n",
    "    Parametri:\n",
    "    - env: L'ambiente di simulazione.\n",
    "    - policy: La policy addestrata da valutare.\n",
    "    - episodes: Numero di episodi da eseguire per la valutazione.\n",
    "\n",
    "    Ritorna:\n",
    "    - La ricompensa media e la deviazione standard delle ricompense ottenute.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs = env.reset()  # Reset dell'ambiente per iniziare un nuovo episodio\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action, _ = policy.predict(obs)  # Predice l'azione da eseguire\n",
    "            obs, reward, done, _ = env.step(action)  # Esegue l'azione e ottiene il feedback dall'ambiente\n",
    "            total_reward += reward  # Accumula la ricompensa ottenuta\n",
    "        total_rewards.append(total_reward)  # Aggiunge la ricompensa totale dell'episodio alla lista\n",
    "    return np.mean(total_rewards), np.std(total_rewards)  # Calcola e ritorna la media e la deviazione standard delle ricompense\n",
    "\n",
    "# 200-400 episodi sono adeguati \n",
    "def evaluate_random_policy(env, episodes=500):\n",
    "    \"\"\"\n",
    "    Valuta una policy casuale su un ambiente dato.\n",
    "\n",
    "    Parametri:\n",
    "    - env: L'ambiente di simulazione.\n",
    "    - episodes: Numero di episodi da eseguire per la valutazione.\n",
    "\n",
    "    Ritorna:\n",
    "    - La ricompensa media e la deviazione standard delle ricompense ottenute.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs = env.reset()  # Reset dell'ambiente per iniziare un nuovo episodio\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action = env.action_space.sample()  # Genera un'azione casuale\n",
    "            obs, reward, done, _ = env.step(np.array([action]))  # Esegue l'azione e ottiene il feedback dall'ambiente\n",
    "            total_reward += reward  # Accumula la ricompensa ottenuta\n",
    "        total_rewards.append(total_reward)  # Aggiunge la ricompensa totale dell'episodio alla lista\n",
    "    return np.mean(total_rewards), np.std(total_rewards)  # Calcola e ritorna la media e la deviazione standard delle ricompense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Policy: Mean Reward: 36.27058029174805, Std: 11.181402206420898\n",
      "Random Policy: Mean Reward: 14.548761367797852, Std: 12.113778114318848\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Valutazione dopo l'addestramento\n",
    "mean_reward_trained, std_reward_trained = evaluate_policy(env, model)  # Valuta la policy addestrata\n",
    "mean_reward_random, std_reward_random = evaluate_random_policy(env)  # Valuta la policy casuale\n",
    "\n",
    "# Stampa dei risultati\n",
    "print(f\"Trained Policy: Mean Reward: {mean_reward_trained}, Std: {std_reward_trained}\")\n",
    "print(f\"Random Policy: Mean Reward: {mean_reward_random}, Std: {std_reward_random}\")\n",
    "\n",
    "# Creazione del grafico di confronto\n",
    "labels = ['Random Policy', 'Trained Policy']\n",
    "means = [mean_reward_random, mean_reward_trained]\n",
    "stds = [std_reward_random, std_reward_trained]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, means, yerr=stds, capsize=10, color=['skyblue', 'lightgreen'])\n",
    "plt.ylabel('Mean Episodic Reward')\n",
    "plt.title('Policy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
