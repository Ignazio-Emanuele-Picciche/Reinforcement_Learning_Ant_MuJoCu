{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, SubprocVecEnv\n",
    "import numpy as np\n",
    "import tensorboard\n",
    "import optuna\n",
    "\n",
    "# Install tqdm if not already installed\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(reset_noise_scale, forward_reward_weight, ctrl_cost_weight, healthy_reward, contact_cost_weight, healthy_z_range, contact_force_range):\n",
    "    \"\"\"\n",
    "    Crea e restituisce l'ambiente Ant-v5 dalla libreria Gymnasium con i parametri specificati.\n",
    "    \"\"\"\n",
    "    # Ant-v5 è l’ambiente più recente in Gymnasium.\n",
    "    return gym.make(\"Ant-v5\", \n",
    "                    reset_noise_scale=reset_noise_scale, \n",
    "                    forward_reward_weight=forward_reward_weight, \n",
    "                    ctrl_cost_weight=ctrl_cost_weight, \n",
    "                    healthy_reward=healthy_reward, \n",
    "                    contact_cost_weight = contact_cost_weight,\n",
    "                    healthy_z_range=healthy_z_range,\n",
    "                    contact_force_range=contact_force_range)\n",
    "                   # render_mode='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # reset_noise_scale = trial.suggest_float('reset_noise_scale', 0.05, 0.2)           # Default circa 0.1; esploriamo da 0.05 a 0.2\n",
    "    # forward_reward_weight = trial.suggest_float('forward_reward_weight', 0.5, 1.5)     # Default tipico è 1; esploriamo da 0.5 a 1.5\n",
    "    # ctrl_cost_weight = trial.suggest_float('ctrl_cost_weight', 0.1, 1.0)               # Default tipico 0.5; esploriamo da 0.1 a 1.0\n",
    "    # healthy_reward = trial.suggest_float('healthy_reward', 0.5, 1.5)                   # Default tipico 1; esploriamo da 0.5 a 1.5\n",
    "    \n",
    "    # # Parametri aggiuntivi per Ant-v5\n",
    "    # contact_cost_weight = trial.suggest_float('contact_cost_weight', 1e-4, 1e-3)  # Es. range intorno a 5e-4 come default\n",
    "    # healthy_z_lower = trial.suggest_float('healthy_z_lower', 0.1, 0.3)             # Per definire l'intervallo di altezze \"sane\"\n",
    "    # healthy_z_upper = trial.suggest_float('healthy_z_upper', 0.8, 1.2)\n",
    "    # contact_force_min = trial.suggest_float('contact_force_min', -1.0, -0.5)         # Modificabile se usi forze di contatto\n",
    "    # contact_force_max = trial.suggest_float('contact_force_max', 0.5, 1.0)\n",
    "\n",
    "\n",
    "    # learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    # n_steps = trial.suggest_int('n_steps', 2048, 8192, step=2048)\n",
    "    # batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])  \n",
    "    # # Per ambienti complessi come Ant, molti esperimenti usano gamma intorno a 0.99-0.995\n",
    "    # gamma = trial.suggest_float('gamma', 0.99, 0.999)\n",
    "    # gae_lambda = trial.suggest_float('gae_lambda', 0.8, 1.0)\n",
    "    # clip_range = trial.suggest_float('clip_range', 0.1, 0.3) \n",
    "    # ent_coef = trial.suggest_float('ent_coef', 0.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-13 14:03:19,848] A new study created in memory with name: no-name-08439524-5e43-4f1a-b29c-ec93379ec575\n",
      "/var/folders/5w/qb_kxxjs5lscg9_8tpttrzs40000gn/T/ipykernel_1007/574168797.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "[I 2025-02-13 14:03:57,253] Trial 0 finished with value: 804.2700148174947 and parameters: {'reset_noise_scale': 0.1520136151187822, 'forward_reward_weight': 1.4254520921256828, 'ctrl_cost_weight': 0.12030169167067424, 'healthy_reward': 1.3804644287683994, 'contact_cost_weight': 0.0003556788854528443, 'healthy_z_lower': 0.14614548407918257, 'healthy_z_upper': 0.8104235185110683, 'contact_force_min': -0.6596389595563125, 'contact_force_max': 0.746882706440835, 'learning_rate': 0.00016626733184664174, 'n_steps': 2048, 'batch_size': 2048, 'gamma': 0.9790997082781029, 'gae_lambda': 0.9704353246066534, 'clip_range': 0.3452303179539005, 'ent_coef': 0.04083438180870861}. Best is trial 0 with value: 804.2700148174947.\n",
      "[I 2025-02-13 14:04:31,522] Trial 1 finished with value: 35.002609356698194 and parameters: {'reset_noise_scale': 0.1725505883475412, 'forward_reward_weight': 1.3921046169276148, 'ctrl_cost_weight': 0.7112208329988289, 'healthy_reward': 0.6552190442745621, 'contact_cost_weight': 0.0001065107500503637, 'healthy_z_lower': 0.23142475005012317, 'healthy_z_upper': 1.1607618209575856, 'contact_force_min': -0.8169504384311854, 'contact_force_max': 0.6812566587335003, 'learning_rate': 0.0003647347491431771, 'n_steps': 2048, 'batch_size': 512, 'gamma': 0.9652141477374709, 'gae_lambda': 0.9674111010667124, 'clip_range': 0.3762152626763437, 'ent_coef': 0.04957155209172706}. Best is trial 0 with value: 804.2700148174947.\n",
      "[I 2025-02-13 14:05:11,072] Trial 2 finished with value: 455.2431815114757 and parameters: {'reset_noise_scale': 0.10658250549505699, 'forward_reward_weight': 0.8939894839867353, 'ctrl_cost_weight': 0.42778380942300404, 'healthy_reward': 0.8806195204442384, 'contact_cost_weight': 0.0005890497891549111, 'healthy_z_lower': 0.2296603873590086, 'healthy_z_upper': 1.0143965486320798, 'contact_force_min': -0.9329092498154783, 'contact_force_max': 0.7257239570938088, 'learning_rate': 0.00016647780469006472, 'n_steps': 6144, 'batch_size': 1024, 'gamma': 0.9792158543609661, 'gae_lambda': 0.9263739321080573, 'clip_range': 0.4385741141599466, 'ent_coef': 0.056422803016490275}. Best is trial 0 with value: 804.2700148174947.\n",
      "[I 2025-02-13 14:05:47,528] Trial 3 finished with value: 283.45950169130623 and parameters: {'reset_noise_scale': 0.06952608740860126, 'forward_reward_weight': 1.1368313059403459, 'ctrl_cost_weight': 0.6120752559530451, 'healthy_reward': 1.46727583104275, 'contact_cost_weight': 0.0005684336773660468, 'healthy_z_lower': 0.23298466821596603, 'healthy_z_upper': 0.970100293715246, 'contact_force_min': -0.6199780305874174, 'contact_force_max': 0.7244850469349675, 'learning_rate': 0.00023009872977380118, 'n_steps': 2048, 'batch_size': 512, 'gamma': 0.9700367187654497, 'gae_lambda': 0.9332420204891086, 'clip_range': 0.461107204210974, 'ent_coef': 0.012794501802862858}. Best is trial 0 with value: 804.2700148174947.\n",
      "[I 2025-02-13 14:06:27,199] Trial 4 finished with value: 623.0369215638203 and parameters: {'reset_noise_scale': 0.08239031589709532, 'forward_reward_weight': 0.6548133698437505, 'ctrl_cost_weight': 0.7160624110076826, 'healthy_reward': 0.9029559973247928, 'contact_cost_weight': 0.0008036672608421973, 'healthy_z_lower': 0.25112519628895086, 'healthy_z_upper': 0.8041675027322143, 'contact_force_min': -0.7171693189423822, 'contact_force_max': 0.8228004079703298, 'learning_rate': 1.1765003935885284e-05, 'n_steps': 2048, 'batch_size': 1024, 'gamma': 0.9784163923500351, 'gae_lambda': 0.9315801738829134, 'clip_range': 0.30658694066204917, 'ent_coef': 0.03327741106634163}. Best is trial 0 with value: 804.2700148174947.\n",
      "[I 2025-02-13 14:07:09,961] Trial 5 finished with value: 693.8029441362456 and parameters: {'reset_noise_scale': 0.15232653914174374, 'forward_reward_weight': 1.4379107565655112, 'ctrl_cost_weight': 0.644458495059171, 'healthy_reward': 0.7992362600827632, 'contact_cost_weight': 0.0003227235941144641, 'healthy_z_lower': 0.20228485123214435, 'healthy_z_upper': 0.8878313533058543, 'contact_force_min': -0.5731108215788805, 'contact_force_max': 0.5919881014457997, 'learning_rate': 1.0043034053465331e-05, 'n_steps': 6144, 'batch_size': 4096, 'gamma': 0.9796614725441395, 'gae_lambda': 0.9313527216545296, 'clip_range': 0.37778380587004773, 'ent_coef': 0.027485642908338992}. Best is trial 0 with value: 804.2700148174947.\n",
      "[I 2025-02-13 14:07:43,211] Trial 6 finished with value: 121.15699996027669 and parameters: {'reset_noise_scale': 0.11554798452485977, 'forward_reward_weight': 1.4790209348346208, 'ctrl_cost_weight': 0.71447413026819, 'healthy_reward': 0.9571901677400906, 'contact_cost_weight': 0.0009949555920633348, 'healthy_z_lower': 0.2818834764597529, 'healthy_z_upper': 0.8909945887796771, 'contact_force_min': -0.9532656115889828, 'contact_force_max': 0.9843514696006834, 'learning_rate': 3.8735663483912424e-05, 'n_steps': 8192, 'batch_size': 512, 'gamma': 0.9736318809293292, 'gae_lambda': 0.91251912209609, 'clip_range': 0.35926107239420435, 'ent_coef': 0.03148077973219663}. Best is trial 0 with value: 804.2700148174947.\n",
      "[I 2025-02-13 14:08:30,535] Trial 7 finished with value: 826.6900556051601 and parameters: {'reset_noise_scale': 0.12572341676176407, 'forward_reward_weight': 0.829228007532589, 'ctrl_cost_weight': 0.5021223372142851, 'healthy_reward': 0.8324073396254394, 'contact_cost_weight': 0.000986325964811443, 'healthy_z_lower': 0.10961726381488393, 'healthy_z_upper': 1.1120556235269774, 'contact_force_min': -0.8353813439034623, 'contact_force_max': 0.6464428524342898, 'learning_rate': 0.00015712665023065247, 'n_steps': 8192, 'batch_size': 1024, 'gamma': 0.9751198960394918, 'gae_lambda': 0.9652173808166763, 'clip_range': 0.3835921499210124, 'ent_coef': 0.09600471471376783}. Best is trial 7 with value: 826.6900556051601.\n",
      "[I 2025-02-13 14:09:03,976] Trial 8 finished with value: 30.906030371710695 and parameters: {'reset_noise_scale': 0.11315158120356936, 'forward_reward_weight': 1.101293905834491, 'ctrl_cost_weight': 0.9578936845845063, 'healthy_reward': 0.6034173714702702, 'contact_cost_weight': 0.0006036342148627051, 'healthy_z_lower': 0.15799085061705048, 'healthy_z_upper': 0.883024052346686, 'contact_force_min': -0.8215992209969402, 'contact_force_max': 0.6654969787870908, 'learning_rate': 0.00037084162150582576, 'n_steps': 6144, 'batch_size': 512, 'gamma': 0.9694637720072237, 'gae_lambda': 0.9501710621981965, 'clip_range': 0.3533475595222246, 'ent_coef': 0.02972845643412734}. Best is trial 7 with value: 826.6900556051601.\n",
      "[I 2025-02-13 14:10:05,003] Trial 9 finished with value: 862.8247806209957 and parameters: {'reset_noise_scale': 0.07362264781275409, 'forward_reward_weight': 0.7052975800022729, 'ctrl_cost_weight': 0.625770246200171, 'healthy_reward': 0.8731142136730435, 'contact_cost_weight': 0.000564897620748436, 'healthy_z_lower': 0.2508795142898002, 'healthy_z_upper': 1.0506639418052248, 'contact_force_min': -0.6092546586303078, 'contact_force_max': 0.5041217584437814, 'learning_rate': 5.3161820551174115e-05, 'n_steps': 4096, 'batch_size': 2048, 'gamma': 0.970885272822333, 'gae_lambda': 0.9739363555333352, 'clip_range': 0.30889294516509075, 'ent_coef': 0.05464171302947483}. Best is trial 9 with value: 862.8247806209957.\n",
      "[I 2025-02-13 14:10:53,911] Trial 10 finished with value: 693.1132188324741 and parameters: {'reset_noise_scale': 0.05032443307311811, 'forward_reward_weight': 0.5019078012905681, 'ctrl_cost_weight': 0.2857076153250355, 'healthy_reward': 1.1685447986031936, 'contact_cost_weight': 0.0007454744358693867, 'healthy_z_lower': 0.2962855501180321, 'healthy_z_upper': 1.0643416610152363, 'contact_force_min': -0.5017193980934478, 'contact_force_max': 0.5034555591657988, 'learning_rate': 0.0009843507465969383, 'n_steps': 4096, 'batch_size': 2048, 'gamma': 0.9659372401775086, 'gae_lambda': 0.998322000263839, 'clip_range': 0.30469769402289476, 'ent_coef': 0.0692015040110003}. Best is trial 9 with value: 862.8247806209957.\n",
      "[I 2025-02-13 14:11:49,353] Trial 11 finished with value: 1113.533904897885 and parameters: {'reset_noise_scale': 0.19688994896767964, 'forward_reward_weight': 0.810879566877222, 'ctrl_cost_weight': 0.4850074153696087, 'healthy_reward': 1.1261838433381532, 'contact_cost_weight': 0.0009089116291813107, 'healthy_z_lower': 0.11133796655928205, 'healthy_z_upper': 1.1232203628497803, 'contact_force_min': -0.8292713559875017, 'contact_force_max': 0.5416060704692642, 'learning_rate': 4.735417929623335e-05, 'n_steps': 8192, 'batch_size': 1024, 'gamma': 0.974533380122525, 'gae_lambda': 0.984106851263348, 'clip_range': 0.4192263224171827, 'ent_coef': 0.0947299918812065}. Best is trial 11 with value: 1113.533904897885.\n",
      "[I 2025-02-13 14:12:44,489] Trial 12 finished with value: 1146.2793865140527 and parameters: {'reset_noise_scale': 0.18600728900348468, 'forward_reward_weight': 0.7241855436448009, 'ctrl_cost_weight': 0.92003802650433, 'healthy_reward': 1.1340273199027073, 'contact_cost_weight': 0.0008063949937014667, 'healthy_z_lower': 0.16791511112291962, 'healthy_z_upper': 1.1706546892954075, 'contact_force_min': -0.7440867736932764, 'contact_force_max': 0.5167441987671567, 'learning_rate': 4.458221339005126e-05, 'n_steps': 4096, 'batch_size': 2048, 'gamma': 0.9709307373830541, 'gae_lambda': 0.9939490861620841, 'clip_range': 0.42468015147573346, 'ent_coef': 0.09972590648990343}. Best is trial 12 with value: 1146.2793865140527.\n",
      "[I 2025-02-13 14:13:36,554] Trial 13 finished with value: 1173.317942473529 and parameters: {'reset_noise_scale': 0.1960228941805394, 'forward_reward_weight': 0.9420521118830517, 'ctrl_cost_weight': 0.9987961334573814, 'healthy_reward': 1.1804623087760715, 'contact_cost_weight': 0.00082872762772537, 'healthy_z_lower': 0.11061047464892867, 'healthy_z_upper': 1.190293012770046, 'contact_force_min': -0.7413008025620504, 'contact_force_max': 0.579195649129446, 'learning_rate': 3.662423719138136e-05, 'n_steps': 4096, 'batch_size': 4096, 'gamma': 0.975720575185661, 'gae_lambda': 0.9965691704584232, 'clip_range': 0.4227968844736432, 'ent_coef': 0.09451769791126495}. Best is trial 13 with value: 1173.317942473529.\n",
      "[I 2025-02-13 14:14:25,223] Trial 14 finished with value: 1201.7875004125492 and parameters: {'reset_noise_scale': 0.19718531696680897, 'forward_reward_weight': 0.9921420134901344, 'ctrl_cost_weight': 0.9584828514862717, 'healthy_reward': 1.2084197044945857, 'contact_cost_weight': 0.0007588593216132154, 'healthy_z_lower': 0.1558779815710732, 'healthy_z_upper': 1.1984757580176228, 'contact_force_min': -0.733654351151829, 'contact_force_max': 0.8405867541649855, 'learning_rate': 2.2795721071133935e-05, 'n_steps': 4096, 'batch_size': 4096, 'gamma': 0.9718916174098319, 'gae_lambda': 0.9976617089201794, 'clip_range': 0.4961048367449865, 'ent_coef': 0.08069700684770957}. Best is trial 14 with value: 1201.7875004125492.\n",
      "[I 2025-02-13 14:15:14,751] Trial 15 finished with value: 1278.0448379283514 and parameters: {'reset_noise_scale': 0.16638377028833234, 'forward_reward_weight': 1.0204644935727354, 'ctrl_cost_weight': 0.850509496504976, 'healthy_reward': 1.280898561018496, 'contact_cost_weight': 0.0007376066562904764, 'healthy_z_lower': 0.1293028476890305, 'healthy_z_upper': 1.1729928483059282, 'contact_force_min': -0.6975548110604961, 'contact_force_max': 0.8706593061748742, 'learning_rate': 2.428130252027207e-05, 'n_steps': 4096, 'batch_size': 4096, 'gamma': 0.9767670000256865, 'gae_lambda': 0.9856470995257379, 'clip_range': 0.49753837482464575, 'ent_coef': 0.07851827824080697}. Best is trial 15 with value: 1278.0448379283514.\n",
      "[I 2025-02-13 14:16:07,575] Trial 16 finished with value: 1298.3177222149127 and parameters: {'reset_noise_scale': 0.1652448940337005, 'forward_reward_weight': 1.2329207867219654, 'ctrl_cost_weight': 0.8523657972807173, 'healthy_reward': 1.3117752027462513, 'contact_cost_weight': 0.0006870729489568602, 'healthy_z_lower': 0.13827378152580955, 'healthy_z_upper': 1.118478860073371, 'contact_force_min': -0.6508928236209142, 'contact_force_max': 0.8598919644482135, 'learning_rate': 2.1055486235213125e-05, 'n_steps': 4096, 'batch_size': 4096, 'gamma': 0.976670184763873, 'gae_lambda': 0.983685480569817, 'clip_range': 0.4974558795472835, 'ent_coef': 0.07622861081447366}. Best is trial 16 with value: 1298.3177222149127.\n",
      "[I 2025-02-13 14:17:01,740] Trial 17 finished with value: 1332.2398336300348 and parameters: {'reset_noise_scale': 0.15841222159399487, 'forward_reward_weight': 1.2534817635155513, 'ctrl_cost_weight': 0.821953797531862, 'healthy_reward': 1.3341955256835054, 'contact_cost_weight': 0.0004327043988678855, 'healthy_z_lower': 0.13309419882233592, 'healthy_z_upper': 1.1150690097129687, 'contact_force_min': -0.6770122969668941, 'contact_force_max': 0.9225655481413069, 'learning_rate': 1.8858067436938132e-05, 'n_steps': 6144, 'batch_size': 4096, 'gamma': 0.9765811234923133, 'gae_lambda': 0.9557693182868863, 'clip_range': 0.49435247054429904, 'ent_coef': 0.07523037979138758}. Best is trial 17 with value: 1332.2398336300348.\n",
      "[I 2025-02-13 14:17:56,605] Trial 18 finished with value: 1499.128641136419 and parameters: {'reset_noise_scale': 0.14021555611084824, 'forward_reward_weight': 1.2802191246333334, 'ctrl_cost_weight': 0.827880142467386, 'healthy_reward': 1.4901621786308343, 'contact_cost_weight': 0.0003992543661647139, 'healthy_z_lower': 0.17874848250847233, 'healthy_z_upper': 1.1003117124443178, 'contact_force_min': -0.5380592889998497, 'contact_force_max': 0.9494702507319864, 'learning_rate': 8.832244853427148e-05, 'n_steps': 6144, 'batch_size': 4096, 'gamma': 0.9774298579356495, 'gae_lambda': 0.949199455897315, 'clip_range': 0.4695554399831394, 'ent_coef': 0.06817608067398113}. Best is trial 18 with value: 1499.128641136419.\n",
      "[I 2025-02-13 14:18:47,986] Trial 19 finished with value: 1439.2688547927748 and parameters: {'reset_noise_scale': 0.13517076466901232, 'forward_reward_weight': 1.2406229579546735, 'ctrl_cost_weight': 0.8099692885034114, 'healthy_reward': 1.494456537092623, 'contact_cost_weight': 0.00042647950464500537, 'healthy_z_lower': 0.18168392042562537, 'healthy_z_upper': 1.074576169565575, 'contact_force_min': -0.5071634192377015, 'contact_force_max': 0.9924649114908926, 'learning_rate': 9.200285958619219e-05, 'n_steps': 6144, 'batch_size': 4096, 'gamma': 0.9772570835435375, 'gae_lambda': 0.9536871027633702, 'clip_range': 0.46555744767129614, 'ent_coef': 0.06664537694900727}. Best is trial 18 with value: 1499.128641136419.\n",
      "[I 2025-02-13 14:19:41,230] Trial 20 finished with value: 1465.0520410556073 and parameters: {'reset_noise_scale': 0.13340858882598935, 'forward_reward_weight': 1.2766149413047336, 'ctrl_cost_weight': 0.7936072916613486, 'healthy_reward': 1.467371602758994, 'contact_cost_weight': 0.00018827049544946285, 'healthy_z_lower': 0.1775568943459002, 'healthy_z_upper': 0.990129830631992, 'contact_force_min': -0.5070674133494529, 'contact_force_max': 0.9997081702554621, 'learning_rate': 7.954065842237862e-05, 'n_steps': 6144, 'batch_size': 4096, 'gamma': 0.9776690512229891, 'gae_lambda': 0.9436182261292089, 'clip_range': 0.4698334939445449, 'ent_coef': 0.06183778209057116}. Best is trial 18 with value: 1499.128641136419.\n",
      "[I 2025-02-13 14:20:34,739] Trial 21 finished with value: 1504.494881389998 and parameters: {'reset_noise_scale': 0.13753799742092854, 'forward_reward_weight': 1.310057286758923, 'ctrl_cost_weight': 0.8014622430475563, 'healthy_reward': 1.4970885004669376, 'contact_cost_weight': 0.00017388428540962022, 'healthy_z_lower': 0.18894024101702786, 'healthy_z_upper': 0.9765289989818047, 'contact_force_min': -0.5088463562239066, 'contact_force_max': 0.984736027650443, 'learning_rate': 8.114506932765498e-05, 'n_steps': 6144, 'batch_size': 4096, 'gamma': 0.9777729182601306, 'gae_lambda': 0.9397210417748172, 'clip_range': 0.46247824611156857, 'ent_coef': 0.06384564452156305}. Best is trial 21 with value: 1504.494881389998.\n",
      "[I 2025-02-13 14:21:26,951] Trial 22 finished with value: 1413.5244699390907 and parameters: {'reset_noise_scale': 0.13976675457476076, 'forward_reward_weight': 1.3452609789378025, 'ctrl_cost_weight': 0.744587965169149, 'healthy_reward': 1.4395344035842543, 'contact_cost_weight': 0.00013785435830036057, 'healthy_z_lower': 0.19346501852169046, 'healthy_z_upper': 0.9646508531851005, 'contact_force_min': -0.5549566867803294, 'contact_force_max': 0.9371321023130535, 'learning_rate': 7.746040276016335e-05, 'n_steps': 6144, 'batch_size': 4096, 'gamma': 0.9779838159476724, 'gae_lambda': 0.9421551873633436, 'clip_range': 0.46717669154297825, 'ent_coef': 0.060439853043728724}. Best is trial 21 with value: 1504.494881389998.\n",
      "[I 2025-02-13 14:22:20,506] Trial 23 finished with value: 1592.7604811594106 and parameters: {'reset_noise_scale': 0.09510312210738994, 'forward_reward_weight': 1.312297906598504, 'ctrl_cost_weight': 0.8880673194633365, 'healthy_reward': 1.4013306745505474, 'contact_cost_weight': 0.0002083743946068172, 'healthy_z_lower': 0.20644266113817852, 'healthy_z_upper': 0.9439676125304286, 'contact_force_min': -0.5507194370007737, 'contact_force_max': 0.9323604686196933, 'learning_rate': 8.342088835075186e-05, 'n_steps': 8192, 'batch_size': 4096, 'gamma': 0.9737211040016112, 'gae_lambda': 0.9419322199533426, 'clip_range': 0.4489142023682039, 'ent_coef': 0.04607391990801879}. Best is trial 23 with value: 1592.7604811594106.\n",
      "[I 2025-02-13 14:23:10,516] Trial 24 finished with value: 1248.479029863589 and parameters: {'reset_noise_scale': 0.0929722310956937, 'forward_reward_weight': 1.1472186623385163, 'ctrl_cost_weight': 0.8836695993112467, 'healthy_reward': 1.3674330699245718, 'contact_cost_weight': 0.0002431832305337969, 'healthy_z_lower': 0.20599705941316254, 'healthy_z_upper': 0.9213466449013958, 'contact_force_min': -0.5683535402015066, 'contact_force_max': 0.9253458938560751, 'learning_rate': 0.0001178343439150528, 'n_steps': 8192, 'batch_size': 4096, 'gamma': 0.9734414172017959, 'gae_lambda': 0.9162188280778416, 'clip_range': 0.4462413780177278, 'ent_coef': 0.04921357436499614}. Best is trial 23 with value: 1592.7604811594106.\n",
      "[I 2025-02-13 14:24:03,574] Trial 25 finished with value: 1240.9113249792542 and parameters: {'reset_noise_scale': 0.09383359832134691, 'forward_reward_weight': 1.3360162537221052, 'ctrl_cost_weight': 0.8976480009553579, 'healthy_reward': 1.0470731414683028, 'contact_cost_weight': 0.00023900565721853137, 'healthy_z_lower': 0.21379046115301253, 'healthy_z_upper': 0.941953101748223, 'contact_force_min': -0.5470198092604057, 'contact_force_max': 0.7968752182609452, 'learning_rate': 7.130173640034088e-05, 'n_steps': 8192, 'batch_size': 4096, 'gamma': 0.9739737602104763, 'gae_lambda': 0.9410586973631117, 'clip_range': 0.449287623855204, 'ent_coef': 0.04212488534785731}. Best is trial 23 with value: 1592.7604811594106.\n",
      "[I 2025-02-13 14:24:57,326] Trial 26 finished with value: 1312.3014726981971 and parameters: {'reset_noise_scale': 0.10107184590686502, 'forward_reward_weight': 1.180963594379526, 'ctrl_cost_weight': 0.7746430586066341, 'healthy_reward': 1.2591585779546188, 'contact_cost_weight': 0.00030958515370391995, 'healthy_z_lower': 0.18583100657929702, 'healthy_z_upper': 1.0219400779193244, 'contact_force_min': -0.606830115995439, 'contact_force_max': 0.9535610483538246, 'learning_rate': 0.00011965131893503837, 'n_steps': 8192, 'batch_size': 4096, 'gamma': 0.9681855157491277, 'gae_lambda': 0.9227548476066608, 'clip_range': 0.47625043880076695, 'ent_coef': 0.014971378623649386}. Best is trial 23 with value: 1592.7604811594106.\n",
      "[I 2025-02-13 14:25:48,957] Trial 27 finished with value: 1085.4505370803315 and parameters: {'reset_noise_scale': 0.12314294853582378, 'forward_reward_weight': 1.0680415310648557, 'ctrl_cost_weight': 0.38243213134082316, 'healthy_reward': 1.4248890966765524, 'contact_cost_weight': 0.00022097044308831438, 'healthy_z_lower': 0.21415476286037066, 'healthy_z_upper': 0.8569878470715521, 'contact_force_min': -0.5386069554670552, 'contact_force_max': 0.891475834659768, 'learning_rate': 0.00024105063030076062, 'n_steps': 6144, 'batch_size': 4096, 'gamma': 0.9723056529206492, 'gae_lambda': 0.9040434014306641, 'clip_range': 0.40554019386274326, 'ent_coef': 0.08400235869695427}. Best is trial 23 with value: 1592.7604811594106.\n",
      "[I 2025-02-13 14:26:44,017] Trial 28 finished with value: 1389.4291777305166 and parameters: {'reset_noise_scale': 0.14454794894645634, 'forward_reward_weight': 1.3052027644396773, 'ctrl_cost_weight': 0.9989698765464917, 'healthy_reward': 1.3885381136643216, 'contact_cost_weight': 0.00045032293457736305, 'healthy_z_lower': 0.17002609373598654, 'healthy_z_upper': 1.037448026284086, 'contact_force_min': -0.5783834998997004, 'contact_force_max': 0.8951596048740409, 'learning_rate': 6.366341432178275e-05, 'n_steps': 8192, 'batch_size': 4096, 'gamma': 0.9758323946061929, 'gae_lambda': 0.9573543507107175, 'clip_range': 0.48288116153156685, 'ent_coef': 0.002096131301111255}. Best is trial 23 with value: 1592.7604811594106.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning con Optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Parametri dell'environment\n",
    "    reset_noise_scale = trial.suggest_float('reset_noise_scale', 0.05, 0.2)           # Default circa 0.1; esploriamo da 0.05 a 0.2\n",
    "    forward_reward_weight = trial.suggest_float('forward_reward_weight', 0.5, 1.5)     # Default tipico è 1; esploriamo da 0.5 a 1.5\n",
    "    ctrl_cost_weight = trial.suggest_float('ctrl_cost_weight', 0.1, 1.0)               # Default tipico 0.5; esploriamo da 0.1 a 1.0\n",
    "    healthy_reward = trial.suggest_float('healthy_reward', 0.5, 1.5)                   # Default tipico 1; esploriamo da 0.5 a 1.5\n",
    "    \n",
    "    # Parametri aggiuntivi per Ant-v5\n",
    "    contact_cost_weight = trial.suggest_float('contact_cost_weight', 1e-4, 1e-3)  # Es. range intorno a 5e-4 come default\n",
    "    healthy_z_lower = trial.suggest_float('healthy_z_lower', 0.1, 0.3)             # Per definire l'intervallo di altezze \"sane\"\n",
    "    healthy_z_upper = trial.suggest_float('healthy_z_upper', 0.8, 1.2)\n",
    "    contact_force_min = trial.suggest_float('contact_force_min', -1.0, -0.5)         # Modificabile se usi forze di contatto\n",
    "    contact_force_max = trial.suggest_float('contact_force_max', 0.5, 1.0)\n",
    "\n",
    "    # Crea l'ambiente passando tutti i parametri\n",
    "    # env = make_env(\n",
    "    #     reset_noise_scale,\n",
    "    #     forward_reward_weight,\n",
    "    #     ctrl_cost_weight,\n",
    "    #     healthy_reward,\n",
    "    #     contact_cost_weight=contact_cost_weight,\n",
    "    #     healthy_z_range=(healthy_z_lower, healthy_z_upper),\n",
    "    #     contact_force_range=(contact_force_min, contact_force_max)\n",
    "    # )\n",
    "    #env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    # MULTIPROCESSING (MULTIENVIRONMENTS) \n",
    "    NUM_ENVS=8\n",
    "    env = SubprocVecEnv([\n",
    "        lambda: make_env(\n",
    "            reset_noise_scale,\n",
    "            forward_reward_weight,\n",
    "            ctrl_cost_weight,\n",
    "            healthy_reward,\n",
    "            contact_cost_weight=contact_cost_weight,\n",
    "            healthy_z_range=(healthy_z_lower, healthy_z_upper),\n",
    "            contact_force_range=(contact_force_min, contact_force_max)\n",
    "        ) for _ in range(NUM_ENVS)\n",
    "    ])\n",
    "    env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "    \n",
    "\n",
    "    env.training = False # Setta l'environment in modalità di valutazione\n",
    "    env.norm_reward = False # Disabilita la normalizzazione della reward. Questo è importante per valutare correttamente il modello.\n",
    "    \n",
    "\n",
    "    # Iperparametri per il modello PPO\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    n_steps = trial.suggest_int('n_steps', 2048, 8192, step=2048)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [512, 1024, 2048, 4096])  \n",
    "    # Per ambienti complessi come Ant, molti esperimenti usano gamma intorno a 0.99-0.995\n",
    "    gamma = trial.suggest_float('gamma', 0.965, 0.98)\n",
    "    gae_lambda = trial.suggest_float('gae_lambda', 0.9, 1.0)\n",
    "    clip_range = trial.suggest_float('clip_range', 0.3, 0.5) \n",
    "    ent_coef = trial.suggest_float('ent_coef', 0.0, 0.1)\n",
    "    \n",
    "    # Nuovo iperparametro per la penalizzazione della varianza\n",
    "    # std_penalty_weight = trial.suggest_float('std_penalty_weight', 0.0, 0.5)\n",
    "\n",
    "\n",
    "\n",
    "    # Crea ed allena il modello PPO\n",
    "    model = PPO(\"MlpPolicy\", env,\n",
    "                learning_rate=learning_rate,\n",
    "                n_steps=n_steps,\n",
    "                batch_size=batch_size,\n",
    "                gamma=gamma,\n",
    "                gae_lambda=gae_lambda,\n",
    "                clip_range=clip_range,\n",
    "                ent_coef=ent_coef,\n",
    "                seed=42,\n",
    "                verbose=0)\n",
    "    model.learn(total_timesteps=200000)\n",
    "\n",
    "    # Valuta il modello su 200 episodi (200 è ottimale)\n",
    "    episodes = 200\n",
    "\n",
    "    # episode_rewards = []\n",
    "    # for episode in range(episodes):\n",
    "    #     obs = env.reset()\n",
    "    #     done = False\n",
    "    #     episode_reward = 0\n",
    "    #     while not done:\n",
    "    #         action, _states = model.predict(obs)\n",
    "    #         obs, reward, done, info = env.step(action)\n",
    "    #         episode_reward += reward\n",
    "    #     episode_rewards.append(episode_reward)\n",
    "\n",
    "    # # Calcola reward media e varianza\n",
    "    # mean_reward = np.mean(episode_rewards)\n",
    "    # reward_std = np.std(episode_rewards)\n",
    "\n",
    "    # # Definisce l'obiettivo: massimizzare la reward media penalizzando la varianza\n",
    "    # score = mean_reward - std_penalty_weight * reward_std\n",
    "\n",
    "    # print(f'Mean is: {mean_reward}, Std is: {reward_std}\\n')\n",
    "\n",
    "\n",
    "\n",
    "    mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=episodes)\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "# Crea uno studio Optuna e ottimizza l'obiettivo\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "# Stampa i migliori iperparametri trovati\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
